{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to extract hidden-states and attention heads activations from ALBERT model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from model import AlbertExtractor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tokenizer import tokenize\n",
    "from utils import set_seed\n",
    "from numpy import linalg as la\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_folder(path):\n",
    "    \"\"\"Create adequate folders if necessary.\"\"\"\n",
    "    try:\n",
    "        if not os.path.isdir(path):\n",
    "            check_folder(os.path.dirname(path))\n",
    "            os.mkdir(path)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(activations, path, name, run_index, n_layers_hidden=13, n_layers_attention=12, hidden_size=768):\n",
    "    assert activations.values.shape[1] == (n_layers_hidden + n_layers_attention) * hidden_size\n",
    "    indexes = [[index*hidden_size, (index+1)*hidden_size] for index in range(n_layers_hidden + n_layers_attention)]\n",
    "    for order in [None]:\n",
    "        matrices = []\n",
    "        for index in indexes:\n",
    "            matrix = activations.values[:, index[0]:index[1]]\n",
    "            with_std = True if order=='std' else False\n",
    "            scaler = StandardScaler(with_mean=True, with_std=with_std)\n",
    "            scaler.fit(matrix)\n",
    "            matrix = scaler.transform(matrix)\n",
    "            if order is not None and order != 'std':\n",
    "                matrix = matrix / np.mean(la.norm(matrix, ord=order, axis=1))\n",
    "            matrices.append(matrix)\n",
    "        matrices = np.hstack(matrices)\n",
    "        new_data = pd.DataFrame(matrices, columns=activations.columns)\n",
    "        new_path = path + '_norm-' + str(order).replace('np.', '')\n",
    "        check_folder(new_path)\n",
    "        new_data.to_csv(os.path.join(new_path, name + '_run{}.csv'.format(run_index + 1)), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/text/english/text_english_run*.txt' # path to text input\n",
    "language = 'english'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating iterator for each run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#template = '/Users/alexpsq/Code/Parietal/data/text_english_run*.txt' # path to text input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob.glob(template))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:00<00:00, 163131.96it/s]\n",
      "100%|██████████| 135/135 [00:00<00:00, 202877.48it/s]\n",
      "100%|██████████| 176/176 [00:00<00:00, 208177.53it/s]\n",
      "100%|██████████| 173/173 [00:00<00:00, 213856.35it/s]\n",
      "100%|██████████| 177/177 [00:00<00:00, 212476.19it/s]\n",
      "100%|██████████| 216/216 [00:00<00:00, 231114.71it/s]\n",
      "100%|██████████| 196/196 [00:00<00:00, 213639.19it/s]\n",
      "100%|██████████| 145/145 [00:00<00:00, 201716.11it/s]\n",
      "100%|██████████| 207/207 [00:00<00:00, 258938.54it/s]\n"
     ]
    }
   ],
   "source": [
    "iterator_list = [tokenize(path, language, train=False) for path in paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_albert_models = ['albert-base-v2'] * 1\n",
    "names = [\n",
    "    #'albert-base-v2_pre-0_1_post-0',\n",
    "    #'albert-base-v2_pre-1_1_post-0',\n",
    "    #'albert-base-v2_pre-2_1_post-0',\n",
    "    #'albert-base-v2_pre-5_1_post-0',\n",
    "    #'albert-base-v2_pre-7_1_post-0',\n",
    "    #'albert-base-v2_pre-10_1_post-0',\n",
    "    #'albert-base-v2_pre-15_1_post-0',\n",
    "    'albert-base-v2_pre-19_1_post-0'\n",
    "         ]\n",
    "config_paths = [None] * 8\n",
    "saving_path_folders = [\n",
    "    #'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/{}/albert-base-v2_pre-0_1_post-0'.format(language),\n",
    "    #'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/{}/albert-base-v2_pre-1_1_post-0'.format(language),\n",
    "    #'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/{}/albert-base-v2_pre-2_1_post-0'.format(language),\n",
    "    #'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/{}/albert-base-v2_pre-5_1_post-0'.format(language),\n",
    "    #'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/{}/albert-base-v2_pre-7_1_post-0'.format(language),\n",
    "    #'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/{}/albert-base-v2_pre-10_1_post-0'.format(language),\n",
    "    #'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/{}/albert-base-v2_pre-15_1_post-0'.format(language),\n",
    "    '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/{}/albert-base-v2_pre-19_1_post-0'.format(language)\n",
    "]\n",
    "prediction_types = ['sentence'] * 8\n",
    "number_of_sentence_list = [1] * 8\n",
    "number_of_sentence_before_list = [19] # 0, 1, 2, 5, 7, 10, 15, 20\n",
    "number_of_sentence_after_list = [0] * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albert-base-v2_pre-19_1_post-0  - Extracting activations ...\n",
      "############# Run 0 #############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [01:14, 74.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Run 1 #############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [01:55, 64.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Run 2 #############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [02:41, 59.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Run 3 #############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [03:25, 54.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Run 4 #############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [04:08, 50.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Run 5 #############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [05:00, 51.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Run 6 #############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [06:35, 64.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Run 7 #############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [07:16, 57.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Run 8 #############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [08:07, 54.14s/it]\n"
     ]
    }
   ],
   "source": [
    "for index, albert_model in enumerate(pretrained_albert_models):\n",
    "    extractor = AlbertExtractor(albert_model, \n",
    "                              language, \n",
    "                              names[index], \n",
    "                              prediction_types[index], \n",
    "                              output_hidden_states=True, \n",
    "                              output_attentions=False, \n",
    "                              config_path=config_paths[index], \n",
    "                              max_length=512, \n",
    "                              number_of_sentence=number_of_sentence_list[index], \n",
    "                              number_of_sentence_before=number_of_sentence_before_list[index], \n",
    "                              number_of_sentence_after=number_of_sentence_after_list[index])\n",
    "    print(extractor.name, ' - Extracting activations ...')\n",
    "    for run_index, iterator in tqdm(enumerate(iterator_list)):\n",
    "        gc.collect()\n",
    "        print(\"############# Run {} #############\".format(run_index))\n",
    "        activations  = extractor.extract_activations(iterator, language)\n",
    "        hidden_states_activations = activations[0]\n",
    "        #attention_heads_activations = activations[1]\n",
    "        #(cls_hidden_states_activations, cls_attention_activations) = activations[2]\n",
    "        #(sep_hidden_states_activations, sep_attention_activations) = activations[3]\n",
    "        #activations = pd.concat([hidden_states_activations, attention_heads_activations], axis=1)\n",
    "        #cls_activations = pd.concat([cls_hidden_states_activations, cls_attention_activations], axis=1)\n",
    "        #sep_activations = pd.concat([sep_hidden_states_activations, sep_attention_activations], axis=1)\n",
    "        \n",
    "        transform(\n",
    "            hidden_states_activations, \n",
    "            saving_path_folders[index], \n",
    "            'activations', \n",
    "            run_index=run_index,\n",
    "            n_layers_hidden=13,\n",
    "            n_layers_attention=0, \n",
    "            hidden_size=768)\n",
    "        #transform(activations, saving_path_folders[index], 'activations', run_index=run_index)\n",
    "        #transform(cls_activations, saving_path_folders[index], 'cls')\n",
    "        #transform(sep_activations, saving_path_folders[index], 'sep')\n",
    "        \n",
    "        #activations.to_csv(os.path.join(saving_path_folders[index], 'activations_run{}.csv'.format(run_index + 1)), index=False)\n",
    "        #cls_activations.to_csv(os.path.join(saving_path_folders[index], 'cls_run{}.csv'.format(run_index + 1)), index=False)\n",
    "        #sep_activations.to_csv(os.path.join(saving_path_folders[index], 'sep_run{}.csv'.format(run_index + 1)), index=False)\n",
    "        del activations\n",
    "        #del cls_activations\n",
    "        #del sep_activations\n",
    "        del hidden_states_activations\n",
    "        #del attention_heads_activations\n",
    "        #del cls_hidden_states_activations\n",
    "        #del cls_attention_activations\n",
    "        #del sep_hidden_states_activations\n",
    "        #del sep_attention_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
