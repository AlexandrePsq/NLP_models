{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to extract hidden-states and attention heads activations from LSTM model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from model import LSTMExtractor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import linalg as la\n",
    "from tokenizer import tokenize\n",
    "from utils import set_seed\n",
    "from data import Dictionary\n",
    "from utils import read_yaml, save_yaml, batchify_text_with_memory_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_folder(path):\n",
    "    \"\"\"Create adequate folders if necessary.\"\"\"\n",
    "    try:\n",
    "        if not os.path.isdir(path):\n",
    "            check_folder(os.path.dirname(path))\n",
    "            os.mkdir(path)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(activations, path, name, run_index, n_layers_hidden=1, hidden_size=300):\n",
    "    assert activations.values.shape[1] == ((n_layers_hidden) * hidden_size + 2)\n",
    "    indexes = [[index*hidden_size, (index+1)*hidden_size] for index in range(n_layers_hidden)]\n",
    "    indexes += [[-2, -1], [-1, activations.values.shape[1]]]\n",
    "    for order in [None]:\n",
    "        matrices = []\n",
    "        for index in indexes:\n",
    "            matrix = activations.values[:, index[0]:index[1]]\n",
    "            with_std = True if order=='std' else False\n",
    "            scaler = StandardScaler(with_mean=True, with_std=with_std)\n",
    "            scaler.fit(matrix)\n",
    "            matrix = scaler.transform(matrix)\n",
    "            if order is not None and order != 'std':\n",
    "                matrix = matrix / np.mean(la.norm(matrix, ord=order, axis=1))\n",
    "            matrices.append(matrix)\n",
    "        matrices = np.hstack(matrices)\n",
    "        new_data = pd.DataFrame(matrices, columns=activations.columns)\n",
    "        new_path = path + '_norm-' + str(order).replace('np.', '')\n",
    "        check_folder(new_path)\n",
    "        new_data.to_csv(os.path.join(new_path, name + '_run{}.csv'.format(run_index + 1)), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/text/english/text_english_run*.txt' # path to text input\n",
    "language = 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_template = 'weights_{}_embedding-size-{}_nhid-{}_nlayers-{}_dropout-{}_memory-size-{}_wiki-kristina_english.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_types = ['LSTM'] * 17\n",
    "ninps = ['600'] * 17\n",
    "nhids =  ['300'] * 17\n",
    "nlayers = ['1'] * 17\n",
    "dropouts =  ['02'] * 17\n",
    "memory_sizes = [1, 2, 3, 4, 5, 7, 10, 12, 15, 17, 20, 25, 30, 35, 40, 50, np.inf]\n",
    "vocab_path = '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/text/english/lstm_training'\n",
    "config_path_folder = '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/models/LSTM/configs/'\n",
    "trained_model_folder = '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/derivatives/fMRI/models/english/'\n",
    "path_to_data = '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#template = '/Users/alexpsq/Code/Parietal/data/text_english_run*.txt' # path to text input\n",
    "#config_path_folder = '/Users/alexpsq/Code/Parietal/data/configs/'\n",
    "#trained_model_folder = '/Users/alexpsq/Code/Parietal'\n",
    "#path_to_data = '/Users/alexpsq/Code/data/stimuli-representations'\n",
    "#vocab_path = '/Users/alexpsq/Code/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_lstm_models = [\n",
    "    trained_model_folder + name_template.format(rnn_type, ninp, nhid, nlayer, dropout, memory_size) for (rnn_type, ninp, nhid, nlayer, dropout, memory_size) in zip(rnn_types, ninps, nhids, nlayers, dropouts, memory_sizes)] # path to the model from which we want to retrieve the activations\n",
    "infos = [os.path.basename(model).split('_') for model in pretrained_lstm_models]\n",
    "names = ['_'.join(os.path.basename(model).split('.')[0].split('_')[1:]) for model in pretrained_lstm_models]\n",
    "config_paths = [os.path.join(config_path_folder, 'config_' + name + '.yml') for name in names]\n",
    "config_paths = ['_'.join(config.split('_')[:-3]) + '_' + '_'.join(config.split('_')[-2:]) for config in config_paths]\n",
    "saving_path_folders = [\n",
    "    os.path.join(path_to_data, '{}/{}'.format(language, name)) for name in names]\n",
    "prediction_types = ['sequential' for i in pretrained_lstm_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/english/LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-1_wiki-kristina_english',\n",
       " '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/english/LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-2_wiki-kristina_english',\n",
       " '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/english/LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-3_wiki-kristina_english',\n",
       " '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/english/LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-4_wiki-kristina_english',\n",
       " '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/english/LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-5_wiki-kristina_english',\n",
       " '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/english/LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-7_wiki-kristina_english',\n",
       " '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/english/LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-10_wiki-kristina_english',\n",
       " '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/english/LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-12_wiki-kristina_english',\n",
       " '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/english/LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-15_wiki-kristina_english',\n",
       " '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/english/LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-17_wiki-kristina_english',\n",
       " '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/english/LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-20_wiki-kristina_english',\n",
       " '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/english/LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-25_wiki-kristina_english',\n",
       " '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/english/LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-30_wiki-kristina_english',\n",
       " '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/english/LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-35_wiki-kristina_english',\n",
       " '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/english/LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-40_wiki-kristina_english',\n",
       " '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/english/LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-50_wiki-kristina_english',\n",
       " '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/english/LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-inf_wiki-kristina_english']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saving_path_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(rnn_type='LSTM',\n",
    "               language='english',\n",
    "               ntoken=50001,\n",
    "               ninp=650,\n",
    "               nhid=650,\n",
    "               nlayers=2,\n",
    "               dropout='02',\n",
    "               memory_size=np.inf,\n",
    "               tie_weights=False,\n",
    "               eos_separator='<eos>',\n",
    "               cuda=True,\n",
    "               weights_path=None,\n",
    "               path_to_vocab=None,\n",
    "               includ_surprisal=True,\n",
    "               includ_entropy=True,\n",
    "               parameters=['in', 'forget', 'out', 'c_tilde', 'hidden', 'cell']):\n",
    "    config_template = {\n",
    "        'rnn_type': rnn_type,\n",
    "        'language': language,\n",
    "        'ntoken': ntoken,\n",
    "        'ninp': ninp,\n",
    "        'nhid': nhid,\n",
    "        'nlayers': nlayers,\n",
    "        'dropout': int(dropout)/10,\n",
    "        'memory_size': memory_size,\n",
    "        'tie_weights': tie_weights,\n",
    "        'eos_separator': eos_separator,\n",
    "        'cuda': cuda,\n",
    "        'weights_path': os.path.join(weights_path, name_template.format(rnn_type, ninp, nhid, nlayers, dropout, 0)).replace('_memory-size-0', ''),\n",
    "        'path_to_vocab': path_to_vocab,\n",
    "        'includ_surprisal': includ_surprisal,\n",
    "        'includ_entropy': includ_entropy,\n",
    "        'parameters': parameters}\n",
    "    return config_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (rnn_type, ninp, nhid, nlayer, dropout, memory_size) in enumerate(zip(rnn_types, ninps, nhids, nlayers, dropouts, memory_sizes)):\n",
    "    config_template =  get_config(rnn_type=rnn_type,\n",
    "                                   language='english',\n",
    "                                   ntoken=50001,\n",
    "                                   ninp=int(ninp),\n",
    "                                   nhid=int(nhid),\n",
    "                                   nlayers=int(nlayer),\n",
    "                                   dropout=dropout,\n",
    "                                   memory_size=memory_size,\n",
    "                                   weights_path=trained_model_folder,\n",
    "                                   path_to_vocab=vocab_path,\n",
    "                                 parameters=['hidden'])\n",
    "    save_yaml(config_template, config_paths[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rnn_type': 'LSTM',\n",
       " 'language': 'english',\n",
       " 'ntoken': 50001,\n",
       " 'ninp': 600,\n",
       " 'nhid': 300,\n",
       " 'nlayers': 1,\n",
       " 'dropout': 0.2,\n",
       " 'memory_size': inf,\n",
       " 'tie_weights': False,\n",
       " 'eos_separator': '<eos>',\n",
       " 'cuda': True,\n",
       " 'weights_path': '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/derivatives/fMRI/models/english/weights_LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_wiki-kristina_english.pt',\n",
       " 'path_to_vocab': '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/text/english/lstm_training',\n",
       " 'includ_surprisal': True,\n",
       " 'includ_entropy': True,\n",
       " 'parameters': ['hidden']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating iterator for each run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob.glob(template))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Dictionary(vocab_path, language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:00<00:00, 154834.85it/s]\n",
      "100%|██████████| 135/135 [00:00<00:00, 621.31it/s]\n",
      "100%|██████████| 135/135 [00:00<00:00, 210338.42it/s]\n",
      "100%|██████████| 135/135 [00:00<00:00, 533.69it/s]\n",
      "100%|██████████| 176/176 [00:00<00:00, 243549.16it/s]\n",
      "100%|██████████| 176/176 [00:00<00:00, 711.79it/s]\n",
      "100%|██████████| 173/173 [00:00<00:00, 201727.72it/s]\n",
      "100%|██████████| 173/173 [00:00<00:00, 772.33it/s]\n",
      "100%|██████████| 177/177 [00:00<00:00, 231780.15it/s]\n",
      "100%|██████████| 177/177 [00:00<00:00, 913.51it/s]\n",
      "100%|██████████| 216/216 [00:00<00:00, 266461.67it/s]\n",
      "100%|██████████| 216/216 [00:00<00:00, 1026.84it/s]\n",
      "100%|██████████| 196/196 [00:00<00:00, 229120.29it/s]\n",
      "100%|██████████| 196/196 [00:00<00:00, 740.46it/s]\n",
      "100%|██████████| 145/145 [00:00<00:00, 221961.34it/s]\n",
      "100%|██████████| 145/145 [00:00<00:00, 709.31it/s]\n",
      "100%|██████████| 207/207 [00:00<00:00, 257403.18it/s]\n",
      "100%|██████████| 207/207 [00:00<00:00, 1008.55it/s]\n"
     ]
    }
   ],
   "source": [
    "iterator_list = [tokenize(path, language, train=False, vocab=vocab) for path in paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "9it [00:00, 82.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_embedding-size_600_nhid_300_nlayers_1_dropout_02  - Extracting activations ...\n",
      "############# Run 0 #############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "17it [00:00, 78.61it/s]\u001b[A\n",
      "26it [00:00, 78.21it/s]\u001b[A\n",
      "36it [00:00, 82.96it/s]\u001b[A\n",
      "43it [00:00, 76.88it/s]\u001b[A\n",
      "62it [00:00, 91.77it/s]\u001b[A\n",
      "77it [00:00, 100.88it/s]\u001b[A\n",
      "88it [00:00, 88.77it/s] \u001b[A\n",
      "98it [00:01, 79.87it/s]\u001b[A\n",
      "118it [00:01, 97.36it/s]\u001b[A\n",
      "130it [00:01, 95.03it/s]\u001b[A\n",
      "142it [00:01, 87.14it/s]\u001b[A\n",
      "152it [00:01, 87.01it/s]\u001b[A\n",
      "179it [00:01, 109.05it/s]\u001b[A\n",
      "194it [00:01, 118.39it/s]\u001b[A\n",
      "209it [00:01, 126.26it/s]\u001b[A\n",
      "232it [00:02, 145.27it/s]\u001b[A\n",
      "254it [00:02, 161.73it/s]\u001b[A\n",
      "273it [00:02, 135.56it/s]\u001b[A\n",
      "289it [00:02, 118.49it/s]\u001b[A\n",
      "303it [00:02, 110.18it/s]\u001b[A\n",
      "316it [00:02, 112.77it/s]\u001b[A\n",
      "329it [00:02, 106.27it/s]\u001b[A\n",
      "341it [00:03, 94.61it/s] \u001b[A\n",
      "352it [00:03, 80.86it/s]\u001b[A\n",
      "362it [00:03, 76.07it/s]\u001b[A\n",
      "371it [00:03, 72.40it/s]\u001b[A\n",
      "381it [00:03, 76.45it/s]\u001b[A\n",
      "395it [00:03, 86.29it/s]\u001b[A\n",
      "406it [00:03, 91.38it/s]\u001b[A\n",
      "416it [00:03, 85.42it/s]\u001b[A\n",
      "426it [00:04, 81.24it/s]\u001b[A\n",
      "435it [00:04, 81.28it/s]\u001b[A\n",
      "444it [00:04, 78.95it/s]\u001b[A\n",
      "453it [00:04, 80.02it/s]\u001b[A\n",
      "463it [00:04, 83.95it/s]\u001b[A\n",
      "472it [00:04, 81.86it/s]\u001b[A\n",
      "481it [00:04, 81.20it/s]\u001b[A\n",
      "491it [00:04, 83.60it/s]\u001b[A\n",
      "500it [00:05, 77.65it/s]\u001b[A\n",
      "509it [00:05, 78.13it/s]\u001b[A\n",
      "517it [00:05, 77.93it/s]\u001b[A\n",
      "526it [00:05, 78.86it/s]\u001b[A\n",
      "534it [00:05, 73.57it/s]\u001b[A\n",
      "545it [00:05, 80.05it/s]\u001b[A\n",
      "554it [00:05, 80.64it/s]\u001b[A\n",
      "566it [00:05, 86.71it/s]\u001b[A\n",
      "578it [00:05, 91.45it/s]\u001b[A\n",
      "588it [00:06, 82.65it/s]\u001b[A\n",
      "599it [00:06, 87.58it/s]\u001b[A\n",
      "609it [00:06, 78.87it/s]\u001b[A\n",
      "618it [00:06, 81.73it/s]\u001b[A\n",
      "628it [00:06, 84.76it/s]\u001b[A\n",
      "637it [00:06, 81.30it/s]\u001b[A\n",
      "647it [00:06, 85.91it/s]\u001b[A\n",
      "661it [00:06, 95.09it/s]\u001b[A\n",
      "671it [00:07, 90.40it/s]\u001b[A\n",
      "681it [00:07, 87.00it/s]\u001b[A\n",
      "692it [00:07, 92.15it/s]\u001b[A\n",
      "702it [00:07, 89.30it/s]\u001b[A\n",
      "712it [00:07, 90.47it/s]\u001b[A\n",
      "723it [00:07, 95.43it/s]\u001b[A\n",
      "735it [00:07, 101.61it/s]\u001b[A\n",
      "746it [00:07, 86.99it/s] \u001b[A\n",
      "759it [00:07, 95.06it/s]\u001b[A\n",
      "770it [00:08, 84.40it/s]\u001b[A\n",
      "780it [00:08, 81.90it/s]\u001b[A\n",
      "789it [00:08, 81.41it/s]\u001b[A\n",
      "798it [00:08, 77.70it/s]\u001b[A\n",
      "813it [00:08, 90.70it/s]\u001b[A\n",
      "838it [00:08, 112.03it/s]\u001b[A\n",
      "855it [00:08, 122.52it/s]\u001b[A\n",
      "870it [00:08, 115.64it/s]\u001b[A\n",
      "884it [00:09, 107.33it/s]\u001b[A\n",
      "897it [00:09, 111.64it/s]\u001b[A\n",
      "910it [00:09, 109.89it/s]\u001b[A\n",
      "922it [00:09, 96.52it/s] \u001b[A\n",
      "933it [00:09, 98.89it/s]\u001b[A\n",
      "944it [00:09, 95.17it/s]\u001b[A\n",
      "954it [00:09, 84.06it/s]\u001b[A\n",
      "965it [00:09, 89.09it/s]\u001b[A\n",
      "975it [00:10, 90.37it/s]\u001b[A\n",
      "987it [00:10, 94.19it/s]\u001b[A\n",
      "1000it [00:10, 100.45it/s]\u001b[A\n",
      "1011it [00:10, 91.49it/s] \u001b[A\n",
      "1021it [00:10, 85.21it/s]\u001b[A\n",
      "1030it [00:10, 83.66it/s]\u001b[A\n",
      "1041it [00:10, 89.72it/s]\u001b[A\n",
      "1052it [00:10, 92.54it/s]\u001b[A\n",
      "1063it [00:11, 92.95it/s]\u001b[A\n",
      "1077it [00:11, 103.19it/s]\u001b[A\n",
      "1088it [00:11, 92.91it/s] \u001b[A\n",
      "1098it [00:11, 83.05it/s]\u001b[A\n",
      "1107it [00:11, 79.38it/s]\u001b[A\n",
      "1118it [00:11, 84.78it/s]\u001b[A\n",
      "1129it [00:11, 87.91it/s]\u001b[A\n",
      "1139it [00:11, 83.56it/s]\u001b[A\n",
      "1149it [00:11, 87.04it/s]\u001b[A\n",
      "1162it [00:12, 94.17it/s]\u001b[A\n",
      "1172it [00:12, 87.14it/s]\u001b[A\n",
      "1182it [00:12, 90.52it/s]\u001b[A\n",
      "1203it [00:12, 108.78it/s]\u001b[A\n",
      "1216it [00:12, 113.02it/s]\u001b[A\n",
      "1229it [00:12, 92.70it/s] \u001b[A\n",
      "1240it [00:12, 93.20it/s]\u001b[A\n",
      "1251it [00:12, 91.31it/s]\u001b[A\n",
      "1261it [00:13, 93.28it/s]\u001b[A\n",
      "1276it [00:13, 102.61it/s]\u001b[A\n",
      "1288it [00:13, 107.14it/s]\u001b[A\n",
      "1300it [00:13, 110.24it/s]\u001b[A\n",
      "1312it [00:13, 91.32it/s] \u001b[A\n",
      "1322it [00:13, 85.17it/s]\u001b[A\n",
      "1332it [00:13, 88.49it/s]\u001b[A\n",
      "1346it [00:13, 96.80it/s]\u001b[A\n",
      "1368it [00:14, 116.12it/s]\u001b[A\n",
      "1382it [00:14, 120.61it/s]\u001b[A\n",
      "1402it [00:14, 133.63it/s]\u001b[A\n",
      "1417it [00:14, 128.11it/s]\u001b[A\n",
      "1431it [00:14, 112.63it/s]\u001b[A\n",
      "1444it [00:14, 100.42it/s]\u001b[A\n",
      "1456it [00:14, 102.04it/s]\u001b[A\n",
      "1467it [00:14, 91.43it/s] \u001b[A\n",
      "1478it [00:15, 94.58it/s]\u001b[A\n",
      "1488it [00:15, 93.66it/s]\u001b[A\n",
      "1498it [00:15, 93.27it/s]\u001b[A\n",
      "1509it [00:15, 94.86it/s]\u001b[A\n",
      "1519it [00:15, 95.18it/s]\u001b[A\n",
      "1529it [00:15, 94.64it/s]\u001b[A\n",
      "1539it [00:15, 82.39it/s]\u001b[A\n",
      "1548it [00:15, 80.68it/s]\u001b[A\n",
      "1557it [00:16, 75.33it/s]\u001b[A\n",
      "1577it [00:16, 92.52it/s]\u001b[A\n",
      "1589it [00:16, 89.58it/s]\u001b[A\n",
      "1600it [00:16, 88.96it/s]\u001b[A\n",
      "1610it [00:16, 79.70it/s]\u001b[A\n",
      "1621it [00:16, 85.47it/s]\u001b[A\n",
      "1631it [00:16, 80.94it/s]\u001b[A\n",
      "1641it [00:16, 84.92it/s]\u001b[A\n",
      "1653it [00:17, 90.36it/s]\u001b[A\n",
      "1663it [00:17, 81.03it/s]\u001b[A\n",
      "1673it [00:17, 84.63it/s]\u001b[A\n",
      "1684it [00:17, 88.45it/s]\u001b[A\n",
      "1698it [00:17, 96.94it/s]\u001b[A\n",
      "1709it [00:17, 100.39it/s]\u001b[A\n",
      "1720it [00:17, 86.80it/s] \u001b[A\n",
      "1730it [00:17, 78.78it/s]\u001b[A\n",
      "1742it [00:18, 87.73it/s]\u001b[A\n",
      "1752it [00:18, 82.48it/s]\u001b[A\n",
      "1761it [00:18, 80.80it/s]\u001b[A\n",
      "1770it [00:18, 78.91it/s]\u001b[A\n",
      "1779it [00:18, 81.81it/s]\u001b[A\n",
      "1790it [00:18, 87.00it/s]\u001b[A\n",
      "1802it [00:18, 94.56it/s]\u001b[A\n",
      "1812it [00:18, 85.00it/s]\u001b[A\n",
      "1821it [00:18, 84.29it/s]\u001b[A\n",
      "1832it [00:19, 88.43it/s]\u001b[A\n",
      "1844it [00:19, 95.70it/s]\u001b[A\n",
      "1854it [00:19, 89.00it/s]\u001b[A\n",
      "1867it [00:19, 98.11it/s]\u001b[A\n",
      "1878it [00:19, 90.77it/s]\u001b[A\n",
      "1894it [00:19, 96.01it/s]\u001b[A\n",
      "1it [00:20, 20.51s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "12it [00:00, 116.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Run 1 #############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "22it [00:00, 108.60it/s]\u001b[A\n",
      "28it [00:00, 87.16it/s] \u001b[A\n",
      "38it [00:00, 89.84it/s]\u001b[A\n",
      "47it [00:00, 89.43it/s]\u001b[A\n",
      "58it [00:00, 90.77it/s]\u001b[A\n",
      "66it [00:00, 78.86it/s]\u001b[A\n",
      "90it [00:00, 97.45it/s]\u001b[A\n",
      "116it [00:00, 119.86it/s]\u001b[A\n",
      "132it [00:01, 107.72it/s]\u001b[A\n",
      "146it [00:01, 94.16it/s] \u001b[A\n",
      "161it [00:01, 104.19it/s]\u001b[A\n",
      "186it [00:01, 125.84it/s]\u001b[A\n",
      "213it [00:01, 149.64it/s]\u001b[A\n",
      "233it [00:01, 139.07it/s]\u001b[A\n",
      "251it [00:01, 131.16it/s]\u001b[A\n",
      "267it [00:02, 113.97it/s]\u001b[A\n",
      "281it [00:02, 96.86it/s] \u001b[A\n",
      "293it [00:02, 94.68it/s]\u001b[A\n",
      "304it [00:02, 89.83it/s]\u001b[A\n",
      "314it [00:02, 80.12it/s]\u001b[A\n",
      "324it [00:02, 83.99it/s]\u001b[A\n",
      "336it [00:03, 91.64it/s]\u001b[A\n",
      "346it [00:03, 93.96it/s]\u001b[A\n",
      "356it [00:03, 90.46it/s]\u001b[A\n",
      "366it [00:03, 87.92it/s]\u001b[A\n",
      "376it [00:03, 89.02it/s]\u001b[A\n",
      "386it [00:03, 85.41it/s]\u001b[A\n",
      "398it [00:03, 90.65it/s]\u001b[A\n",
      "411it [00:03, 97.62it/s]\u001b[A\n",
      "424it [00:03, 103.23it/s]\u001b[A\n",
      "435it [00:04, 94.98it/s] \u001b[A\n",
      "445it [00:04, 84.97it/s]\u001b[A\n",
      "454it [00:04, 80.23it/s]\u001b[A\n",
      "465it [00:04, 84.95it/s]\u001b[A\n",
      "492it [00:04, 106.77it/s]\u001b[A\n",
      "518it [00:04, 129.42it/s]\u001b[A\n",
      "541it [00:04, 145.85it/s]\u001b[A\n",
      "560it [00:04, 117.48it/s]\u001b[A\n",
      "576it [00:05, 104.06it/s]\u001b[A\n",
      "590it [00:05, 100.15it/s]\u001b[A\n",
      "603it [00:05, 95.19it/s] \u001b[A\n",
      "614it [00:05, 81.26it/s]\u001b[A\n",
      "624it [00:05, 74.58it/s]\u001b[A\n",
      "633it [00:05, 76.82it/s]\u001b[A\n",
      "642it [00:06, 76.87it/s]\u001b[A\n",
      "653it [00:06, 83.14it/s]\u001b[A\n",
      "662it [00:06, 80.66it/s]\u001b[A\n",
      "676it [00:06, 91.29it/s]\u001b[A\n",
      "689it [00:06, 99.64it/s]\u001b[A\n",
      "700it [00:06, 97.35it/s]\u001b[A\n",
      "711it [00:06, 86.26it/s]\u001b[A\n",
      "722it [00:06, 91.77it/s]\u001b[A\n",
      "732it [00:06, 86.62it/s]\u001b[A\n",
      "745it [00:07, 96.23it/s]\u001b[A\n",
      "758it [00:07, 102.51it/s]\u001b[A\n",
      "769it [00:07, 89.43it/s] \u001b[A\n",
      "779it [00:07, 90.58it/s]\u001b[A\n",
      "804it [00:07, 111.57it/s]\u001b[A\n",
      "829it [00:07, 133.46it/s]\u001b[A\n",
      "847it [00:07, 113.49it/s]\u001b[A\n",
      "862it [00:08, 114.24it/s]\u001b[A\n",
      "876it [00:08, 94.84it/s] \u001b[A\n",
      "888it [00:08, 87.06it/s]\u001b[A\n",
      "899it [00:08, 83.75it/s]\u001b[A\n",
      "909it [00:08, 82.61it/s]\u001b[A\n",
      "919it [00:08, 79.01it/s]\u001b[A\n",
      "928it [00:08, 73.53it/s]\u001b[A\n",
      "940it [00:09, 82.61it/s]\u001b[A\n",
      "950it [00:09, 87.04it/s]\u001b[A\n",
      "961it [00:09, 90.48it/s]\u001b[A\n",
      "971it [00:09, 89.84it/s]\u001b[A\n",
      "983it [00:09, 96.32it/s]\u001b[A\n",
      "993it [00:09, 90.41it/s]\u001b[A\n",
      "1003it [00:09, 84.25it/s]\u001b[A\n",
      "1014it [00:09, 87.92it/s]\u001b[A\n",
      "1024it [00:09, 80.09it/s]\u001b[A\n",
      "1033it [00:10, 74.45it/s]\u001b[A\n",
      "1043it [00:10, 79.03it/s]\u001b[A\n",
      "1053it [00:10, 81.95it/s]\u001b[A\n",
      "1064it [00:10, 86.80it/s]\u001b[A\n",
      "1073it [00:10, 86.07it/s]\u001b[A\n",
      "1082it [00:10, 82.94it/s]\u001b[A\n",
      "1093it [00:10, 86.71it/s]\u001b[A\n",
      "1102it [00:10, 79.31it/s]\u001b[A\n",
      "1111it [00:11, 78.37it/s]\u001b[A\n",
      "1122it [00:11, 83.05it/s]\u001b[A\n",
      "1133it [00:11, 89.49it/s]\u001b[A\n",
      "1153it [00:11, 107.09it/s]\u001b[A\n",
      "1176it [00:11, 126.24it/s]\u001b[A\n",
      "1192it [00:11, 102.85it/s]\u001b[A\n",
      "1205it [00:11, 94.24it/s] \u001b[A\n",
      "1217it [00:11, 100.31it/s]\u001b[A\n",
      "1229it [00:12, 104.15it/s]\u001b[A\n",
      "1248it [00:12, 119.28it/s]\u001b[A\n",
      "1271it [00:12, 138.43it/s]\u001b[A\n",
      "1291it [00:12, 149.03it/s]\u001b[A\n",
      "1308it [00:12, 115.07it/s]\u001b[A\n",
      "1334it [00:12, 137.92it/s]\u001b[A\n",
      "1358it [00:12, 157.63it/s]\u001b[A\n",
      "1378it [00:13, 130.78it/s]\u001b[A\n",
      "1395it [00:13, 124.01it/s]\u001b[A\n",
      "1410it [00:13, 127.14it/s]\u001b[A\n",
      "1425it [00:13, 127.33it/s]\u001b[A\n",
      "1439it [00:13, 112.28it/s]\u001b[A\n",
      "1460it [00:13, 130.37it/s]\u001b[A\n",
      "1485it [00:13, 151.25it/s]\u001b[A\n",
      "1503it [00:14, 120.70it/s]\u001b[A\n",
      "1518it [00:14, 114.64it/s]\u001b[A\n",
      "1532it [00:14, 110.20it/s]\u001b[A\n",
      "1545it [00:14, 103.76it/s]\u001b[A\n",
      "1557it [00:14, 97.78it/s] \u001b[A\n",
      "1569it [00:14, 103.01it/s]\u001b[A\n",
      "1580it [00:14, 101.73it/s]\u001b[A\n",
      "1593it [00:14, 107.94it/s]\u001b[A\n",
      "1605it [00:15, 97.51it/s] \u001b[A\n",
      "1616it [00:15, 92.45it/s]\u001b[A\n",
      "1626it [00:15, 81.68it/s]\u001b[A\n",
      "1635it [00:15, 82.66it/s]\u001b[A\n",
      "1644it [00:15, 83.55it/s]\u001b[A\n",
      "1653it [00:15, 77.00it/s]\u001b[A\n",
      "1667it [00:15, 88.56it/s]\u001b[A\n",
      "1679it [00:15, 94.19it/s]\u001b[A\n",
      "1690it [00:15, 98.04it/s]\u001b[A\n",
      "1701it [00:16, 92.20it/s]\u001b[A\n",
      "1711it [00:16, 88.58it/s]\u001b[A\n",
      "1721it [00:16, 82.75it/s]\u001b[A\n",
      "1733it [00:16, 90.81it/s]\u001b[A\n",
      "1747it [00:16, 101.36it/s]\u001b[A\n",
      "1758it [00:16, 94.90it/s] \u001b[A\n",
      "1769it [00:16, 90.49it/s]\u001b[A\n",
      "1784it [00:16, 99.81it/s]\u001b[A\n",
      "1796it [00:17, 104.74it/s]\u001b[A\n",
      "1808it [00:17, 108.82it/s]\u001b[A\n",
      "1820it [00:17, 105.25it/s]\u001b[A\n",
      "1832it [00:17, 108.37it/s]\u001b[A\n",
      "1844it [00:17, 93.23it/s] \u001b[A\n",
      "1854it [00:17, 90.23it/s]\u001b[A\n",
      "1866it [00:17, 95.85it/s]\u001b[A\n",
      "1876it [00:17, 92.95it/s]\u001b[A\n",
      "1886it [00:18, 82.92it/s]\u001b[A\n",
      "1895it [00:18, 76.57it/s]\u001b[A\n",
      "1904it [00:18, 75.25it/s]\u001b[A\n",
      "1915it [00:18, 82.16it/s]\u001b[A\n",
      "1924it [00:18, 78.81it/s]\u001b[A\n",
      "1934it [00:18, 81.20it/s]\u001b[A\n",
      "1943it [00:18, 80.14it/s]\u001b[A\n",
      "1956it [00:18, 87.92it/s]\u001b[A\n",
      "1966it [00:19, 86.41it/s]\u001b[A\n",
      "1975it [00:19, 87.29it/s]\u001b[A\n",
      "1984it [00:19, 87.82it/s]\u001b[A\n",
      "1993it [00:19, 83.47it/s]\u001b[A\n",
      "2002it [00:19, 80.05it/s]\u001b[A\n",
      "2011it [00:19, 79.30it/s]\u001b[A\n",
      "2020it [00:19, 77.47it/s]\u001b[A\n",
      "2030it [00:19, 81.27it/s]\u001b[A\n",
      "2039it [00:19, 77.25it/s]\u001b[A\n",
      "2049it [00:20, 82.50it/s]\u001b[A\n",
      "2058it [00:20, 76.32it/s]\u001b[A\n",
      "2073it [00:20, 88.97it/s]\u001b[A\n",
      "2093it [00:20, 102.30it/s][A\n",
      "2it [00:41, 20.75s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "5it [00:00, 46.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Run 2 #############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "13it [00:00, 53.02it/s]\u001b[A\n",
      "32it [00:00, 66.91it/s]\u001b[A\n",
      "42it [00:00, 72.96it/s]\u001b[A\n",
      "51it [00:00, 71.82it/s]\u001b[A\n",
      "67it [00:00, 85.68it/s]\u001b[A\n",
      "82it [00:00, 97.84it/s]\u001b[A\n",
      "94it [00:00, 102.12it/s]\u001b[A\n",
      "111it [00:00, 115.49it/s]\u001b[A\n",
      "137it [00:01, 138.47it/s]\u001b[A\n",
      "165it [00:01, 162.85it/s]\u001b[A\n",
      "186it [00:01, 172.32it/s]\u001b[A\n",
      "207it [00:01, 141.16it/s]\u001b[A\n",
      "225it [00:01, 128.46it/s]\u001b[A\n",
      "241it [00:01, 103.54it/s]\u001b[A\n",
      "254it [00:02, 90.09it/s] \u001b[A\n",
      "265it [00:02, 80.44it/s]\u001b[A\n",
      "275it [00:02, 84.87it/s]\u001b[A\n",
      "285it [00:02, 86.99it/s]\u001b[A\n",
      "295it [00:02, 78.15it/s]\u001b[A\n",
      "304it [00:02, 77.08it/s]\u001b[A\n",
      "315it [00:02, 84.31it/s]\u001b[A\n",
      "325it [00:02, 85.19it/s]\u001b[A\n",
      "334it [00:03, 82.67it/s]\u001b[A\n",
      "344it [00:03, 86.85it/s]\u001b[A\n",
      "365it [00:03, 105.18it/s]\u001b[A\n",
      "393it [00:03, 128.08it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "for index, config in enumerate(config_paths):\n",
    "    extractor = LSTMExtractor(config, language, names[index], prediction_types[index], output_hidden_states=True, memory_size=memory_sizes[index])\n",
    "    print(extractor.name, ' - Extracting activations ...')\n",
    "    for run_index, iterator in tqdm(enumerate(iterator_list)):\n",
    "        print(\"############# Run {} #############\".format(run_index))\n",
    "        check_folder(saving_path_folders[index])\n",
    "        activations  = extractor.extract_activations(iterator, language)\n",
    "        \n",
    "        #transform(\n",
    "        #    activations, \n",
    "        #    saving_path_folders[index], \n",
    "        #    'activations', \n",
    "        #    run_index=run_index,\n",
    "        #    n_layers_hidden=1,\n",
    "        #    hidden_size=300)  \n",
    "        activations.to_csv(os.path.join(saving_path_folders[index], 'activations_run{}.csv'.format(run_index + 1)), index=False)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-1_wiki-kristina_english',\n",
       " 'LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-2_wiki-kristina_english',\n",
       " 'LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-3_wiki-kristina_english',\n",
       " 'LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-4_wiki-kristina_english',\n",
       " 'LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-5_wiki-kristina_english',\n",
       " 'LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-7_wiki-kristina_english',\n",
       " 'LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-10_wiki-kristina_english',\n",
       " 'LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-12_wiki-kristina_english',\n",
       " 'LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-15_wiki-kristina_english',\n",
       " 'LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-17_wiki-kristina_english',\n",
       " 'LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-20_wiki-kristina_english',\n",
       " 'LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-25_wiki-kristina_english',\n",
       " 'LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-30_wiki-kristina_english',\n",
       " 'LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-35_wiki-kristina_english',\n",
       " 'LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-40_wiki-kristina_english',\n",
       " 'LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-50_wiki-kristina_english',\n",
       " 'LSTM_embedding-size-600_nhid-300_nlayers-1_dropout-02_memory-size-inf_wiki-kristina_english']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden-layer-1-1</th>\n",
       "      <th>hidden-layer-1-2</th>\n",
       "      <th>hidden-layer-1-3</th>\n",
       "      <th>hidden-layer-1-4</th>\n",
       "      <th>hidden-layer-1-5</th>\n",
       "      <th>hidden-layer-1-6</th>\n",
       "      <th>hidden-layer-1-7</th>\n",
       "      <th>hidden-layer-1-8</th>\n",
       "      <th>hidden-layer-1-9</th>\n",
       "      <th>hidden-layer-1-10</th>\n",
       "      <th>...</th>\n",
       "      <th>hidden-layer-1-293</th>\n",
       "      <th>hidden-layer-1-294</th>\n",
       "      <th>hidden-layer-1-295</th>\n",
       "      <th>hidden-layer-1-296</th>\n",
       "      <th>hidden-layer-1-297</th>\n",
       "      <th>hidden-layer-1-298</th>\n",
       "      <th>hidden-layer-1-299</th>\n",
       "      <th>hidden-layer-1-300</th>\n",
       "      <th>surprisal</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.009343</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>0.020219</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>-0.002103</td>\n",
       "      <td>0.006810</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.456862</td>\n",
       "      <td>0.020347</td>\n",
       "      <td>0.027560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136505</td>\n",
       "      <td>-0.008620</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>0.019614</td>\n",
       "      <td>-0.019661</td>\n",
       "      <td>-0.008184</td>\n",
       "      <td>-0.002025</td>\n",
       "      <td>-0.021357</td>\n",
       "      <td>7.510410</td>\n",
       "      <td>3.288988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.059053</td>\n",
       "      <td>-0.291021</td>\n",
       "      <td>-0.023248</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>-0.010412</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>0.649610</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.011817</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006221</td>\n",
       "      <td>-0.016686</td>\n",
       "      <td>0.031706</td>\n",
       "      <td>-0.024747</td>\n",
       "      <td>-0.013827</td>\n",
       "      <td>0.022457</td>\n",
       "      <td>0.143735</td>\n",
       "      <td>-0.028213</td>\n",
       "      <td>2.280959</td>\n",
       "      <td>4.822252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003183</td>\n",
       "      <td>-0.043191</td>\n",
       "      <td>-0.005218</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.097851</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>0.073366</td>\n",
       "      <td>-0.093171</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018625</td>\n",
       "      <td>-0.016255</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>0.011992</td>\n",
       "      <td>-0.003812</td>\n",
       "      <td>-0.007940</td>\n",
       "      <td>0.048375</td>\n",
       "      <td>-0.019784</td>\n",
       "      <td>6.703503</td>\n",
       "      <td>6.749106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.075047</td>\n",
       "      <td>-0.260891</td>\n",
       "      <td>0.710530</td>\n",
       "      <td>-0.013033</td>\n",
       "      <td>-0.414856</td>\n",
       "      <td>0.008764</td>\n",
       "      <td>-0.004385</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>-0.074609</td>\n",
       "      <td>-0.011487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004501</td>\n",
       "      <td>-0.022174</td>\n",
       "      <td>0.029474</td>\n",
       "      <td>-0.000377</td>\n",
       "      <td>0.279350</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>0.232537</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>9.189131</td>\n",
       "      <td>3.540587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000112</td>\n",
       "      <td>-0.271419</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.512300</td>\n",
       "      <td>-0.001794</td>\n",
       "      <td>0.322740</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.039313</td>\n",
       "      <td>-0.039021</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043292</td>\n",
       "      <td>-0.020852</td>\n",
       "      <td>0.025520</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.059670</td>\n",
       "      <td>-0.497802</td>\n",
       "      <td>0.041170</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>0.830372</td>\n",
       "      <td>6.087246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>0.050916</td>\n",
       "      <td>-0.040301</td>\n",
       "      <td>-0.002676</td>\n",
       "      <td>-0.079301</td>\n",
       "      <td>-0.012413</td>\n",
       "      <td>-0.000150</td>\n",
       "      <td>0.019106</td>\n",
       "      <td>0.015590</td>\n",
       "      <td>-0.041344</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070237</td>\n",
       "      <td>0.211453</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>-0.428825</td>\n",
       "      <td>-0.569217</td>\n",
       "      <td>-0.261878</td>\n",
       "      <td>-0.331965</td>\n",
       "      <td>4.751386</td>\n",
       "      <td>6.544256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>-0.075146</td>\n",
       "      <td>-0.021213</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>-0.016276</td>\n",
       "      <td>-0.003278</td>\n",
       "      <td>-0.000257</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0.043155</td>\n",
       "      <td>-0.015755</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002624</td>\n",
       "      <td>0.252582</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>-0.379103</td>\n",
       "      <td>0.065756</td>\n",
       "      <td>0.127261</td>\n",
       "      <td>-0.389973</td>\n",
       "      <td>9.103417</td>\n",
       "      <td>9.232536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2527</th>\n",
       "      <td>-0.099023</td>\n",
       "      <td>-0.063729</td>\n",
       "      <td>0.020083</td>\n",
       "      <td>-0.020541</td>\n",
       "      <td>0.005853</td>\n",
       "      <td>-0.004721</td>\n",
       "      <td>0.007316</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>-0.007743</td>\n",
       "      <td>-0.001299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.137877</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>-0.001862</td>\n",
       "      <td>0.209638</td>\n",
       "      <td>0.090016</td>\n",
       "      <td>0.011607</td>\n",
       "      <td>-0.433547</td>\n",
       "      <td>10.239527</td>\n",
       "      <td>8.252920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>0.488984</td>\n",
       "      <td>0.042901</td>\n",
       "      <td>-0.002047</td>\n",
       "      <td>-0.009047</td>\n",
       "      <td>-0.086916</td>\n",
       "      <td>-0.023077</td>\n",
       "      <td>-0.424121</td>\n",
       "      <td>0.011148</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>-0.014340</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044774</td>\n",
       "      <td>0.211255</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.018582</td>\n",
       "      <td>0.088907</td>\n",
       "      <td>-0.060101</td>\n",
       "      <td>0.045650</td>\n",
       "      <td>-0.372656</td>\n",
       "      <td>8.623935</td>\n",
       "      <td>5.192456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2529</th>\n",
       "      <td>0.010765</td>\n",
       "      <td>-0.247392</td>\n",
       "      <td>0.005811</td>\n",
       "      <td>-0.018930</td>\n",
       "      <td>-0.054154</td>\n",
       "      <td>-0.000843</td>\n",
       "      <td>-0.250232</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.007293</td>\n",
       "      <td>-0.011231</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012136</td>\n",
       "      <td>0.238072</td>\n",
       "      <td>0.015314</td>\n",
       "      <td>0.008637</td>\n",
       "      <td>-0.113099</td>\n",
       "      <td>-0.149635</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>-0.405437</td>\n",
       "      <td>5.098304</td>\n",
       "      <td>7.097515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2530 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hidden-layer-1-1  hidden-layer-1-2  hidden-layer-1-3  hidden-layer-1-4  \\\n",
       "0            -0.009343          0.004728          0.020219          0.001229   \n",
       "1             0.059053         -0.291021         -0.023248         -0.000256   \n",
       "2             0.003183         -0.043191         -0.005218         -0.000076   \n",
       "3            -0.075047         -0.260891          0.710530         -0.013033   \n",
       "4             0.000112         -0.271419          0.002731         -0.000031   \n",
       "...                ...               ...               ...               ...   \n",
       "2525          0.050916         -0.040301         -0.002676         -0.079301   \n",
       "2526         -0.075146         -0.021213          0.002198         -0.016276   \n",
       "2527         -0.099023         -0.063729          0.020083         -0.020541   \n",
       "2528          0.488984          0.042901         -0.002047         -0.009047   \n",
       "2529          0.010765         -0.247392          0.005811         -0.018930   \n",
       "\n",
       "      hidden-layer-1-5  hidden-layer-1-6  hidden-layer-1-7  hidden-layer-1-8  \\\n",
       "0            -0.002103          0.006810          0.023671          0.456862   \n",
       "1            -0.010412         -0.000283          0.649610          0.002013   \n",
       "2            -0.097851          0.000788          0.073366         -0.093171   \n",
       "3            -0.414856          0.008764         -0.004385          0.008527   \n",
       "4            -0.512300         -0.001794          0.322740          0.002040   \n",
       "...                ...               ...               ...               ...   \n",
       "2525         -0.012413         -0.000150          0.019106          0.015590   \n",
       "2526         -0.003278         -0.000257          0.319500          0.043155   \n",
       "2527          0.005853         -0.004721          0.007316          0.000683   \n",
       "2528         -0.086916         -0.023077         -0.424121          0.011148   \n",
       "2529         -0.054154         -0.000843         -0.250232          0.001254   \n",
       "\n",
       "      hidden-layer-1-9  hidden-layer-1-10  ...  hidden-layer-1-293  \\\n",
       "0             0.020347           0.027560  ...           -0.136505   \n",
       "1             0.011817           0.000040  ...           -0.006221   \n",
       "2             0.028572           0.000750  ...           -0.018625   \n",
       "3            -0.074609          -0.011487  ...            0.004501   \n",
       "4             0.039313          -0.039021  ...           -0.043292   \n",
       "...                ...                ...  ...                 ...   \n",
       "2525         -0.041344           0.000258  ...           -0.070237   \n",
       "2526         -0.015755           0.000444  ...           -0.002624   \n",
       "2527         -0.007743          -0.001299  ...            0.001139   \n",
       "2528          0.004937          -0.014340  ...           -0.044774   \n",
       "2529          0.007293          -0.011231  ...           -0.012136   \n",
       "\n",
       "      hidden-layer-1-294  hidden-layer-1-295  hidden-layer-1-296  \\\n",
       "0              -0.008620           -0.000140            0.019614   \n",
       "1              -0.016686            0.031706           -0.024747   \n",
       "2              -0.016255            0.002736            0.011992   \n",
       "3              -0.022174            0.029474           -0.000377   \n",
       "4              -0.020852            0.025520            0.000300   \n",
       "...                  ...                 ...                 ...   \n",
       "2525            0.211453            0.000145            0.002055   \n",
       "2526            0.252582            0.000002            0.000143   \n",
       "2527            0.137877           -0.000093           -0.001862   \n",
       "2528            0.211255            0.000910            0.018582   \n",
       "2529            0.238072            0.015314            0.008637   \n",
       "\n",
       "      hidden-layer-1-297  hidden-layer-1-298  hidden-layer-1-299  \\\n",
       "0              -0.019661           -0.008184           -0.002025   \n",
       "1              -0.013827            0.022457            0.143735   \n",
       "2              -0.003812           -0.007940            0.048375   \n",
       "3               0.279350            0.002559            0.232537   \n",
       "4               0.059670           -0.497802            0.041170   \n",
       "...                  ...                 ...                 ...   \n",
       "2525           -0.428825           -0.569217           -0.261878   \n",
       "2526           -0.379103            0.065756            0.127261   \n",
       "2527            0.209638            0.090016            0.011607   \n",
       "2528            0.088907           -0.060101            0.045650   \n",
       "2529           -0.113099           -0.149635            0.004505   \n",
       "\n",
       "      hidden-layer-1-300  surprisal   entropy  \n",
       "0              -0.021357   7.510410  3.288988  \n",
       "1              -0.028213   2.280959  4.822252  \n",
       "2              -0.019784   6.703503  6.749106  \n",
       "3               0.002798   9.189131  3.540587  \n",
       "4               0.009986   0.830372  6.087246  \n",
       "...                  ...        ...       ...  \n",
       "2525           -0.331965   4.751386  6.544256  \n",
       "2526           -0.389973   9.103417  9.232536  \n",
       "2527           -0.433547  10.239527  8.252920  \n",
       "2528           -0.372656   8.623935  5.192456  \n",
       "2529           -0.405437   5.098304  7.097515  \n",
       "\n",
       "[2530 rows x 302 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
