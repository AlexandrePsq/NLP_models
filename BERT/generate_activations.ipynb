{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to extract hidden-states and attention heads activations from bert model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformers==3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/Volumes/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/src/lib')\n",
    "\n",
    "import glob\n",
    "import torch\n",
    "import yaml\n",
    "import gc\n",
    "import uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from model import BertExtractor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tokenizer import tokenize\n",
    "from bert_utils import set_seed\n",
    "from numpy import linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import bert_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_folder(path):\n",
    "    \"\"\"Create adequate folders if necessary.\"\"\"\n",
    "    try:\n",
    "        if not os.path.isdir(path):\n",
    "            check_folder(os.path.dirname(path))\n",
    "            os.mkdir(path)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(activations, path, name, run_index, n_layers_hidden=13, n_layers_attention=12, hidden_size=768):\n",
    "    assert activations.values.shape[1] == (n_layers_hidden + n_layers_attention) * hidden_size\n",
    "    indexes = [[index*hidden_size, (index+1)*hidden_size] for index in range(n_layers_hidden + n_layers_attention)]\n",
    "    for order in [2]:\n",
    "        matrices = []\n",
    "        for i, index in enumerate(indexes):\n",
    "            matrix = activations.values[:, index[0]:index[1]]\n",
    "            #with_std = True if order=='std' else False\n",
    "            #scaler = StandardScaler(with_mean=True, with_std=with_std)\n",
    "            #scaler.fit(matrix)\n",
    "            #matrix = scaler.transform(matrix)\n",
    "            if order is not None and order != 'std':\n",
    "                matrix = matrix / np.mean(la.norm(matrix, ord=order, axis=1))\n",
    "            matrices.append(matrix)\n",
    "        matrices = np.hstack(matrices)\n",
    "        new_data = pd.DataFrame(matrices, columns=activations.columns)\n",
    "        new_path = path + '_norm-' + str(order).replace('np.', '')\n",
    "        check_folder(new_path)\n",
    "        new_data.to_csv(os.path.join(new_path, name + '_run{}.csv'.format(run_index + 1)), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/text/english/text_english_run*.txt' # path to text input\n",
    "language = 'english'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating iterator for each run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '/Users/alexpsq/Code/Parietal/data/text_english_run*.txt' # path to text input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob.glob(template))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:00<00:00, 627750.60it/s]\n",
      "100%|██████████| 135/135 [00:00<00:00, 394586.09it/s]\n",
      "100%|██████████| 176/176 [00:00<00:00, 804136.71it/s]\n",
      "100%|██████████| 173/173 [00:00<00:00, 790429.84it/s]\n",
      "100%|██████████| 177/177 [00:00<00:00, 740171.29it/s]\n",
      "100%|██████████| 216/216 [00:00<00:00, 959713.63it/s]\n",
      "100%|██████████| 196/196 [00:00<00:00, 928908.00it/s]\n",
      "100%|██████████| 145/145 [00:00<00:00, 617435.61it/s]\n",
      "100%|██████████| 207/207 [00:00<00:00, 876990.84it/s]\n"
     ]
    }
   ],
   "source": [
    "iterator_list = [tokenize(path, language, train=False) for path in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Once , when I was six years old , I saw a magnificent picture in a book about the primeval forest called ‘ Real - life Stories . ’',\n",
       "  'It showed a boa constrictor swallowing a wild animal .',\n",
       "  'Here is a copy of the drawing .',\n",
       "  'It said in the book : “ Boa constrictors swallow their prey whole , without chewing .',\n",
       "  'Then they are not able to move , and they sleep for the six months it takes for digestion . ”',\n",
       "  'So I thought a lot about the adventures of the jungle and , in turn , I managed , with a coloured pencil , to make my first drawing .',\n",
       "  'My Drawing Number one .',\n",
       "  'It looked like this : I showed my masterpiece to the grownups and I asked them if my drawing frightened them .',\n",
       "  'They answered me : “ Why would anyone be frightened by a hat ? ”',\n",
       "  'My drawing was not of a hat .',\n",
       "  'It showed a boa constrictor digesting an elephant .',\n",
       "  'I then drew the inside of the boa constrictor , so that the grownups could understand .',\n",
       "  'They always need to have things explained .',\n",
       "  'My Drawing Number two looked like this : The grownups advised me to leave aside drawings of boa constrictors , open or closed , and to apply myself instead to geography , history , arithmetic and grammar .',\n",
       "  'Thus I abandoned , at the age of six , a magnificent career as a painter .',\n",
       "  'I was discouraged by the failure of my Drawing Number one and of my Drawing Number two .',\n",
       "  'Grownups never understand anything by themselves , and it ’ s tiresome for children to always explain things for them again and again .',\n",
       "  'So I had to choose another profession , and I learned to fly airplanes .',\n",
       "  'I flew a little in many places around the world .',\n",
       "  \"And geography , it ' s true , has served me well .\",\n",
       "  'I could recognize , at first glance , China from Arizona .',\n",
       "  'It ’ s very useful if you get lost at night .',\n",
       "  'I have had , during my life , a lot of contact with many persons of consequence .',\n",
       "  'I have lived a lot amongst the grownups .',\n",
       "  'I have seen them from close up .',\n",
       "  'It hasnt much improved my opinion of them .',\n",
       "  \"Whenever I met one of them that seemed a bit more clear - sighted , I tried the experiment of showing them my Drawing Number one , that I ' ve always kept .\",\n",
       "  'I wanted to know if they were really a person of true understanding .',\n",
       "  \"But they always responded : “ It ' s a hat . ”\",\n",
       "  'So I would never speak to them of boa constrictors , nor of primeval forests , nor of the stars .',\n",
       "  'I put myself at their level .',\n",
       "  'I talked to them about bridge , golf , politics and neckties .',\n",
       "  'And the grownup was glad to know such a sensible man .',\n",
       "  'So I lived alone , without anyone I could really talk to , until a breakdown in the Sahara desert , six years ago .',\n",
       "  'Something had broken in my engine .',\n",
       "  'And as I had with me neither a mechanic nor any passengers , I readied myself to try and carry out , all alone , the difficult repairs .',\n",
       "  'For me it was a matter of life or death .',\n",
       "  'I had hardly enough water to drink for a week .',\n",
       "  'The first night I went to sleep on the sand , a thousand miles from any human habitation .',\n",
       "  'I was more isolated than a shipwrecked sailor on a raft in the middle of the ocean .',\n",
       "  'So you can imagine my surprise when at daybreak , a funny little voice woke me up .',\n",
       "  'It said : “ Please ...',\n",
       "  'draw me a sheep ! ”',\n",
       "  '“ What ? ”',\n",
       "  '“ Draw me a sheep ! ”',\n",
       "  'I jumped to my feet as if I ’ d been struck by lightning .',\n",
       "  'I rubbed my eyes .',\n",
       "  'I took a good look around me .',\n",
       "  'And I saw a quite extraordinary little man , who was examining me seriously .',\n",
       "  'Here is the best portrait that , later , I managed to do of him .',\n",
       "  'But my drawing , of course , is much less charming than its model .',\n",
       "  \"It ' s not my fault .\",\n",
       "  \"I was discouraged in my career as a painter by the grownups , at the age of six , and I hadn ' t learned to draw anything except boa constrictors , closed and open .\",\n",
       "  'I stared at this sudden apparition wide eyed with astonishment .',\n",
       "  'Remember that I was a thousand miles from any inhabited region .',\n",
       "  'And yet this little fellow seemed neither lost , nor half - dead with fatigue , nor starved or dying of thirst or fear .',\n",
       "  'He looked nothing like a child lost in the middle of the desert , a thousand miles from any inhabited region .',\n",
       "  'When I finally managed to speak , I said : “ But — what are you doing here ? ”',\n",
       "  'And he repeated , very slowly , as if it was something very serious : “ Please ...',\n",
       "  'draw me a sheep ... ”',\n",
       "  'When a mystery is too overpowering , one dare not disobey .',\n",
       "  'Absurd as it seemed to me a thousand miles from any human habitation and in danger of death , I took out of my pocket a sheet of paper and a pen .',\n",
       "  'But then I remembered that I had mainly studied geography , history , arithmetic and grammar , and I told the little fellow ( a little crossly ) that I didn ’ t know how to draw .',\n",
       "  \"He replied : “ It doesn ' t matter .\",\n",
       "  'Draw me a sheep . ”',\n",
       "  'As I ’ d never drawn a sheep , I redrew for him one of the only two drawings that I was capable of .',\n",
       "  'The one of the closed boa constrictor .',\n",
       "  'And I was astounded to hear the little fellow respond : “ No !',\n",
       "  'No !',\n",
       "  'I don ’ t want an elephant inside a boa constrictor .',\n",
       "  'A boa constrictor is very dangerous , and an elephant is very cumbersome .',\n",
       "  'Where I live everything is very small .',\n",
       "  'I need a sheep .',\n",
       "  'Draw me a sheep . ”',\n",
       "  'So I drew .',\n",
       "  'He looked carefully , then said : “ No !',\n",
       "  'This one ’ s already very sick .',\n",
       "  'Make another one . ”',\n",
       "  'I drew again : My friend smiled gently and indulgently : “ You can see yourself ...',\n",
       "  \"this isn ’ t a sheep , it ' s a ram .\",\n",
       "  'It has horns ...',\n",
       "  '“ So once again I redid my drawing : But it was rejected , like the previous ones : “ This one ’ s too old .',\n",
       "  'I want a sheep that will live a long time . ”',\n",
       "  'So , getting impatient , as I was eager to start dismantling my engine , I hastily sketched this drawing : And I snapped : “ This here is the box .',\n",
       "  'The sheep you want is inside . ”',\n",
       "  \"But I was very surprised to see the face of my young judge light up : “ It ' s exactly the way I wanted !\",\n",
       "  'Do you think this sheep needs a lot of grass ? ”',\n",
       "  '“ Why ? ”',\n",
       "  \"“ Because where I ' m from everything is very small ... ”\",\n",
       "  '“ There will certainly be enough .',\n",
       "  'I gave you a very small sheep . ”',\n",
       "  'He leaned his head towards the drawing : “ Not that small ...',\n",
       "  'Look !',\n",
       "  \"He ' s fallen asleep ... ”\",\n",
       "  \"And that ' s how I met the little prince .\",\n",
       "  'It took me a long time to find out where he came from .',\n",
       "  'The little prince , who asked me many questions , never seemed to hear my own .',\n",
       "  'It was the words spoken by chance that , little by little , revealed everything to me .',\n",
       "  \"So , when he saw my airplane for the first time ( I won ’ t draw my airplane , it would be a drawing far too complicated for me ) , he asked me : “ What ' s that thing there ? ”\",\n",
       "  \"“ It ' s not a thing .\",\n",
       "  'It flies .',\n",
       "  \"It ' s an airplane .\",\n",
       "  'It ’ s my airplane . ”',\n",
       "  'And I was proud to have him know that I could fly .',\n",
       "  'Then he cried : “ What ?',\n",
       "  'You fell from the sky ! ”',\n",
       "  '“ Yes , ” I said modestly .',\n",
       "  '“ Oh !',\n",
       "  \"That ' s funny !\",\n",
       "  '... ”',\n",
       "  'And the little prince broke into a lovely peal of laughter , which irritated me very much .',\n",
       "  'I prefer people to take my misfortunes seriously .',\n",
       "  'Then he added : “ So , you also come from the sky !',\n",
       "  'What planet are you from ? ”',\n",
       "  'I caught a glimpse into the mystery of his presence , and I asked abruptly : “ So you come from another planet then ? ”',\n",
       "  'But he didn ’ t answer .',\n",
       "  \"He shook his head slowly whilst looking at my airplane : “ It ' s true that you can ' t have come from far away in that thing ... ”\",\n",
       "  'And he drifted into a daydream which lasted a long while .',\n",
       "  'Then , taking my sheep out of his pocket , he sank himself into the contemplation of his treasure .',\n",
       "  'You can imagine how my curiosity was aroused by this small disclosure about ‘ the other planets . ’',\n",
       "  'So I tried to find out more : “ Where are you from my little fellow ?',\n",
       "  'Where ’ s this ‘ where I live ’ of yours ?',\n",
       "  'Where do you take my sheep off to ? ”',\n",
       "  \"After a reflective silence he answered : “ What ' s good about the box you ’ ve given me is that at night , he can use it as a house . ”\",\n",
       "  '“ That ’ s right .',\n",
       "  \"And if you ’ re good , I ' ll give you a rope to tie him up with during the day .\",\n",
       "  'And a stake . ”',\n",
       "  'The offer seemed to shock the little prince : “ Tie him up ?',\n",
       "  'What a funny idea ! ”',\n",
       "  \"“ But if you don ' t tie him up , he ’ ll wander off , and get lost . ”\",\n",
       "  'My friend broke into another peal of laughter : “ Where do you think he ’ d go ! ”',\n",
       "  '“ Anywhere .',\n",
       "  'Straight ahead ... ”',\n",
       "  'Then the little prince said gravely : “ That doesn ’ t matter ; where I live , everything is so small ! ”',\n",
       "  \"And perhaps with a hint of sadness , he added : “ Straight ahead you can ' t go far ... ”\"],\n",
       " ['I thus learned a second very important thing : that his home planet was barely bigger than a house !',\n",
       "  \"It didn ' t surprise me much .\",\n",
       "  'I knew that , apart from the large planets like the Earth , Jupiter , Mars , and Venus , which have been given names , there are hundreds of others that are sometimes so small that one has great difficulty in spotting them through the telescope .',\n",
       "  'When an astronomer discovers one of these , he gives it a number for a name .',\n",
       "  'He might call it for example “ asteroid three hundred and twenty - five . ”',\n",
       "  'I have serious reason to believe that the planet from where the little prince came is the asteroid B - six hundred and twelve .',\n",
       "  'This asteroid has only been seen through a telescope once , in one thousand , nine hundred and nine , by a Turkish astronomer .',\n",
       "  'He had then given a big presentation on his discovery at an international astronomy conference .',\n",
       "  'But nobody had believed him because of his outfit .',\n",
       "  'Grownups are like that .',\n",
       "  'Fortunately for the reputation of Asteroid B - six hundred and twelve , a Turkish dictator imposed on his people , on pain of death , to dress themselves in the European fashion .',\n",
       "  'The astronomer gave his presentation again in one thousand , nine hundred and twenty , dressed very stylishly .',\n",
       "  'And this time everybody believed him .',\n",
       "  'If I have told you these details about the asteroid B - six hundred and twelve , and revealed to you its number , it ’ s because of the grownups .',\n",
       "  'Grownups love numbers .',\n",
       "  'When you talk to them about a new friend , they never ask you about any of the important things .',\n",
       "  'They never ask you : “ How does his voice sound ?',\n",
       "  'What games does he like best ?',\n",
       "  'Does he collect butterflies ? ”',\n",
       "  'They ask : “ How old is he ?',\n",
       "  'How many brothers does he have ?',\n",
       "  'How much does he weigh ?',\n",
       "  'How much money does his father make ? ”',\n",
       "  'Only then do they think they know him .',\n",
       "  'If you said to the grownups : “ I saw a beautiful red brick house with geraniums by the windows and doves on the roof ...',\n",
       "  ', ” they wouldn ’ t be able to picture this house in their minds .',\n",
       "  'You ’ d have to tell them : “ I saw a hundred thousand franc house . ”',\n",
       "  'And they ’ d cry : “ How pretty ! ”',\n",
       "  'So if you were to say to them : “ The proof that the little prince existed is that he was charming , he laughed , and he wanted a sheep .',\n",
       "  'If someone wants a sheep , that proves they exist , ” they ’ d shrug their shoulders and treat you like a child .',\n",
       "  'But if you were to say : “ The planet he came from is the Asteroid B - six hundred and twelve ” , they ’ d be convinced , and leave you in peace and spare you their questions .',\n",
       "  'They ’ re like that .',\n",
       "  'Don ’ t blame them .',\n",
       "  'Children should be forgiving towards the grownups .',\n",
       "  \"But , of course , those of us who understand life , we don ' t much care for numbers !\",\n",
       "  'I ’ d have liked to begin this story in the same way as a fairy tale .',\n",
       "  'I ’ d have liked to say : “ Once upon a time , there was a little prince who lived on a planet not much bigger than himself , and who needed a friend ... ”',\n",
       "  'For those who understand life , it would have seemed much more natural .',\n",
       "  'For I don ’ t want my book to be read lightly .',\n",
       "  'I feel so much sadness in recounting these memories .',\n",
       "  \"It ' s already been six years since my friend left with his sheep .\",\n",
       "  'If I try to describe him here , it ’ s so as not to forget him .',\n",
       "  'It ’ s sad to forget a friend .',\n",
       "  'Not everyone has had a friend .',\n",
       "  'And if I forgot him , I could become like the grownups who are only interested in numbers .',\n",
       "  'So that ’ s why I have again bought a box of paints and some pencils .',\n",
       "  \"It ' s hard to take up drawing again at my age , when I have only ever attempted to draw a boa constrictor , closed and open , at the age of six !\",\n",
       "  \"I ' ll try , of course , to make my portraits as lifelike as possible .\",\n",
       "  \"But I ’ m not quite sure I ' ll succeed .\",\n",
       "  'Some drawings go alright ; others don ’ t look like their subjects .',\n",
       "  'I also get the size a bit wrong .',\n",
       "  'Here the little prince is too big .',\n",
       "  'There he ’ s too small .',\n",
       "  'I ’ m also not sure about the colour of his outfit .',\n",
       "  'So I fumble along somehow , as best I can .',\n",
       "  'I will make mistakes on certain important points too .',\n",
       "  'But you ’ ll have to forgive me that .',\n",
       "  'My friend never gave explanations .',\n",
       "  'Perhaps he thought I was just like himself .',\n",
       "  \"But I , unfortunately , don ' t know how to see sheep through boxes .\",\n",
       "  'Perhaps I ’ m a bit like the grownups .',\n",
       "  'I must have got older .',\n",
       "  'Every day I ’ d learn something about his planet , the departure , and the trip .',\n",
       "  'The information came slowly , as his thoughts wandered .',\n",
       "  'It was in this way that , on the third day , I came to know of the tragedy of the baobabs .',\n",
       "  'This time again it was thanks to the sheep , because the little prince asked me abruptly , as if seized by a grave doubt : “ It ’ s true , isn ’ t it , that sheep eat shrubs ? ”',\n",
       "  '“ Yes .',\n",
       "  \"It ' s true . ”\",\n",
       "  '“ Oh !',\n",
       "  'I am glad ! ”',\n",
       "  'I didn ’ t understand why it was so important that sheep eat shrubs .',\n",
       "  'But the little prince added : “ Then it follows they also eat baobabs ? ”',\n",
       "  \"I pointed out to the little prince that baobabs were not shrubs , but trees as big as churches , and that even if he took with him a whole herd of elephants , the herd wouldn ' t manage to eat up one single baobab .\",\n",
       "  'The idea of the herd of elephants made the little prince laugh : “ They ’ d have to be piled up on top of each other ... ”',\n",
       "  'But he remarked wisely : “ The baobab trees , before they grow up , start off small . ”',\n",
       "  \"“ That ' s right !\",\n",
       "  'But why do you want the sheep to eat the little baobabs ? ”',\n",
       "  'He replied : “ Oh , come on ! ”',\n",
       "  'as if it were obvious .',\n",
       "  'And it took me a great mental effort to understand this problem on my own , without any help .',\n",
       "  'And indeed , on the planet of the little prince there were , like on all planets , both good plants and bad plants .',\n",
       "  'And therefore , both good seeds from good plants and bad seeds from bad plants .',\n",
       "  'But seeds are invisible .',\n",
       "  'They sleep secretly deep in the earth until , on a whim , one of them decides to wake up .',\n",
       "  'Then it elongates and grows , timidly at first , toward the sun : a charming little harmless sprig .',\n",
       "  'If it ’ s a sprig of radish or rose bush , you can let it grow as it likes .',\n",
       "  'But if it ’ s a bad plant , one must pull the plant out straight away , as soon as it can be recognised .',\n",
       "  'Now there were some terrible seeds on the planet of the little prince ...',\n",
       "  'there were the seeds of baobab trees .',\n",
       "  'The soil of the planet was infested with them .',\n",
       "  'A baobab , if you get to it too late , can never be got rid of .',\n",
       "  'It takes over the entire planet .',\n",
       "  'It pierces it with its roots .',\n",
       "  'And if the planet is too small , and if there are too many baobabs , they shatter it to pieces .',\n",
       "  \"“ It ' s a matter of discipline , ” the little prince told me later .\",\n",
       "  '“ After grooming oneself in the morning , the planet must be carefully groomed .',\n",
       "  'You must see to it that you regularly pull out the baobabs as soon as they can be told apart from the rose bushes , to which they look very similar when they ’ re very young .',\n",
       "  \"It ' s a very boring job , but very easy . ”\",\n",
       "  'And one day he suggested that I apply myself to making a beautiful drawing , so that the children from where I come from would understand all this .',\n",
       "  '“ If one day they travel , ” he said to me , “ it could come in useful .',\n",
       "  \"Sometimes there ’ s no harm in postponing one ' s work .\",\n",
       "  'But in the case of baobabs , that always leads to a catastrophe .',\n",
       "  'I used to know a planet inhabited by a lazy man .',\n",
       "  'He had neglected three little bushes ... ”',\n",
       "  'And based on what the little prince told me , I drew this planet .',\n",
       "  'I don ’ t like to sound like a moralist .',\n",
       "  'But the danger of the baobabs is so little understood , and the risks run by anyone who might get lost on an asteroid are so large that , for once , I am breaking my normal reserve .',\n",
       "  'I say : “ Children !',\n",
       "  'Beware of baobabs ! ”',\n",
       "  \"It ’ s to warn my friends of the danger they ' ve long been skirting , like myself , without knowing it , that I have worked so hard on this drawing .\",\n",
       "  'The lesson which I pass on by this means was worth the effort .',\n",
       "  \"You might be wondering : Why is it that in this book there aren ' t any other drawings as impressive as the drawing of the baobabs ?\",\n",
       "  'The answer is simple : I tried but I couldn ’ t succeed .',\n",
       "  'When I drew the baobabs I was spurred on by a sense of urgency .',\n",
       "  'Oh !',\n",
       "  'Little prince , I came to understand , gradually , in this way , your sad life .',\n",
       "  'For a long time your only entertainment was the softness of the sunsets .',\n",
       "  'I learned this new detail on the fourth day , in the morning , when you said to me : “ I ’ m very fond of sunsets .',\n",
       "  'Let ’ s go and see a sunset now ... ”',\n",
       "  '“ But we have to wait ... ”',\n",
       "  '“ Wait for what ? ”',\n",
       "  '“ Wait until the sun goes down . ”',\n",
       "  'You seemed surprised at first , and then you chuckled at yourself .',\n",
       "  'And you said : “ I think myself at home still ! ”',\n",
       "  'Indeed .',\n",
       "  'When it ’ s noon in the United States , the sun , everybody knows , is setting over France .',\n",
       "  'It would suffice to be able to go to France in one minute to be able to see a sunset .',\n",
       "  'Unfortunately , France is much too far away .',\n",
       "  'But on your tiny planet , all you needed was to move your chair a few steps .',\n",
       "  'And you watched the twilight falling whenever you liked ...',\n",
       "  'One day I saw the sunset forty - four times !',\n",
       "  'And a little later you added : “ You know ...',\n",
       "  'you love the sunset , when you ’ re really sad ... ”',\n",
       "  '“ The day you saw it forty - four times , were you were really that sad then ? ”',\n",
       "  'But the little prince made no reply .'],\n",
       " [\"On the fifth day , again thanks to the sheep , this secret of the little prince ' s life was revealed to me .\",\n",
       "  'He asked abruptly , without anything leading up to it , as if it was the result of a long silent meditation on a problem : “ If a sheep eats shrubs , then does it eat flowers too : “ A sheep eats everything it finds . ”',\n",
       "  '“ Even flowers that have thorns ? ”',\n",
       "  '“ Yes , even flowers that have thorns . ”',\n",
       "  '“ What are the thorns for then ? ”',\n",
       "  \"I didn ' t know the answer .\",\n",
       "  'I was very busy trying to unscrew a bolt in my engine that had got stuck .',\n",
       "  'I was very worried because my breakdown was beginning to appear to be very serious , and I had so little drinking water left that I had to fear the worst .',\n",
       "  '“ What are the thorns for then ? ”',\n",
       "  'The little prince never let go of a question , once he had asked it .',\n",
       "  'I was upset over the bolt and I said the first thing that came into my head : “ The thorns are of no use at all .',\n",
       "  'Flowers have thorns just for spite ! ”',\n",
       "  '“ Oh ! ”',\n",
       "  'But after a moment of silence , he exclaimed with a sort of resentment : “ I don ’ t believe you !',\n",
       "  'Flowers are weak creatures .',\n",
       "  'They ’ re naive .',\n",
       "  'They reassure themselves as best they can .',\n",
       "  'They think themselves frightful with their thorns ... ”',\n",
       "  'I made no reply .',\n",
       "  \"At that moment I was thinking to myself : “ If this bolt won ’ t budge , I ' ll knock it out with a hammer . ”\",\n",
       "  'The little prince interrupted my thoughts again : “ And you actually believe that flowers — ” “ No !',\n",
       "  'No !',\n",
       "  'I don ’ t believe it at all !',\n",
       "  'I answered the first thing that came to my mind .',\n",
       "  'I , myself , am busy with matters of consequence ! ”',\n",
       "  'He looked at me dumbfounded .',\n",
       "  '“ Matters of consequence ! ”',\n",
       "  'He watched me , hammer in hand and my fingers black with grease , leaning on an object that would have seemed to him very ugly .',\n",
       "  '“ You talk just like the grownups ! ”',\n",
       "  'That made me feel a little ashamed .',\n",
       "  'But he went on relentlessly : “ You confuse everything ...',\n",
       "  'you mix everything up ! ”',\n",
       "  'He was really very angry .',\n",
       "  'He shook his golden curls in the breeze : “ I know a planet where there is a red faced gentleman .',\n",
       "  'He has never smelled a flower .',\n",
       "  'He has never looked at a star .',\n",
       "  'He has never loved anyone .',\n",
       "  'He has never done anything but sums .',\n",
       "  'And all day long he repeats just like you : ‘ I am busy with matters of consequence ! ’',\n",
       "  'And that makes him swell up with pride .',\n",
       "  'But this is not a man , he ’ s a mushroom ! ”',\n",
       "  '“ A what ? ”',\n",
       "  '“ A mushroom ! ”',\n",
       "  'The little prince was now white with rage .',\n",
       "  '“ Flowers have been growing thorns for millions of years .',\n",
       "  'For millions of years , the sheep have eaten the flowers all the same .',\n",
       "  \"And it ' s not a matter of consequence to try to understand why they take so much trouble to grow thorns which are never of any use ?\",\n",
       "  'Is the war between the flowers and sheep not important ?',\n",
       "  'Is it not of more consequence and more important than the sums of a fat red faced gentleman ?',\n",
       "  \"And if I myself know of a unique flower , which grows nowhere but on my planet , that a little sheep can destroy in one stroke , just like that , one morning , without realising what he ' s done , is that not important ! ”\",\n",
       "  'He blushed , and continued : “ If someone loves a flower of which just one specimen exists amongst the millions and millions of stars , it ’ s enough to make him happy when he looks at them .',\n",
       "  'He can say : ‘ My flower is out there somewhere ... ’',\n",
       "  'But if the sheep eats the flower , for him it ’ s as if suddenly all the stars have gone out !',\n",
       "  'And you think that ’ s not important !',\n",
       "  'He couldn ’ t say anything more .',\n",
       "  'He suddenly burst into tears .',\n",
       "  'Night had fallen .',\n",
       "  'I had put down my tools .',\n",
       "  'Of what moment was my hammer , my bolt , or thirst , or death ?',\n",
       "  'There was on a star , on a planet , my planet , Earth , a little prince to be comforted !',\n",
       "  'I took him in my arms .',\n",
       "  'I rocked him .',\n",
       "  'I said : “ The flower that you love isn ’ t in danger ...',\n",
       "  'I ’ ll draw you a muzzle for your sheep ...',\n",
       "  \"I ' ll draw you a railing for your flower ...\",\n",
       "  'I ... ”',\n",
       "  \"I wasn ' t sure what to say .\",\n",
       "  'I felt very awkward .',\n",
       "  'I didn ’ t know how to reach him , where to find him ...',\n",
       "  \"It ' s so secretive , the land of tears .\",\n",
       "  'I learned very quickly to know this flower better .',\n",
       "  \"There had always been very simple flowers on the planet of the little prince , decorated with a single row of petals , that didn ' t take up any space , and didn ’ t bother anyone .\",\n",
       "  'They would appear one morning in the grass , and by evening they ’ d have faded away .',\n",
       "  'But this one had sprouted one day , from a seed blown in from no one knows where , and the little prince had watched very closely this sprout that was not like the other sprouts .',\n",
       "  'It could have been a new kind of baobab .',\n",
       "  'But the shrub soon stopped growing and began to produce a flower .',\n",
       "  'The little prince , who witnessed the appearance of a huge bud , felt that a miraculous apparition must emerge from it , but the flower never stopped preparing for her future beauty , safe in her green chamber .',\n",
       "  'She chose her colours carefully .',\n",
       "  'She dressed slowly ; she arranged her petals one by one .',\n",
       "  'She did not want to come out all rumpled , like the poppies .',\n",
       "  'She would only want to appear in the full radiance of her beauty .',\n",
       "  'Oh yes !',\n",
       "  'She was a very flirtatious creature !',\n",
       "  'And her mysterious adornment had thus lasted for days and days .',\n",
       "  'Then one morning , exactly at sunrise , she suddenly showed herself .',\n",
       "  'And , after having worked with such care and attention to detail , she said with a yawn : “ Oh !',\n",
       "  'I have only just woken up ...',\n",
       "  'I do apologize ...',\n",
       "  'I am not yet presentable ” The little prince couldn ’ t restrain his admiration : “ You ’ re so beautiful ! ”',\n",
       "  '“ Am I not ? ”',\n",
       "  'the flower responded , sweetly .',\n",
       "  '“ And I was born at the same moment as the sun ...',\n",
       "  '” The little prince guessed easily enough that she was not very modest , but how moving she was !',\n",
       "  \"“ It ' s time , I think , for breakfast , ” she added an instant later , “ If you would have the kindness to think of my needs .\",\n",
       "  'And the little prince , completely abashed , having gone to look for a sprinkling can of fresh water , tended to the flower .',\n",
       "  'And like that , she had soon begun to torment him with her vanity .',\n",
       "  'One day , for example , speaking of her four thorns , she told the little prince : “ Let them come , the tigers , with their claws ! ”',\n",
       "  '“ There aren ’ t any tigers on my planet , ” the little prince objected , “ and tigers don ’ t eat weeds . ”',\n",
       "  '“ I am not a weed , ” the flower replied sweetly .',\n",
       "  '“ Please forgive me ...',\n",
       "  '“ I do not fear tigers , but I detest drafts .',\n",
       "  \"You wouldn ' t happen to have a screen ? ”\",\n",
       "  '“ Detests drafts ...',\n",
       "  'that ’ s bad luck for a plant , ” remarked the little prince .',\n",
       "  '“ What a very complicated flower .',\n",
       "  '“ In the evening you will put me under a glass dome .',\n",
       "  'It is very cold where you live .',\n",
       "  'Where I come from ... ”',\n",
       "  'But she interrupted herself .',\n",
       "  'She had come in the form of a seed .',\n",
       "  'She couldn ’ t have known anything of other worlds .',\n",
       "  'Humiliated at having been caught out on a lie so naive , she coughed two or three times to imply the little prince was in the wrong .',\n",
       "  '“ The screen ...',\n",
       "  '? ”',\n",
       "  '“ I was just going to look for it when you spoke to me ! ”',\n",
       "  'Then she forced a cough to inflict still more remorse .',\n",
       "  'So the little prince , despite the good will of his love , had soon come to doubt her .',\n",
       "  'He had taken seriously words of no importance , and had become very unhappy .',\n",
       "  '“ I shouldn ’ t have listened to her , ” he told me one day , “ you should never listen to the flowers .',\n",
       "  'We must look at them and breathe their fragrance .',\n",
       "  'Mine perfumed my whole planet , but I didn ’ t know how to take pleasure in it .',\n",
       "  \"This business of the claws , which annoyed me so much , should only have filled my heart with tenderness and pity ” He continued his confidences : “ I didn ' t know how to understand !\",\n",
       "  'I should have her judged by her deeds and not by her words .',\n",
       "  'She overwhelmed me with her fragrance and light .',\n",
       "  'I should never have run away !',\n",
       "  'I should have seen the tenderness behind her contrivances .',\n",
       "  'Flowers are so contradictory !',\n",
       "  'But I was too young to know how to love her . ”',\n",
       "  'I think that for his escape he took advantage of a migration of a flock of wild birds .',\n",
       "  'On the morning of his departure he put his planet in perfect order .',\n",
       "  'He carefully swept out his active volcanoes .',\n",
       "  'He owned two active volcanoes ; it was very convenient for heating his breakfast in the morning .',\n",
       "  'He also owned an extinct volcano .',\n",
       "  'But , as he used to say , “ You never know ! ”',\n",
       "  'So he cleaned out the extinct volcano , too .',\n",
       "  'If they are well cleaned out , volcanoes burn slowly and steadily , without any eruptions .',\n",
       "  'Volcanic eruptions are like fires in a chimney .',\n",
       "  \"On our earth we ' re obviously much too small to clean out our volcanoes .\",\n",
       "  'That ’ s why they cause us no end of trouble .',\n",
       "  'The little prince also pulled up , with a hint of sadness , the last little shoots of the baobabs .',\n",
       "  'He believed he would never return .',\n",
       "  'But all these familiar tasks seemed , on that morning , very precious .',\n",
       "  'And as he watered the flower one last time , and prepared to shelter her under her dome , he found himself close to tears .',\n",
       "  '“ Goodbye , ” he said to the flower .',\n",
       "  'But she didn ’ t answer .',\n",
       "  '“ Goodbye , ” he said again .',\n",
       "  'The flower coughed .',\n",
       "  'But it was not because she had a cold .',\n",
       "  '“ I was silly , ” she said finally .',\n",
       "  '“ I ask your forgiveness .',\n",
       "  'Try to be happy . ”',\n",
       "  'He was surprised by this absence of reproaches .',\n",
       "  'He stood there all bewildered , the dome held in mid - air .',\n",
       "  'He didn ’ t understand this quiet sweetness .',\n",
       "  '“ Of course I love you , ” the flower said to him .',\n",
       "  '“ It ’ s my fault that you didn ’ t know .',\n",
       "  'That is of no importance .',\n",
       "  'But you have been just as foolish as I have .',\n",
       "  'Try to be happy ...',\n",
       "  'Let the dome be .',\n",
       "  'I do not want it anymore . ”',\n",
       "  '“ But the wind — ” “ My cold is not all that bad ...',\n",
       "  'The cool night air will do me good .',\n",
       "  'I am a flower . ”',\n",
       "  '“ But the animals — ” “ I will have to endure two or three caterpillars if I wish to become acquainted with the butterflies .',\n",
       "  'It seems that they are very beautiful .',\n",
       "  'And otherwise who else will come to visit me ?',\n",
       "  'You will be far away .',\n",
       "  'As for the large animals , I am not at all afraid of anything .',\n",
       "  'I have my claws . ”',\n",
       "  'And , naively , she showed her four thorns .',\n",
       "  \"Then she added : “ Don ' t linger like this , it ’ s tiresome .\",\n",
       "  'You have decided to leave .',\n",
       "  'Now go ! ”',\n",
       "  'For she did not want him to see her crying .',\n",
       "  'She was such a proud flower ...'],\n",
       " ['He found himself in the neighborhood of the asteroids three two five , three two six , three two seven , three two eight , three two nine , and three three zero .',\n",
       "  'So he began by visiting them to learn more .',\n",
       "  'The first one was inhabited by a king .',\n",
       "  'The king was sitting , dressed in purple and ermine , on a very simple yet majestic throne .',\n",
       "  '“ Ah !',\n",
       "  'Here comes a subject , ” exclaimed the king , when he caught sight of the little prince .',\n",
       "  'And the little prince asked himself : “ How could he recognise me when he ’ s never seen me before ? ”',\n",
       "  'He didn ’ t know that for Kings , the world is very much simplified .',\n",
       "  'To them , all men are subjects .',\n",
       "  '“ Approach , so that I may see you better , ” said the king , who was very proud to finally be king over somebody .',\n",
       "  'The little prince looked around him for a place to sit , but the planet was completely taken over by the magnificent ermine robe .',\n",
       "  'So he remained standing , and , since he was tired , he yawned .',\n",
       "  '“ It is contrary to etiquette to yawn in the presence of a king , ” the monarch said to him .',\n",
       "  '“ I forbid you to do so . ”',\n",
       "  \"“ I can ' t stop myself , ” replied the little prince , thoroughly embarrassed .\",\n",
       "  '“ I ve come on a long journey , and I haven ’ t slept ... ”',\n",
       "  '“ Ah , then , ” the king said .',\n",
       "  '“ I order you to yawn .',\n",
       "  'I have not seen anyone yawning for years .',\n",
       "  'Yawns , to me , are objects of curiosity .',\n",
       "  'Come , now !',\n",
       "  'Yawn again !',\n",
       "  'It is an order . ”',\n",
       "  '“ That frightens me ...',\n",
       "  'I can ’ t any more ... ”',\n",
       "  'said the little prince , blushing .',\n",
       "  '“ Hum !',\n",
       "  'Hum ! ”',\n",
       "  'replied the king .',\n",
       "  '“ Then I — I order you sometimes to yawn and sometimes to — ” He sputtered a bit , and seemed vexed .',\n",
       "  'For the king fundamentally insisted that his authority be respected .',\n",
       "  'He didn ’ t tolerate disobedience .',\n",
       "  'He was an absolute monarch .',\n",
       "  'But , because he was good at heart , he gave reasonable orders .',\n",
       "  '“ If I ordered a general , ” he would often say , “ if I ordered a general to change himself into a seabird , and if the general did not obey me , it would not be the general ’ s fault .',\n",
       "  'It would be my fault . ”',\n",
       "  '“ May I sit down ? ”',\n",
       "  'the little prince enquired timidly .',\n",
       "  '“ I order you to sit down , ” replied the king , who majestically gathered in a fold of his ermine mantle .',\n",
       "  'But the little prince was astonished .',\n",
       "  'The planet was tiny .',\n",
       "  'Over what could this king really rule ?',\n",
       "  '“ Sire , ” he said to him , “ excuse my asking you a question — ” “ I order you to ask me a question , ” hastened to say the king .',\n",
       "  '“ Sire ...',\n",
       "  'over what do you rule ? ”',\n",
       "  '“ Over everything , ” said the king , with a magnificent simplicity .',\n",
       "  '“ Over everything ? ”',\n",
       "  'The king made a subtle gesture , pointing out his planet , the other planets and the stars .',\n",
       "  '“ Over all that ? ”',\n",
       "  'asked the little prince .',\n",
       "  '“ Over all that , ” the king answered .',\n",
       "  'For his rule was not only absolute : it was also universal .',\n",
       "  '“ And the stars obey you ? ”',\n",
       "  '“ Of course , ” the king said .',\n",
       "  '“ They obey instantly .',\n",
       "  'I do not tolerate insubordination . ”',\n",
       "  'Such power filled the little prince with wonder .',\n",
       "  'If he had held it himself , he would ’ ve been able to watch , not forty - four , but seventy - two , or even a hundred , or even two hundred sunsets on the same day , without ever having to move his chair !',\n",
       "  'And as he felt a bit sad as he remembered his forsaken little planet , he plucked up his courage to ask the king a favour : “ I ’ d like to see a sunset ...',\n",
       "  'Do that for me ...',\n",
       "  'Order the sun to set ... ”',\n",
       "  '“ If I ordered a general to fly from one flower to another like a butterfly , or to write a tragic drama , or to change himself into a sea bird , and if the general did not carry out the order received , which one of us would be in the wrong ?',\n",
       "  '” You , ” said the little prince firmly .',\n",
       "  '“ Exactly .',\n",
       "  'One must ask of each person that which they can give , ” the king went on .',\n",
       "  '“ Authority is based above all on reason .',\n",
       "  'If you ordered your people to go and throw themselves into the sea , they would rise up in revolution .',\n",
       "  'I have the right to demand obedience because my orders are reasonable . ”',\n",
       "  '“ Then my sunset ? ”',\n",
       "  'the little prince reminded him , who never forgot a question once he had asked it .',\n",
       "  '“ You shall have your sunset .',\n",
       "  'I shall command it .',\n",
       "  'But I shall wait , according to my science of government , until conditions are favourable . ”',\n",
       "  '“ When will that be ? ”',\n",
       "  'inquired the little prince .',\n",
       "  '“ Hum !',\n",
       "  'hum ! ”',\n",
       "  'replied the king , who consulted a bulky almanac .',\n",
       "  '“ Hum !',\n",
       "  'Hum !',\n",
       "  'That will be about — about — that will be this evening about twenty minutes to eight .',\n",
       "  'And you will see how well I am obeyed ! ”',\n",
       "  'The little prince yawned .',\n",
       "  'He was regretting his lost sunset .',\n",
       "  'And then he was already getting a little bored .',\n",
       "  \"“ I ' ve nothing more to do here , ” he said to the king .\",\n",
       "  '“ I ’ ll set off . ”',\n",
       "  '“ Do not go , ” said the king , who was very proud of having a subject .',\n",
       "  '“ Do not go .',\n",
       "  'I will make you a Minister ! ”',\n",
       "  '“ Minister of what ? ”',\n",
       "  '“ Minster of — of Justice ! ”',\n",
       "  '“ But there ’ s nobody here to judge ! ”',\n",
       "  '“ We do not know that , ” the king said to him .',\n",
       "  '“ I have not yet made a complete tour of my kingdom .',\n",
       "  'I am very old , I have no space for a carriage and it tires me to walk . ”',\n",
       "  '“ Oh , but I ’ ve already looked ! ”',\n",
       "  'said the little prince , who leant over to give one more glance at the other side of the planet .',\n",
       "  'There was no one there either ...',\n",
       "  '“ Then you shall judge yourself , ” the king answered .',\n",
       "  '“ That is the most difficult thing of all .',\n",
       "  'It is much more difficult to judge oneself than to judge someone else .',\n",
       "  'If you succeed in judging yourself rightly , then you are truly wise . ”',\n",
       "  '“ Yes , ” said the little prince , “ but I can judge myself anywhere .',\n",
       "  'I don ’ t have to live here . ”',\n",
       "  '“ Hum !',\n",
       "  'hum ! ”',\n",
       "  'said the king .',\n",
       "  '“ I am fairly certain that somewhere on my planet there is an old rat .',\n",
       "  'I hear him at night .',\n",
       "  'You can judge this old rat .',\n",
       "  'From time to time you will condemn him to death .',\n",
       "  'Thus his life will depend on your justice .',\n",
       "  'But you will pardon him on each occasion to conserve him .',\n",
       "  'There is only one of him . ”',\n",
       "  '“ I , ” replied the little prince , “ don ’ t like to condemn anyone to death , and now I think I ’ ll go on my way . ”',\n",
       "  '“ No , ” said the king .',\n",
       "  'But the little prince , having readied himself to leave , had no wish to grieve the old monarch .',\n",
       "  '“ If Your Majesty wishes to be promptly obeyed , he should be able to give me a reasonable order .',\n",
       "  'He should be able , for example , to order me to leave within a minute .',\n",
       "  'It seems to me that conditions are favourable ... ”',\n",
       "  'As the king made no answer , the little prince hesitated at first , then , with a sigh , took his leave .',\n",
       "  '“ I make you my Ambassador , ” the king hastily called out .',\n",
       "  'He had a magnificent air of authority .',\n",
       "  '“ The grownups are very strange , ” the little prince said to himself , as he continued on his journey .',\n",
       "  'The second planet was inhabited by a conceited man .',\n",
       "  '“ Ah !',\n",
       "  'Here comes a visit from an admirer ! ”',\n",
       "  'exclaimed the conceited man from afar , the moment he spotted the little prince .',\n",
       "  'Because , to conceited men , all other men are admirers .',\n",
       "  '“ Good morning , ” said the little prince .',\n",
       "  '“ You have a funny hat . ”',\n",
       "  '“ It ’ s for saluting , ” the conceited man replied .',\n",
       "  '“ It ’ s to raise in salute when people acclaim me .',\n",
       "  'Unfortunately , nobody ever passes by this way . ”',\n",
       "  '“ Oh , Really ? ”',\n",
       "  'said the little prince , who didn ’ t understand .',\n",
       "  '“ Clap your hands , one against the other , ” the conceited man advised .',\n",
       "  'The little prince clapped his hands , one against the other .',\n",
       "  'The conceited man raised his hat in a modest salute .',\n",
       "  '“ This is more fun than the visit to the king , ” the little prince said to himself .',\n",
       "  'And he began again to clap his hands , one against the other .',\n",
       "  'The conceited man again raised his hat in a salute .',\n",
       "  'After five minutes of this exercise the little prince grew tired of the monotony of the game : “ And what should I do , ” he asked , “ to make the hat come down ? ”',\n",
       "  'But the conceited man didn ’ t hear him .',\n",
       "  'Conceited people never hear anything but praise .',\n",
       "  '“ Do you really admire me a lot ? ”',\n",
       "  'he asked the little prince .',\n",
       "  \"“ What does that mean — ' to admire ' ? ”\",\n",
       "  '‘ “ To admire ’ means ‘ to recognise that I ’ m the most handsome , the best - dressed , the richest , and the most intelligent man on the planet . ’',\n",
       "  '” “ But you ’ re the only man on the planet ! ”',\n",
       "  '“ Do it for me .',\n",
       "  'Admire me just the same . ”',\n",
       "  '“ I admire you , ” said the little prince , shrugging his shoulders a little , “ but how can that interest you so much ? ”',\n",
       "  'And the little prince went away .',\n",
       "  '“ The grownups are certainly very odd , ” he said to himself , as he continued his journey .',\n",
       "  'The next planet was inhabited by a heavy drinker .',\n",
       "  'This was a very short visit , but it plunged the little prince into a deep sadness .',\n",
       "  '“ What are you doing there ? ”',\n",
       "  'he said to the drinker , who he found sitting in silence in front of a number of empty bottles and a number of full bottles .',\n",
       "  '“ I ’ m drinking , ” replied the drinker , gloomily .',\n",
       "  '“ Why are you drinking ? ”',\n",
       "  'the little prince asked him .',\n",
       "  '“ To forget , ” replied the drinker .',\n",
       "  '“ To forget what ? ”',\n",
       "  'asked the little prince , who already felt sorry for him .',\n",
       "  '“ To forget that I ’ m ashamed , ” confessed the drinker , lowering his head .',\n",
       "  '“ Ashamed of what ? ”',\n",
       "  'inquired the little prince , who wanted to help him .',\n",
       "  '“ Ashamed of drinking ! ”',\n",
       "  'concluded the drinker , who then shut himself away in the silence .',\n",
       "  'And the little prince went away , puzzled .',\n",
       "  '“ The grownups are certainly very , very odd , ” he said to himself , as he continued on his journey .'],\n",
       " ['The fourth planet belonged to a businessman .',\n",
       "  'This man was so busy that he didn ’ t even raise his head when the little prince arrived .',\n",
       "  '“ Good morning , ” the little prince said to him .',\n",
       "  '“ Your cigarette has gone out . ”',\n",
       "  '“ Three and two make five .',\n",
       "  'Five and seven make twelve .',\n",
       "  'Twelve and three make fifteen .',\n",
       "  'Good morning .',\n",
       "  'Fifteen and seven make twenty - two .',\n",
       "  'Twenty - two and six make twenty - eight .',\n",
       "  'No time to light it again .',\n",
       "  'Twenty - six and five make thirty - one .',\n",
       "  'Phew !',\n",
       "  'Then that makes five - hundred - and - one million , six - hundred - twenty - two - thousand , seven - hundred - thirty - one . ”',\n",
       "  '“ Five hundred million what ? ”',\n",
       "  '“ Huh ?',\n",
       "  'Are you still there ?',\n",
       "  'Five - hundred - and - one million ...',\n",
       "  'I ’ ve forgotten now ...',\n",
       "  'I have so much work !',\n",
       "  'I am a man of consequence .',\n",
       "  'I don ’ t amuse myself with balderdash !',\n",
       "  'Two and five make seven .',\n",
       "  '“ Five - hundred - and - one million what ? ”',\n",
       "  'repeated the little prince , who had never in his life let go of a question , once he had asked it .',\n",
       "  'The businessman raised his head .',\n",
       "  '“ During the fifty - four years that I ’ ve lived on this planet , I ’ ve only been disturbed three times .',\n",
       "  'The first time was twenty - two years ago , by some scatterbrain who fell from god knows where .',\n",
       "  'He made the most dreadful noise , and I made four mistakes in a sum .',\n",
       "  'The second time was eleven years ago , by an attack of rheumatism .',\n",
       "  \"I don ' t get enough exercise .\",\n",
       "  'I don ’ t have time to stroll about .',\n",
       "  'I am a man of consequence .',\n",
       "  'The third time — well , this is it !',\n",
       "  'I was saying , then , five - hundred - and - one million — ” “ Millions of what ? ”',\n",
       "  'The businessman realised that there was no hope of being left in peace : “ Millions of those little objects that you see sometimes in the sky . ”',\n",
       "  '“ Flies ? ”',\n",
       "  '“ No , no , the little things that shine . ”',\n",
       "  '“ Bees ? ”',\n",
       "  '“ No , no !',\n",
       "  'The little golden things that make lazy men daydream .',\n",
       "  'As for me , I am a man of consequence .',\n",
       "  'I have no time to daydream . ”',\n",
       "  '‘ Ah !',\n",
       "  'The stars ? ”',\n",
       "  \"“ Yes , that ' s it .\",\n",
       "  'The stars . ”',\n",
       "  '“ And what do you do with five - hundred million stars ? ”',\n",
       "  '“ Five - hundred - and - one million , six - hundred - twenty - two thousand , seven - hundred - thirty - one .',\n",
       "  'I am a man of consequence : I am precise . ”',\n",
       "  '“ And what do you do with these stars ? ”',\n",
       "  '“ What do I do with them ? ”',\n",
       "  '“ Yes . ”',\n",
       "  '“ Nothing .',\n",
       "  'I own them . ”',\n",
       "  '“ You own the stars ? ”',\n",
       "  '“ Yes . ”',\n",
       "  '“ But I ’ ve already seen a king who — ” “ Kings don ’ t own , they ‘ reign ’ over .',\n",
       "  \"It ' s very different . ”\",\n",
       "  '“ And how does owning the stars help you ? ”',\n",
       "  '“ It helps by making me rich . ”',\n",
       "  '“ And how does being rich help you ? ”',\n",
       "  '“ To buy more stars , if someone discovers some more . ”',\n",
       "  '“ This man , ” the little prince said to himself , “ reasons a bit like my poor drinker ... ”',\n",
       "  'But he still had some questions : “ How can you own the stars ?',\n",
       "  '“ “ Who owns them ? ”',\n",
       "  'the businessman retorted , grumpily .',\n",
       "  \"“ I don ' t know .\",\n",
       "  'Nobody does . ”',\n",
       "  '“ Then they belong to me , because I thought of it first . ”',\n",
       "  '“ Is that all that ’ s necessary ? ”',\n",
       "  '“ Certainly .',\n",
       "  'When you find a diamond that belongs to nobody , it ’ s yours .',\n",
       "  'When you discover an island that belongs to nobody , it ’ s yours .',\n",
       "  'When you get an idea first , you take out a patent : it ’ s yours .',\n",
       "  'And I own the stars , because no one before me ever thought of owning them .',\n",
       "  '“ Yes , that ’ s true , ” said the little prince .',\n",
       "  '“ And what do you do with them ? ”',\n",
       "  '“ I administer them .',\n",
       "  'I count them and recount them , ” said the businessman .',\n",
       "  '“ It ’ s difficult .',\n",
       "  'But I am a man of consequence . ”',\n",
       "  'The little prince was still not satisfied .',\n",
       "  '“ If I owned a scarf , I could put it around my neck and take it away with me .',\n",
       "  'If I owned a flower , I could pick my flower and take it away with me .',\n",
       "  'But you can ’ t pick the stars . ”',\n",
       "  '“ No .',\n",
       "  'But I can put them in the bank . ”',\n",
       "  '“ What does that mean ? ”',\n",
       "  '“ That means that I write the number of my stars on a little paper .',\n",
       "  'And then I lock this paper in a drawer . ”',\n",
       "  '“ And that ’ s all ? ”',\n",
       "  '“ That ’ s enough . ”',\n",
       "  '“ That ’ s funny , ” thought the little prince .',\n",
       "  '“ It ’ s rather poetic .',\n",
       "  'But it ’ s of no great consequence . ”',\n",
       "  'On matters of consequence , the little prince had ideas which were very different from those of the grownups .',\n",
       "  '“ I myself , ” he continued , “ own a flower that I water every day .',\n",
       "  'I own three volcanoes , that I sweep out every week , as I also sweep out the one that ’ s extinct .',\n",
       "  'You never know .',\n",
       "  'It ’ s of some use to my volcanoes , and it ’ s of some use to my flower , that I own them .',\n",
       "  'But you ’ re of no use to the stars ... ”',\n",
       "  'The businessman opened his mouth , but he found nothing to say in response , and the little prince went away .',\n",
       "  '“ The grownups are certainly altogether extraordinary , ” he said to himself , as he continued on the journey .',\n",
       "  'The fifth planet was very strange .',\n",
       "  'It was the smallest of them all .',\n",
       "  'There was just enough room on it to accommodate a street lamp and a lamplighter .',\n",
       "  'The little prince couldn ’ t work out the purpose of having a street lamp and a lamplighter , somewhere out in the skies , on a planet without any houses or people .',\n",
       "  'He said to himself nevertheless : “ It may well be that this man is absurd .',\n",
       "  'But , he ’ s less absurd than the king , than the conceited man , the businessman , or the drinker .',\n",
       "  'At least his work has some meaning .',\n",
       "  'When he lights his lamp , it ’ s as if he ’ s bringing to life one more star , or one more flower .',\n",
       "  'When he puts out his lamp , he sends the flower , or the star , to sleep .',\n",
       "  'That ’ s a beautiful occupation .',\n",
       "  'It serves a real purpose , because it ’ s pretty . ”',\n",
       "  'When he arrived on the planet he respectfully saluted the lamplighter .',\n",
       "  '“ Good morning .',\n",
       "  'Why have you just put out your lamp ? ”',\n",
       "  '“ Those are the orders , ” replied the lamplighter .',\n",
       "  '“ Good morning . ”',\n",
       "  '“ What are the orders ? ”',\n",
       "  '“ That I put out my lamp .',\n",
       "  'Good evening . ”',\n",
       "  'And he lit it again .',\n",
       "  '“ But why have you just lit it again ? ”',\n",
       "  '“ Those are the orders , ” replied the lamplighter .',\n",
       "  '“ I don ’ t understand , ” said the little prince .',\n",
       "  '“ There ’ s nothing to understand , ” said the lamplighter .',\n",
       "  '“ Orders are orders .',\n",
       "  'Good morning . ”',\n",
       "  'And he put out his lamp .',\n",
       "  'Then he sponged his forehead with a handkerchief , decorated with red squares .',\n",
       "  '“ I have a terrible profession .',\n",
       "  'In the old days it was reasonable .',\n",
       "  'I ’ d put the lamp out in the morning , and in the evening I ’ d light it .',\n",
       "  'I had the rest of the day to rest , and the rest of the night to sleep ... ”',\n",
       "  '“ And since then , have the orders changed ? ”',\n",
       "  '“ The orders haven ’ t changed , ” said the lamplighter .',\n",
       "  '“ That ’ s the tragedy !',\n",
       "  'Every year the planet has turned faster and faster , and the orders haven ’ t changed ! ”',\n",
       "  '“ So what then ? ”',\n",
       "  'said the little prince .',\n",
       "  '“ So now that it spins round once every minute , I no longer have a moment ’ s rest .',\n",
       "  'Once every minute I light the lamp and put it out again ! ”',\n",
       "  '“ That ’ s funny !',\n",
       "  'Where you live , a day only lasts a minute ! ”',\n",
       "  '“ It ’ s not funny at all ! ”',\n",
       "  'said the lamplighter .',\n",
       "  '“ We ’ ve already been speaking for a month . ”',\n",
       "  '“ A month ? ”',\n",
       "  '“ Yes .',\n",
       "  'Thirty minutes .',\n",
       "  'Thirty days .',\n",
       "  'Good evening . ”',\n",
       "  'And he lit his lamp again .',\n",
       "  'The little prince watched him and felt that he loved this lamplighter who was so faithful to his orders .',\n",
       "  'He remembered the sunsets which he himself had gone to seek in the past , by moving his chair .',\n",
       "  'He wanted to help his friend .',\n",
       "  '“ You know — I know a way you can rest whenever you want ... ”',\n",
       "  '“ I always want to , ” said the lamplighter .',\n",
       "  'For it ’ s possible to be both faithful and lazy at the same time .',\n",
       "  'The little prince went on : “ Your planet is so small that you can go right round it in three strides .',\n",
       "  'You only have to walk along rather slowly to always stay in the sun .',\n",
       "  'When you want to rest , you can walk — and the day will last as long as you like . ”',\n",
       "  \"“ That doesn ' t do me much good , ” said the lamplighter .\",\n",
       "  '“ What I really love in life is to sleep . ”',\n",
       "  '“ That ’ s bad luck , ” said the little prince .',\n",
       "  '“ That is bad luck , ” said the lamplighter .',\n",
       "  '“ Good morning . ”',\n",
       "  'And he put out his lamp .',\n",
       "  '“ That man , ” said the little prince to himself , as he continued further on his journey , “ that man would be despised by all the others : by the king , by the conceited man , by the drinker , and by the businessman .',\n",
       "  'Yet he ’ s the only one that doesn ’ t seem ridiculous to me .',\n",
       "  'Perhaps it ’ s because he thinks of something other than himself . ”',\n",
       "  'He breathed a sigh of regret , and said to himself : “ That man is the only one with whom I could ’ ve made friends .',\n",
       "  'But his planet is really very small .',\n",
       "  'There ’ s no room on it for two people .',\n",
       "  'What the little prince didn ’ t dare admit to himself was that he missed this blessed planet most of all because of the one thousand , four hundred and forty sunsets every day !'],\n",
       " ['The sixth planet was ten times larger than the last .',\n",
       "  'It was inhabited by an old gentleman who wrote enormous books .',\n",
       "  '“ Oh , look !',\n",
       "  'Here comes an explorer ! ”',\n",
       "  'he cried out when he caught sight of the little prince .',\n",
       "  'The little prince sat down on the table and panted a little .',\n",
       "  'He had already travelled so far !',\n",
       "  '“ Where do you come from ? ”',\n",
       "  'the old gentleman said to him .',\n",
       "  '“ What ’ s that big book ? ”',\n",
       "  'said the little prince .',\n",
       "  '“ What do you do here ? ”',\n",
       "  '“ I am a geographer , ” said the old gentleman .',\n",
       "  '“ What ’ s a geographer ? ”',\n",
       "  '“ He is a scholar who knows the location of the seas , the rivers , the towns , the mountains , and the deserts . ”',\n",
       "  '“ That ’ s very interesting , ” said the little prince .',\n",
       "  '“ That really is , at last , a real profession ! ”',\n",
       "  'And he glanced around at the planet of the geographer .',\n",
       "  'He had never seen such a majestic planet before .',\n",
       "  '“ Your planet is very beautiful , ” he said .',\n",
       "  '“ Are there oceans ? ”',\n",
       "  '“ I wouldn ’ t know , ” said the geographer .',\n",
       "  '“ Oh . ”',\n",
       "  '( The little prince was disappointed .',\n",
       "  ') “ And mountains ? ”',\n",
       "  '“ I wouldn ’ t know , ” said the geographer .',\n",
       "  '“ And towns , and rivers , and deserts ? ”',\n",
       "  '“ I wouldn ’ t know that , either , ” said the geographer .',\n",
       "  '“ But you ’ re a geographer ! ”',\n",
       "  '“ That ’ s true , ” the geographer said , “ but I am not an explorer .',\n",
       "  'I don ’ t have a single explorer .',\n",
       "  'It is not for the geographer to count the towns , the rivers , the mountains , the seas , the oceans , and the deserts .',\n",
       "  'The geographer is too important to go strolling about .',\n",
       "  'He doesn ’ t leave his desk .',\n",
       "  'But he receives the explorers .',\n",
       "  'He asks them questions , and he writes down their recollections .',\n",
       "  \"And if any of their recollections seem interesting to him , the geographer orders an inquiry into that explorer ' s moral character . ”\",\n",
       "  '“ Why ’ s that ? ”',\n",
       "  '“ Because an explorer who told lies would cause havoc to geography books .',\n",
       "  'So would an explorer who drank too much . ”',\n",
       "  '“ Why ’ s that ? ”',\n",
       "  'asked the little prince .',\n",
       "  '“ Because intoxicated men see double .',\n",
       "  'So the geographer would record two mountains in a place where there was only one . ”',\n",
       "  '“ I know someone , ” said the little prince , “ who ’ d make a bad explorer . ”',\n",
       "  '“ That ’ s possible .',\n",
       "  'So , when the moral character of the explorer appears to be in order , an inquiry is done into his discovery . ”',\n",
       "  '“ You go to see it ? ”',\n",
       "  '“ No .',\n",
       "  'That would be too complicated .',\n",
       "  'But one requires the explorer to provide proof .',\n",
       "  'If for example , the discovery in question was of a large mountain , one would require that he bring back large stones from it . ”',\n",
       "  'The geographer suddenly became excited .',\n",
       "  '“ But you — you come from far away !',\n",
       "  'You are an explorer !',\n",
       "  'You must describe your planet to me ! ”',\n",
       "  'And the geographer , having opened his big register , sharpened his pencil .',\n",
       "  'The recitals of explorers are first recorded in pencil .',\n",
       "  'One waits until the explorer has provided proof before recording them in ink .',\n",
       "  '“ Well ? ”',\n",
       "  'said the geographer .',\n",
       "  '“ Oh , where I live , ” said the little prince , “ it ’ s not very interesting , everything is very small .',\n",
       "  'I have three volcanoes .',\n",
       "  'Two active volcanoes , and one extinct one .',\n",
       "  'But you never know . ”',\n",
       "  '“ One never knows , ” said the geographer .',\n",
       "  '“ I also have a flower . ”',\n",
       "  '“ We do not record flowers , ” said the geographer .',\n",
       "  '“ Why ’ s that ?',\n",
       "  'It ’ s the prettiest thing ! ”',\n",
       "  '“ Because flowers are ephemeral . ”',\n",
       "  \"“ What does that mean — ' ephemeral ' ? ”\",\n",
       "  '“ Geography books , ” said the geographer , “ of all books , are the most concerned with matters of consequence .',\n",
       "  'They never become out - dated .',\n",
       "  'It is very rare that a mountain changes position .',\n",
       "  'It is very rare that an ocean empties itself of its water .',\n",
       "  'We write about eternal things . ”',\n",
       "  '“ But extinct volcanoes can wake up , ” interrupted the little prince .',\n",
       "  \"“ What does ' ephemeral ' mean ? ”\",\n",
       "  '“ Whether volcanoes are extinct or active is of no consequence to us , ” said the geographer .',\n",
       "  '“ The thing that matters to us is the mountain .',\n",
       "  'It does not change . ”',\n",
       "  \"“ But what does ' ephemeral ' mean ? ”\",\n",
       "  'repeated the little prince , who had never in his life let go of a question , once he had asked it .',\n",
       "  '“ It means , ‘ which is at risk of imminent disappearance . ’',\n",
       "  '\" “ Is my flower at risk of imminent disappearance ? ”',\n",
       "  '“ Of course . ”',\n",
       "  '“ My flower is ephemeral , ” the little prince said to himself , “ and she has only four thorns to defend herself against the world .',\n",
       "  'And I ’ ve left her all alone on my planet ! ”',\n",
       "  'That was his first moment of regret .',\n",
       "  'But he took heart once again : “ What place would you advise me to visit ? ”',\n",
       "  'he asked .',\n",
       "  '“ The planet Earth , ” replied the geographer .',\n",
       "  '“ It has a good reputation ... ”',\n",
       "  'And the little prince went away , thinking of his flower .',\n",
       "  'So the seventh planet was the Earth .',\n",
       "  'The Earth isn ’ t just any old planet !',\n",
       "  'It has one hundred and eleven kings ( not forgetting , of course , the Negro kings amongst them ) , seven thousand geographers , nine hundred thousand businessmen , seven million , five hundred thousand heavy drinkers , three hundred and eleven million conceited men , that ’ s to say , about two billion grownups .',\n",
       "  'To give you an idea of the size of the Earth , I ’ ll tell you that before the invention of electricity it was necessary to maintain , over the span of the six continents , a veritable army of four hundred and sixty - two thousand , five hundred and eleven street lamp lighters .',\n",
       "  'Seen from a distance it made a wonderful spectacle .',\n",
       "  'The movements of this army were regulated like those of an opera ballet .',\n",
       "  'First came the turn of the lamplighters of New Zealand and Australia .',\n",
       "  'Having set their lamps alight , they would go off to bed .',\n",
       "  'Next came the turn of the lamplighters of China and Siberia to enter into the dance .',\n",
       "  'Then they too would disappear into the wings .',\n",
       "  'Then came the turn of the lamplighters of Russia and the Indies .',\n",
       "  'Then those of Africa and Europe .',\n",
       "  'Then those of South America .',\n",
       "  'Then those of North America .',\n",
       "  'And never would they make a mistake in their order of entry on stage .',\n",
       "  'It was magnificent .',\n",
       "  'Only the lamp lighter of the single lamp of the North pole , and his colleague at the single lamp of the South pole led lives of leisure : they worked twice a year .',\n",
       "  'When one wants to be witty , it can happen that one bends the truth a little .',\n",
       "  'I haven ’ t been entirely honest in telling you about the lamplighters .',\n",
       "  'I run the risk of giving a false idea of our planet to those who don ’ t know it .',\n",
       "  'Men take up very little space on the Earth .',\n",
       "  'If the two billion people who inhabit the Earth were to stand upright and squash together a little , like for a meeting , they would easily fit on one public square twenty miles long and twenty miles wide .',\n",
       "  'All humanity could be piled up on the smallest Pacific islet .',\n",
       "  'The grownups , of course , won ’ t believe you .',\n",
       "  'They picture themselves as taking up a lot of space .',\n",
       "  'They think themselves as important as the baobabs .',\n",
       "  'Therefore you should advise them to do the math .',\n",
       "  'They adore numbers , and that will please them .',\n",
       "  'But don ’ t waste your time on this chore .',\n",
       "  'There ’ s no point .',\n",
       "  'You trust me .',\n",
       "  'The little prince , having arrived on Earth , was very surprised not to see anyone .',\n",
       "  'He had already started to worry that he ’ d got the wrong planet , when a moon - coloured coil stirred in the sand .',\n",
       "  '“ Good evening , ” said the little prince courteously .',\n",
       "  '“ Good evening , ” said the snake .',\n",
       "  '“ On what planet have I come down on ? ”',\n",
       "  'asked the little prince .',\n",
       "  '“ Onto Earth , in Africa , ” the snake answered .',\n",
       "  '“ Oh !',\n",
       "  '...',\n",
       "  'So there ’ s no one on Earth ? ”',\n",
       "  '“ This is the desert .',\n",
       "  'There is no one in the deserts .',\n",
       "  'The Earth is large , ” said the snake .',\n",
       "  'The little prince sat down on a stone , and raised his eyes toward the sky .',\n",
       "  '“ I wonder , ” he said , “ if the stars are lit so that each of us can one day find his own again .',\n",
       "  'Look at my planet .',\n",
       "  'It ’ s right there above us ...',\n",
       "  'But it ’ s so far away ! ”',\n",
       "  '“ It is beautiful , ” said the snake .',\n",
       "  '“ What has brought you here ? ”',\n",
       "  '“ I ’ ve been having some trouble with a flower , ” said the little prince .',\n",
       "  '“ Ah ! ”',\n",
       "  'said the snake .',\n",
       "  'And they were silent .',\n",
       "  '“ Where are the men ? ”',\n",
       "  'asked the little prince at last .',\n",
       "  '“ It ’ s a bit lonely in the desert ... ”',\n",
       "  '“ It is also lonely amongst men , ” the snake said .',\n",
       "  'The little prince gazed at him for a long time .',\n",
       "  \"“ You ' re a funny animal , ” he said finally , “ as thin as a finger ... ”\",\n",
       "  '“ But I am more powerful than the finger of a king , ” said the snake .',\n",
       "  'The little prince smiled .',\n",
       "  '“ You ’ re not very powerful ...',\n",
       "  'you haven ’ t even got any legs ...',\n",
       "  'you can ’ t even travel ... ”',\n",
       "  '“ I can carry you further than a ship , ” said the snake .',\n",
       "  \"He wrapped himself around the little prince ' s ankle , like a golden bracelet .\",\n",
       "  '“ Whoever I touch , I send him back to the earth from which he came , ” he continued .',\n",
       "  '“ But you are pure , and you come from a star ... ”',\n",
       "  'The little prince made no reply .',\n",
       "  '“ I feel sorry for you , so weak , on this Earth made of granite .',\n",
       "  'I can help you if someday you become too homesick for your planet .',\n",
       "  'I can . ”',\n",
       "  '“ Oh !',\n",
       "  'I understand very well , ” said the little prince , “ but why do you always speak in riddles ? ”',\n",
       "  '“ I solve them all , ” said the snake .',\n",
       "  'And they were silent .',\n",
       "  'The little prince crossed the desert and met only with one flower .',\n",
       "  'A flower with three petals , a nondescript flower belonging to no one .',\n",
       "  '“ Good morning , ” said the little prince .',\n",
       "  '“ Good morning , ” said the flower .',\n",
       "  '“ Where are the men ? ”',\n",
       "  'asked the little prince politely .',\n",
       "  'The flower had once seen a caravan passing .',\n",
       "  '“ Men ?',\n",
       "  'I think there exists six or seven of them .',\n",
       "  'I saw them years ago .',\n",
       "  'But you never know where to find them .',\n",
       "  'They are blown here and there by the wind .',\n",
       "  'They lack roots , it makes things very difficult for them ” “ Goodbye , ” said the little prince .',\n",
       "  '“ Goodbye , ” said the flower .',\n",
       "  'The little prince climbed a high mountain .',\n",
       "  'The only mountains he ’ d ever known were the three volcanoes that came up to his knees .',\n",
       "  'And he used the extinct volcano as a footstool .',\n",
       "  '“ From a mountain as high as this one , ” he said to himself , “ I ’ ll be able to see the entire planet all at once , and all the people ... ”',\n",
       "  'But he saw nothing but sharp needles of rock .',\n",
       "  '“ Good morning , ” he said courteously .',\n",
       "  '“ Good morning ...',\n",
       "  'Good morning ...',\n",
       "  'Good morning ...',\n",
       "  ', ” answered the echo .',\n",
       "  '“ Who are you ? ”',\n",
       "  'said the little prince .',\n",
       "  '“ Who are you ...',\n",
       "  'who are you ...',\n",
       "  'who are you ...',\n",
       "  '? ”',\n",
       "  'answered the echo .',\n",
       "  '“ Be my friends .',\n",
       "  'I ’ m all alone , ” he said .',\n",
       "  '“ I ’ m all alone ...',\n",
       "  'all alone ...',\n",
       "  'all alone ...',\n",
       "  ', ” answered the echo .',\n",
       "  '“ What a funny planet ! ”',\n",
       "  'he thought .',\n",
       "  '“ It ’ s all dry , and all jagged , and all barren .',\n",
       "  'And the people have no imagination .',\n",
       "  'They repeat whatever you say to them ...',\n",
       "  'On my planet I had a flower : she was always the first to speak ... ”'],\n",
       " ['But it happened that the little prince , having walked for a long time through the sands , rocks , and snow , at last came across a road .',\n",
       "  'And all roads lead to the dwellings of men .',\n",
       "  '“ Good morning , ” he said .',\n",
       "  'It was a garden covered in roses .',\n",
       "  '“ Good morning , ” said the roses .',\n",
       "  '“ Good morning !',\n",
       "  'Good morning !',\n",
       "  'Good morning ! ”',\n",
       "  'The little prince gazed at them .',\n",
       "  'They all looked just like his flower .',\n",
       "  '“ Who are you ? ”',\n",
       "  'he asked them , stunned .',\n",
       "  \"“ We ' re roses , ” the roses said .\",\n",
       "  \"“ We ' re roses !\",\n",
       "  \"We ' re roses !\",\n",
       "  \"We ' re roses ! ”\",\n",
       "  '“ Oh ! ”',\n",
       "  'said the little prince ...',\n",
       "  'And he suddenly felt very unhappy .',\n",
       "  'His flower had told him that she was the only one of her kind in the universe .',\n",
       "  'And here were five thousand of them , all alike , in one single garden !',\n",
       "  '“ She ’ d be very upset , ” he said to himself , “ if she saw this ...',\n",
       "  'she ’ d cough and cough and pretend to die to avoid being laughed at .',\n",
       "  'And I ’ d have to pretend to nurse her back to life , to humble myself also , because if I didn ’ t , she really would allow herself to die ...',\n",
       "  '” Then he said to himself : “ I thought I was rich , with a flower that was one of a kind , and all I have is a common rose .',\n",
       "  \"That , and my three volcanoes that come up to my knees , of one which is perhaps forever extinct ; that doesn ' t make me a very great prince .\",\n",
       "  'And lying in the grass , he started to cry .',\n",
       "  'It was then that the fox appeared : “ Good morning , ” said the fox .',\n",
       "  '“ Good morning , ” responded the little prince politely , who then turned around , but saw nothing .',\n",
       "  '“ I ’ m right here , ” the voice said , “ under the apple tree ... ”',\n",
       "  '“ Who are you ? ”',\n",
       "  'asked the little prince .',\n",
       "  '“ You ’ re very pretty . ”',\n",
       "  '“ I ’ m a fox , ” the fox said .',\n",
       "  '“ Come and play with me , ” proposed the little prince .',\n",
       "  '“ I ’ m so unhappy . ”',\n",
       "  '“ I can ’ t play with you , ” said the fox .',\n",
       "  '“ I ’ m not tamed . ”',\n",
       "  '“ Oh !',\n",
       "  'I ’ m sorry , ” said the little prince .',\n",
       "  \"But , after some thought , he added : “ What does that mean — ' tame ' ? ”\",\n",
       "  '“ You aren ’ t from here , ” said the fox .',\n",
       "  '“ What is it that you ’ re looking for ? ”',\n",
       "  '“ I ’ m looking for men , ” said the little prince .',\n",
       "  \"“ What does ' tame ' mean ? ”\",\n",
       "  '“ Men , ” said the fox , “ they have guns , and they hunt .',\n",
       "  'It ’ s very bothersome .',\n",
       "  'They also raise chickens .',\n",
       "  'It ’ s their sole interest .',\n",
       "  'Are you looking for chickens ? ”',\n",
       "  '“ No , ” said the little prince .',\n",
       "  '“ I ’ m looking for friends .',\n",
       "  \"What does ' tame ' mean ? ”\",\n",
       "  '“ It ’ s something that ’ s too often forgotten , ” said the fox .',\n",
       "  '“ It means ‘ to establish bonds . ’',\n",
       "  '” ‘ “ To establish bonds ? ”',\n",
       "  '’ “ That ’ s right , ” said the fox .',\n",
       "  '“ To me , you ’ re still only a little boy , just like a hundred thousand other little boys .',\n",
       "  'And I don ’ t need you .',\n",
       "  'And you don ’ t need me either .',\n",
       "  'To you , I ’ m only a fox , just like a hundred thousand other foxes .',\n",
       "  'But if you tame me , we ’ ll need each other .',\n",
       "  'To me , you ’ ll be unique in the entire world .',\n",
       "  'To you , I ’ ll be unique in the entire world ... ”',\n",
       "  '“ I ’ m beginning to understand , ” said the little prince .',\n",
       "  '“ There ’ s a flower ...',\n",
       "  'I think she ’ s tamed me ... ”',\n",
       "  '“ It ’ s possible , ” said the fox .',\n",
       "  '“ On Earth you see all kinds of things . ”',\n",
       "  '“ Oh , but she ’ s not on Earth ! ”',\n",
       "  'said the little prince .',\n",
       "  'The fox seemed very intrigued : “ On another planet ? ”',\n",
       "  '“ Yes . ”',\n",
       "  '“ Are there hunters on that planet ? ”',\n",
       "  '“ No . ”',\n",
       "  \"“ That ' s interesting !\",\n",
       "  'And chickens ? ”',\n",
       "  '“ No . ”',\n",
       "  '“ Nothing ’ s perfect , ” sighed the fox .',\n",
       "  'But the fox came back to his idea .',\n",
       "  '“ My life is very monotonous .',\n",
       "  'I hunt chickens ; men hunt me .',\n",
       "  'All the chickens look alike , and all the men look alike .',\n",
       "  'So I get a bit bored .',\n",
       "  'But if you tame me , it would bring some sunlight into my life .',\n",
       "  'I ’ d come to know a sound of footsteps unlike any other .',\n",
       "  'Other footsteps send me hurrying back underground .',\n",
       "  'Yours would call me out of my burrow like music .',\n",
       "  'And then look : you see the wheat fields down there ?',\n",
       "  'I don ’ t eat bread .',\n",
       "  'Wheat is of no use to me .',\n",
       "  'The wheat fields mean nothing to me .',\n",
       "  'And that ’ s sad .',\n",
       "  'But your hair is the colour of gold .',\n",
       "  'So it ’ ll be wonderful when you ’ ve tamed me !',\n",
       "  'The wheat , which is golden , will remind me of you .',\n",
       "  'And I ’ ll love the sound of the wind blowing through the wheat ... ”',\n",
       "  'The fox went silent and gazed at the little prince for a long time .',\n",
       "  '“ Please ...',\n",
       "  'tame me ! ”',\n",
       "  'he said .',\n",
       "  '“ I really want to , ” the little prince replied , “ but I don ’ t have much time .',\n",
       "  'I have friends to discover , and many things to understand . ”',\n",
       "  '“ One only understands the things that one tames , ” said the fox .',\n",
       "  '“ Men no longer have the time to get to know anything .',\n",
       "  'They buy things ready made in the shops .',\n",
       "  'But as there aren ’ t any shops that sell friends , men no longer have any friends .',\n",
       "  'If you want a friend , tame me .',\n",
       "  '“ What should I do ? ”',\n",
       "  'asked the little prince .',\n",
       "  '“ You have to be very patient , ” replied the fox .',\n",
       "  '“ First you ’ ll sit down a little way away from me , like this , in the grass .',\n",
       "  'I ’ ll watch you out of the corner of my eye and you won ’ t say anything .',\n",
       "  'Words are a source of misunderstandings .',\n",
       "  'But every day you ’ ll be able to sit a little closer ... ”',\n",
       "  'The next day the little prince came back .',\n",
       "  '“ It would ’ ve been better to come back at the same time of day , ” said the fox .',\n",
       "  \"“ If you come , for example , at four o ' clock in the afternoon , from three o ' clock I ’ d start to feel happy .\",\n",
       "  'As the time got nearer , I ’ d feel happier and happier .',\n",
       "  \"Already by four o ' clock , I ’ d be jumping about and getting restless ; I ’ d come to learn the price of happiness !\",\n",
       "  'But if you come at just any time , I ‘ d never know at what time my heart should be ready to greet you ...',\n",
       "  'we must observe the rites . ”',\n",
       "  '“ What ’ s a rite ? ”',\n",
       "  'asked the little prince .',\n",
       "  '“ They are also something too often forgotten , ” said the fox .',\n",
       "  '“ They are what make one day different from other days , one hour different from other hours .',\n",
       "  'There ’ s a rite , for example , among my hunters .',\n",
       "  'On Thursdays they dance with the girls of the village .',\n",
       "  'So Thursday is a wonderful day !',\n",
       "  'I can go for a walk as far as the vineyards .',\n",
       "  'If the hunters danced on just any day , all the days would be alike , and I ’ d never have any rest . ”',\n",
       "  'So the little prince tamed the fox .',\n",
       "  'And when the time to leave drew near ...',\n",
       "  '“ Oh , ” said the fox , “ I ’ ll cry . ”',\n",
       "  '“ It ’ s your fault , ” said the little prince .',\n",
       "  '“ I never wished you any harm ; but you wanted me to tame you ... ”',\n",
       "  '“ I know , ” said the fox .',\n",
       "  '“ But you ’ re going to cry ! ”',\n",
       "  'said the little prince .',\n",
       "  '“ I know , ” said the fox .',\n",
       "  '“ So all this has done you no good at all ! ”',\n",
       "  '“ It has done me good , ” said the fox , “ because of the colour of the wheat . ”',\n",
       "  'And then he added : “ Go and see the roses again .',\n",
       "  'You ’ ll understand that yours is unique in the entire world .',\n",
       "  'Then come back to say goodbye to me , and I ’ ll make you a present of a secret . ”',\n",
       "  'The little prince went away to see the roses again : “ You aren ’ t like my rose at all , you are nothing yet , ” he told them .',\n",
       "  'No one has tamed you , and you haven ’ t tamed anyone .',\n",
       "  'You ’ re like my fox used to be .',\n",
       "  'He was only a fox , just like a hundred thousand others .',\n",
       "  'But I ’ ve made him my friend , and now he ’ s unique in the entire world . ”',\n",
       "  'And the roses were very embarrassed .',\n",
       "  '“ You are beautiful , but you are empty , ” he went on .',\n",
       "  '“ One could not die for you .',\n",
       "  'Of course , an ordinary passer - by would think that my rose looked just like you .',\n",
       "  'But she alone is more important than all of you : because it ’ s her that I watered ; because it ’ s her that I put under the glass dome ; because it ’ s her that I sheltered behind the screen ; because it ’ s for her that I killed the caterpillars ( except two or three , to become butterflies ) ; because it ’ s her that I listened to grumble , or boast , or even sometimes when she said nothing .',\n",
       "  'Because she ’ s my rose .',\n",
       "  'And he went back to the fox : “ Goodbye , ” he said .',\n",
       "  '“ Goodbye , ” said the fox .',\n",
       "  \"“ Here ' s my secret .\",\n",
       "  'It ’ s very simple : one only sees clearly with the heart .',\n",
       "  'What is essential is invisible to the eye . ”',\n",
       "  '“ What is essential is invisible to the eye , ” repeated the little prince , so as to remember .',\n",
       "  '“ It is the time you have wasted on your rose that makes your rose so important . ”',\n",
       "  '“ It is the time that I have wasted on my rose ... ”',\n",
       "  'said the little prince , so as to remember .',\n",
       "  '“ The men have forgotten this truth , ” said the fox .',\n",
       "  '“ But you must not forget it .',\n",
       "  'You become forever responsible for that which you have tamed .',\n",
       "  'You are responsible for your rose ... ”',\n",
       "  '“ I am responsible for my rose , ” repeated the little prince , so as to remember .',\n",
       "  '“ Good morning , ” said the little prince .',\n",
       "  '“ Good morning , ” said the railway switchman .',\n",
       "  '“ What do you do here ? ”',\n",
       "  'the little prince asked .',\n",
       "  '“ I sort travelers , in packs of a thousand , ” said the switchman .',\n",
       "  '“ I dispatch the trains that carry them : sometimes to the right , sometimes to the left . ”',\n",
       "  \"And a brilliantly lit express train , rumbling like thunder , shook the switchman ' s cabin .\",\n",
       "  '“ They really are in a hurry , ” said the little prince .',\n",
       "  '“ What is it that they ’ re looking for ? ”',\n",
       "  '“ Not even the locomotive engineer knows that , ” said the switchman .',\n",
       "  'A second brilliantly lit express thundered by in the opposite direction .',\n",
       "  '“ Are they back already ? ”',\n",
       "  'asked the little prince .',\n",
       "  '“ These aren ’ t the same ones , ” said the switchman .',\n",
       "  '“ It ’ s an exchange . ”',\n",
       "  '“ Weren ’ t they happy where they were ? ”',\n",
       "  '“ No one is ever happy where they are , ” said the switchman .',\n",
       "  'A third brilliantly lit express thundered by .',\n",
       "  '“ Are they chasing after the first travelers ? ”',\n",
       "  'asked the little prince .',\n",
       "  '“ They aren ’ t chasing after anything at all , ” said the switchman .',\n",
       "  '“ They ’ re asleep in there , or if not , they ’ re yawning .',\n",
       "  'Only the children are squashing their noses up against the windows . ”',\n",
       "  '“ Only the children know what they ’ re after , ” said the little prince .',\n",
       "  '“ They waste their time with a rag doll and it becomes very important to them ; and if someone takes it away from them , they cry ... ”',\n",
       "  '“ They ’ re lucky , ” said the switchman .'],\n",
       " ['“ Good morning , ” said the little prince .',\n",
       "  '“ Good morning , ” said the merchant .',\n",
       "  'This was a merchant who sold pills that had been created to quench thirst .',\n",
       "  'You could take one pill a week , and you no longer felt the need to drink anything .',\n",
       "  '“ Why are you selling those ? ”',\n",
       "  'asked the little prince .',\n",
       "  '“ It ’ s a big time saver , ” said the merchant .',\n",
       "  '“ Experts have done calculations .',\n",
       "  'You save fifty - three minutes per week . ”',\n",
       "  '“ And what do I do with the fifty - three minutes ? ”',\n",
       "  '“ You can do anything you like with them ... ”',\n",
       "  '“ Myself , ” the little prince said to himself , “ if I had fifty - three minutes to spend as I liked , I ’ d walk very slowly toward a spring of fresh water . ”',\n",
       "  'We were at the eighth day since my accident in the desert , and I ’ d listened to the story of the merchant as I drank the last drop of my water supply .',\n",
       "  '“ Ah , ” I said to the little prince , “ these memories of yours are very charming ; but I haven ’ t managed to repair my plane yet , I have nothing left to drink , and I , too , would be happy if I could walk slowly towards a spring of fresh water ! ”',\n",
       "  '“ My friend the fox — ” he said to me .',\n",
       "  '“ My dear fellow , our situation has nothing to do with the fox anymore ! ”',\n",
       "  '“ Why not ? ”',\n",
       "  '“ Because we will die of thirst .',\n",
       "  'He didn ’ t follow my reasoning , and he answered me : “ It ’ s nice to have had a friend , even if you ’ re about to die .',\n",
       "  'Myself , I ’ m glad to have had a fox as a friend ... ”',\n",
       "  '“ He never considers the danger , ” I said to myself .',\n",
       "  '“ He ’ s never been hungry or thirsty .',\n",
       "  'A little sunshine is all he needs ... ”',\n",
       "  'But he looked at me and replied to my thought : “ I ’ m also thirsty .',\n",
       "  'Let ’ s look for a well .',\n",
       "  'I made a gesture of weariness : it ’ s absurd to look for a well , at random , in the immensity of the desert .',\n",
       "  'But we started walking anyway .',\n",
       "  'When we had walked for hours in silence , night fell , and the stars began to come out .',\n",
       "  'I saw them as if in a dream , as my thirst had made me feverish .',\n",
       "  \"The little prince ' s words danced in my memory : “ So you ’ re also thirsty ? ”\",\n",
       "  'I asked him .',\n",
       "  'But he didn ’ t reply to my question .',\n",
       "  'He said simply : “ Water can be good for the heart too ... ”',\n",
       "  'I didn ’ t understand his answer , but I said nothing .',\n",
       "  'I knew better than to press my questions .',\n",
       "  'He was tired .',\n",
       "  'He sat down .',\n",
       "  'I sat down beside him .',\n",
       "  'And , after a silence , he spoke again : “ The stars are beautiful because of a flower that can ’ t be seen . ”',\n",
       "  'I replied , “ That ’ s true . ”',\n",
       "  'And I looked , without saying anything , at the folds of sand in the moonlight .',\n",
       "  '“ The desert is beautiful , ” the little prince added .',\n",
       "  'And it was true .',\n",
       "  'I have always loved the desert .',\n",
       "  'You sit down on a sand dune .',\n",
       "  'You see nothing .',\n",
       "  'You hear nothing .',\n",
       "  'And yet something radiates forth in the silence ...',\n",
       "  '“ What makes the desert beautiful , ” said the little prince , “ is that somewhere it hides a well ... ”',\n",
       "  'I was surprised to suddenly understand this mysterious radiation of the sands .',\n",
       "  'When I was a little boy I lived in an old house , and legend told that a treasure was buried there .',\n",
       "  'Of course , no one had ever been able to find it , or perhaps no one had even looked for it .',\n",
       "  'But it cast an enchantment over that house .',\n",
       "  'My home was hiding a secret in the depths of its heart ...',\n",
       "  '“ Yes , ” I said to the little prince .',\n",
       "  '“ Whether the house , the stars , or the desert , what gives them their beauty is something invisible ! ”',\n",
       "  '“ I ’ m glad , ” he said , “ that you agree with my fox . ”',\n",
       "  'As the little prince fell asleep , I took him in my arms and set out walking again .',\n",
       "  'I felt deeply moved .',\n",
       "  'It seemed to me that I was carrying a very fragile treasure .',\n",
       "  'It even seemed to me that there was nothing more fragile on Earth .',\n",
       "  'I looked in the moonlight at his pale forehead , his closed eyes , his locks of hair that trembled in the wind , and I said to myself : “ What I see here is only a shell .',\n",
       "  'That which is most important is invisible ... ”',\n",
       "  'As his slightly parted lips gave way to a half - smile , I continued : “ What I find so deeply moving about this little sleeping prince is his devotion to a flower ; it ’ s the image of a rose that shines in him like the flame of a lamp , even when he ’ s sleeping .',\n",
       "  'And I came to think of him as even more fragile .',\n",
       "  'One has to look after lamps : a gust of wind can put them out ...',\n",
       "  'And , continuing to walk , I found the well at daybreak .',\n",
       "  '“ Men , ” said the little prince , “ stuff themselves into express trains , but they don ’ t know what they ’ re looking for .',\n",
       "  'So they rush about , and go round in circles ... ”',\n",
       "  'And he added : “ It ’ s not worth it ... ”',\n",
       "  'The well that we had reached wasn ’ t like the other wells of the Sahara .',\n",
       "  'The wells of the Sahara are mere holes dug in the sand .',\n",
       "  'This one looked like a village well .',\n",
       "  'But there was no village there , and I thought I was dreaming .',\n",
       "  '“ It ’ s strange , ” I said to the little prince , “ Everything ’ s been prepared : the pulley , the bucket , and the rope ... ”',\n",
       "  'He laughed , took the rope , and put the pulley to work .',\n",
       "  'And the pulley moaned like an old weathervane when there has long been no wind .',\n",
       "  '“ Can you hear that ? ”',\n",
       "  'said the little prince , “ We ’ ve woken up the well , and it ’ s singing ... ”',\n",
       "  'I didn ’ t want him to tire himself out .',\n",
       "  '“ Let me do it , ” I said , “ It ’ s too heavy for you . ”',\n",
       "  'I hoisted the bucket slowly to the edge of the well and set it down good and level .',\n",
       "  'The song of the pulley continued in my ears , and in the still trembling water I could see the sunlight shimmer .',\n",
       "  '“ I ’ m thirsty for this water , ” said the little prince .',\n",
       "  '“ Give me some to drink ... ”',\n",
       "  'And I knew then what he ’ d been looking for !',\n",
       "  'I raised the bucket to his lips .',\n",
       "  'He drank , his eyes closed .',\n",
       "  'It was as sweet as some special festival treat .',\n",
       "  'This water was something very different from ordinary nourishment .',\n",
       "  'It was born of the walk under the stars , of the song of the pulley , of the effort of my arms .',\n",
       "  'It was good for the heart , like a present .',\n",
       "  'When I was a little boy , the lights of the Christmas tree , the music of the Midnight Mass , the tenderness in the smiles produced , in a similar way , the radiance of the gift that I received .',\n",
       "  '“ The men where you live , ” said the little prince , “ grow five thousand roses in a single garden ...',\n",
       "  'and they don ’ t find what they ’ re looking for in it . ”',\n",
       "  '“ They don ’ t find it , ” I replied .',\n",
       "  '“ And yet what they ’ re looking for could be found in a single rose , or in a little water ... ”',\n",
       "  '“ That ’ s true , ” I said .',\n",
       "  'And the little prince added : “ But the eyes are blind .',\n",
       "  'You have to search with the heart ... ”',\n",
       "  'I had drunk the water .',\n",
       "  'I breathed easily .',\n",
       "  'The sand at sunrise is the color of honey .',\n",
       "  'This honey color was also making me feel good .',\n",
       "  'Why then did I have this sense of grief ...',\n",
       "  '“ You have to keep your promise , ” said the little prince softly , who had again sat down beside me .',\n",
       "  '“ What promise ?',\n",
       "  '“ You know ...',\n",
       "  'a muzzle for my sheep ...',\n",
       "  'I ’ m responsible for this flower ... ”',\n",
       "  'I took my sketches out of my pocket .',\n",
       "  'The little prince saw them , and laughed as he said : “ Your baobabs - they look a bit like cabbages . ”',\n",
       "  '“ Oh ! ”',\n",
       "  'And I ’ d been so proud of my baobabs !',\n",
       "  '“ Your fox ...',\n",
       "  'his ears ...',\n",
       "  'they look a bit like horns ...',\n",
       "  'and they ’ re too long ! ”',\n",
       "  'And then he laughed again .',\n",
       "  '“ You aren ’ t being fair , my little fellow .',\n",
       "  \"I don ' t know how to draw anything except boa constrictors , closed and open . ”\",\n",
       "  '“ Oh , it ’ ll be all ok , ” he said , “ children understand . ”',\n",
       "  'So I made a pencil sketch of a muzzle .',\n",
       "  'And I felt a pang in my heart as I gave it to him .',\n",
       "  '“ You have plans that I don ’ t know about ... ”',\n",
       "  'But he didn ’ t respond .',\n",
       "  'He said to me : “ You know , my descent to earth ...',\n",
       "  'tomorrow will be its anniversary . ”',\n",
       "  'Then after a silence he went on : “ I came down very near here . ”',\n",
       "  'And he blushed .',\n",
       "  'And once again , without understanding why , I felt a peculiar sense of sorrow .',\n",
       "  'One question occurred to me however : “ So it wasn ’ t by chance that the morning I first met you , a week ago , you were out walking like that , all alone , a thousand miles from any inhabited region ?',\n",
       "  'You were going back to the place where you landed ? ”',\n",
       "  'The little prince blushed again .',\n",
       "  'And I added , hesitantly : “ Perhaps because of the anniversary ...',\n",
       "  '? ”',\n",
       "  'The little prince blushed once more .',\n",
       "  'He never answered questions , but when you blush , that means ‘ yes , ’ doesn ’ t it ?',\n",
       "  '“ Oh , ” I said to him , “ I ’ m worried — ” But he responded : “ Now you must work .',\n",
       "  'You must go back to your engine .',\n",
       "  'I will wait for you here .',\n",
       "  'Come back tomorrow evening .',\n",
       "  'But I wasn ’ t reassured .',\n",
       "  'I remembered the fox .',\n",
       "  'You run the risk of weeping a little , if you allow yourself to be tamed ...'],\n",
       " ['There was , next to the well , the ruin of an old stone wall .',\n",
       "  'When I came back from my work , the next evening , I saw from a distance my little price sitting on top of it , his feet hanging down .',\n",
       "  'And I heard him say : “ Don ’ t you remember then ? ”',\n",
       "  'he said .',\n",
       "  '“ This isn ’ t the exact spot . ”',\n",
       "  'Another voice must have answered him , because he replied : “ Yes , yes !',\n",
       "  'It ’ s the right day , but this isn ’ t the right place . ”',\n",
       "  'I continued my walk toward the wall .',\n",
       "  'I still didn ’ t see or hear anyone .',\n",
       "  'Yet the little prince replied again : ” ...',\n",
       "  'That ’ s right .',\n",
       "  'You ’ ll see where my tracks begin in the sand .',\n",
       "  'You just have to wait there for me .',\n",
       "  'I ’ ll be there tonight ... ”',\n",
       "  'I was twenty meters from the wall , and I still saw nothing .',\n",
       "  'The little prince spoke again , after a pause : “ Do you have good poison ?',\n",
       "  'Are you sure you won ’ t make me suffer too long ? ”',\n",
       "  'I froze , my heart skipped a beat ; but I still didn ’ t understand .',\n",
       "  '“ Now go away , ” he said , “ I want to come down from here . ”',\n",
       "  'I then lowered my eyes to the foot of the wall , and I leapt up !',\n",
       "  'Right there , facing the little prince was one of those yellow snakes that can kill you in thirty seconds flat .',\n",
       "  'Even as I dug around in my pocket to take out my revolver , I made a running step back .',\n",
       "  'But , at the noise I made , the snake let himself flow easily across the sand , like the dying spray of a fountain , and in no apparent hurry , slipped between the stones with a light metallic sound .',\n",
       "  'I reached the wall just in time to catch my little fellow in my arms , who was white as snow .',\n",
       "  '“ What ’ s going on here ?',\n",
       "  'Why are you talking with snakes ? ”',\n",
       "  'I ’ d loosened the golden muffler that he always wore .',\n",
       "  'I ’ d moistened his temples and had him drink .',\n",
       "  'And now I didn ’ t dare ask him anything more .',\n",
       "  'He looked at me gravely and put his arms around my neck .',\n",
       "  'I felt his heart beat like the heart of a dying bird , when shot with a rifle .',\n",
       "  'He said to me : “ I ’ m glad that you ’ ve found what was wrong with your engine .',\n",
       "  'Now you ’ ll be able to go back home — ” “ How did you know ! ”',\n",
       "  'I was just coming to tell him that , against all odds , my work had been successful .',\n",
       "  'He made no answer to my question , but he added : “ I ’ m also going back home today ... ”',\n",
       "  'Then he said sadly : “ It ’ s a lot further ...',\n",
       "  'it ’ s much more difficult ... ”',\n",
       "  'I felt very clearly that something extraordinary was happening .',\n",
       "  'I held him tightly in my arms like a small child ; and yet it seemed to me that he was plummeting down into an abyss , and that I could do nothing to restrain him ...',\n",
       "  'He had a serious look , as if lost far away .',\n",
       "  '“ I have your sheep .',\n",
       "  'And I have the box for the sheep .',\n",
       "  'And I have the muzzle ... ”',\n",
       "  'And he smiled sadly .',\n",
       "  'I waited a long while .',\n",
       "  'I could feel that he was reviving little by little .',\n",
       "  '“ My little fellow , ” I said to him , “ you ’ re afraid ... ”',\n",
       "  'He was afraid , of course .',\n",
       "  'But he laughed softly : “ I ’ ll be much more afraid this evening ... ”',\n",
       "  'Again I felt myself frozen by the sense of something irreparable .',\n",
       "  'And I knew that I couldn ’ t bear the idea of never hearing that laughter again .',\n",
       "  'For me , it was like a spring of fresh water in the desert .',\n",
       "  '“ Little fellow , ” I said , “ I want to hear you laugh again . ”',\n",
       "  'But he said to me : “ Tonight , it ’ ll be a year .',\n",
       "  'My star will be right above the spot where I came down to Earth , a year ago ... ”',\n",
       "  '“ Little fellow , is this all a bad dream - this business with the snake , and the meeting - place , and the star ...',\n",
       "  '? ”',\n",
       "  'But he didn ’ t answer my question .',\n",
       "  'He said to me : “ That which is important can ’ t be seen ... ”',\n",
       "  '“ I know ... ”',\n",
       "  '“ It ’ s like with the flower .',\n",
       "  'If you love a flower that ’ s on a star , it ’ s sweet to look at the sky at night .',\n",
       "  'All the stars are covered with flowers ... ”',\n",
       "  '“ I know ... ”',\n",
       "  '“ It ’ s like with the water .',\n",
       "  'The water you gave me to drink was like music , because of the pulley , and the rope ...',\n",
       "  'you remember ...',\n",
       "  'it was good . ”',\n",
       "  '“ I know . ”',\n",
       "  '“ At night you ’ ll look at the stars .',\n",
       "  'Where I live everything is too small for me to point out to you where my star is .',\n",
       "  'It ’ s better like that .',\n",
       "  'My star will be for you just one of the stars .',\n",
       "  'So you ’ ll love to look at all of the stars ...',\n",
       "  'they ’ ll all be your friends .',\n",
       "  'And , besides , I ’ m going to make you a present ... ”',\n",
       "  'He laughed again .',\n",
       "  '“ Ah , little fellow , dear little fellow !',\n",
       "  'I love to hear that laugh ! ”',\n",
       "  '“ That ’ s my present .',\n",
       "  'Just that .',\n",
       "  'It ’ ll be like with the water ... ”',\n",
       "  '“ What are you trying to say ? ”',\n",
       "  '“ Everyone has the same stars , but they are not the same to everyone .',\n",
       "  'For some , who are travelers , the stars are guides .',\n",
       "  'For others they are nothing but little lights .',\n",
       "  'For others , who are scholars , they are problems .',\n",
       "  'For my businessman they were wealth .',\n",
       "  'But none of these stars say anything back .',\n",
       "  'You will have the stars as no one else has them ... ”',\n",
       "  '“ What are you trying to say ? ”',\n",
       "  '“ When you look at the sky at night , because I ’ ll be living on one of them , because I ’ ll be laughing on one of them , for you it ’ ll be like all the stars are laughing .',\n",
       "  'You - only you - will have stars that can laugh ! ”',\n",
       "  'And he laughed again .',\n",
       "  '“ And when your sorrow is comforted ( time heals all wounds ) you ’ ll be glad to have known me .',\n",
       "  'You ’ ll always be my friend .',\n",
       "  'You ’ ll want to laugh with me .',\n",
       "  'And sometimes , you ’ ll open your window , just like that , for fun ...',\n",
       "  'And your friends will be very surprised to see you laughing whilst watching the sky .',\n",
       "  'So you ’ ll tell them , “ Yes , the stars always make me laugh ! ”',\n",
       "  'And they ’ ll think you ’ re crazy .',\n",
       "  'I will have played a dirty trick on you ...',\n",
       "  'And he laughed again .',\n",
       "  '“ It ‘ ll be as if I ’ d given you , instead of stars , lots and lots of little bells that can laugh ... ”',\n",
       "  'And he laughed some more .',\n",
       "  'Then he suddenly became serious again : “ Tonight ...',\n",
       "  'you know ...',\n",
       "  'don ’ t come . ”',\n",
       "  '“ I won ’ t leave you . ”',\n",
       "  '“ It ’ ll look as if I ’ m suffering ...',\n",
       "  'It ’ ll look a bit as if I ’ m dying .',\n",
       "  'It ’ s like that .',\n",
       "  'Don ’ t come to see that .',\n",
       "  'It ’ s not worth it ... ”',\n",
       "  '“ I won ’ t leave you . ”',\n",
       "  'But he was worried .',\n",
       "  '“ I ’ m telling you this — it ’ s also because of the snake .',\n",
       "  'He mustn ’ t bite you ...',\n",
       "  'Snakes are mean .',\n",
       "  'They can bite you just for fun ... ”',\n",
       "  '“ I won ’ t leave you . ”',\n",
       "  'But something reassured him : “ It ’ s true that they have no poison left for a second bite . ”',\n",
       "  'That night I didn ’ t see him set out .',\n",
       "  'He got away without making a sound .',\n",
       "  'When I managed to catch him up , he was walking along determinedly , at a brisk pace .',\n",
       "  'He said to me only : “ Oh !',\n",
       "  'You came ... ”',\n",
       "  'And he took me by the hand .',\n",
       "  'But he was still worrying .',\n",
       "  '“ You ’ ve made a mistake .',\n",
       "  'You ’ ll suffer .',\n",
       "  'It ’ ll look as if I ’ m dead , and that won ’ t be true ...',\n",
       "  '” I said nothing .',\n",
       "  '“ You understand .',\n",
       "  'It ’ s too far .',\n",
       "  'I can ’ t carry this body with me .',\n",
       "  'It ’ s too heavy . ”',\n",
       "  'I said nothing .',\n",
       "  '“ But it ’ ll be like an old abandoned shell .',\n",
       "  'There ’ s nothing sad about old shells ... ”',\n",
       "  'I said nothing .',\n",
       "  'He got a bit discouraged .',\n",
       "  'But he made one more effort : “ You know , it ’ ll be nice .',\n",
       "  'I ’ ll also look at the stars .',\n",
       "  'All the stars will be wells with a rusty pulley .',\n",
       "  'All the stars will pour out fresh water for me to drink ... ”',\n",
       "  'I said nothing .',\n",
       "  '“ It ’ ll be so much fun !',\n",
       "  'You ’ ll have five hundred million little bells , and I ’ ll have five hundred million springs of fresh water ... ”',\n",
       "  'And then he too was silent , because he was crying .',\n",
       "  '“ Here ’ s the place .',\n",
       "  'Let me go on by myself . ”',\n",
       "  'And he sat down because he was afraid .',\n",
       "  'He said : “ You know - my flower ...',\n",
       "  'I ’ m responsible for her .',\n",
       "  'And she ’ s so weak !',\n",
       "  'And she ’ s so naive !',\n",
       "  'She has four thorns , of no use at all , to protect herself against the entire world ... ”',\n",
       "  'I sat down too because I was no longer able to stand .',\n",
       "  'He said : “ There ...',\n",
       "  'that ’ s everything ... ”',\n",
       "  'He hesitated a bit , and then stood back up .',\n",
       "  'He took one step .',\n",
       "  'I couldn ’ t move .',\n",
       "  'There was nothing but a yellow flash close to his ankle .',\n",
       "  'He remained motionless for an instant .',\n",
       "  'He didn ’ t cry out .',\n",
       "  'He fell as gently as a tree falls .',\n",
       "  'There was not even any sound , because of the sand .',\n",
       "  'And now of course , it ’ s already been six years ...',\n",
       "  'I have never yet told this story .',\n",
       "  'The companions who met me were very happy to see me alive again .',\n",
       "  'I was sad , but I told them : “ It ’ s because I ’ m tired ... ”',\n",
       "  'Now my sorrow is comforted a little .',\n",
       "  'I mean ...',\n",
       "  'not entirely .',\n",
       "  'But I do know that he got back to his planet , because at daybreak I didn ’ t find his body .',\n",
       "  'It wasn ’ t a very heavy body ...',\n",
       "  'And I love to listen to the stars at night .',\n",
       "  'It ’ s just like five hundred million little bells ...',\n",
       "  'But there is one extraordinary thing .',\n",
       "  'When I drew the muzzle for the little prince , I forgot to add the leather strap to it .',\n",
       "  'He would never have been able to fasten it to the sheep .',\n",
       "  'So I wonder : what happened on his planet ?',\n",
       "  'It may well be the sheep ate the flower ...',\n",
       "  'Sometimes I tell myself : “ Surely not !',\n",
       "  'The little prince shuts his flower under her glass dome every night , and he watches over his sheep very carefully ... ”',\n",
       "  'Then I ’ m happy .',\n",
       "  'And all the stars laugh sweetly .',\n",
       "  'Other times I tell myself : “ Everyone is absent - minded at some point , and that ’ s all it takes !',\n",
       "  'One evening he would ’ ve forgotten the glass dome , or maybe the sheep got out quietly during the night ... ”',\n",
       "  'And then the little bells turn to tears ...',\n",
       "  'Herein lies a great mystery .',\n",
       "  'For you , who also love the little prince , just like for me , nothing in the universe is the same if somewhere out there , a sheep that we have never seen has — has it ?',\n",
       "  '- eaten a rose ...',\n",
       "  'Look at the sky .',\n",
       "  'Ask yourselves : Has the sheep - yes or no - eaten the flower ?',\n",
       "  'And you will see how everything changes ...',\n",
       "  'And no grownup will ever understand that this is a matter of such importance !',\n",
       "  'This , to me , is the most beautiful and most sad landscape in the world .',\n",
       "  'It ’ s the same landscape as the one on the previous page , but I have drawn it again to show it to you properly .',\n",
       "  'It ’ s here that the little prince appeared on Earth , and then disappeared .',\n",
       "  'Look at this landscape carefully , so as to be sure to recognize it if one day you travel in Africa , in the desert .',\n",
       "  'And if you happen to pass by there , I beg you , don ’ t hurry on , wait a while exactly under the star .',\n",
       "  'If a child then comes to you , if he laughs , if he has golden hair , if he doesn ’ t respond when questioned , you ’ ll easily guess who it is .',\n",
       "  'So think of me !',\n",
       "  'Save me from this sorrow : write to me quickly , to tell me he ’ s back ...']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator_list = [[sent.lower() for sent in text] for text in iterator_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’',\n",
       "  'it showed a boa constrictor swallowing a wild animal .',\n",
       "  'here is a copy of the drawing .',\n",
       "  'it said in the book : “ boa constrictors swallow their prey whole , without chewing .',\n",
       "  'then they are not able to move , and they sleep for the six months it takes for digestion . ”',\n",
       "  'so i thought a lot about the adventures of the jungle and , in turn , i managed , with a coloured pencil , to make my first drawing .',\n",
       "  'my drawing number one .',\n",
       "  'it looked like this : i showed my masterpiece to the grownups and i asked them if my drawing frightened them .',\n",
       "  'they answered me : “ why would anyone be frightened by a hat ? ”',\n",
       "  'my drawing was not of a hat .',\n",
       "  'it showed a boa constrictor digesting an elephant .',\n",
       "  'i then drew the inside of the boa constrictor , so that the grownups could understand .',\n",
       "  'they always need to have things explained .',\n",
       "  'my drawing number two looked like this : the grownups advised me to leave aside drawings of boa constrictors , open or closed , and to apply myself instead to geography , history , arithmetic and grammar .',\n",
       "  'thus i abandoned , at the age of six , a magnificent career as a painter .',\n",
       "  'i was discouraged by the failure of my drawing number one and of my drawing number two .',\n",
       "  'grownups never understand anything by themselves , and it ’ s tiresome for children to always explain things for them again and again .',\n",
       "  'so i had to choose another profession , and i learned to fly airplanes .',\n",
       "  'i flew a little in many places around the world .',\n",
       "  \"and geography , it ' s true , has served me well .\",\n",
       "  'i could recognize , at first glance , china from arizona .',\n",
       "  'it ’ s very useful if you get lost at night .',\n",
       "  'i have had , during my life , a lot of contact with many persons of consequence .',\n",
       "  'i have lived a lot amongst the grownups .',\n",
       "  'i have seen them from close up .',\n",
       "  'it hasnt much improved my opinion of them .',\n",
       "  \"whenever i met one of them that seemed a bit more clear - sighted , i tried the experiment of showing them my drawing number one , that i ' ve always kept .\",\n",
       "  'i wanted to know if they were really a person of true understanding .',\n",
       "  \"but they always responded : “ it ' s a hat . ”\",\n",
       "  'so i would never speak to them of boa constrictors , nor of primeval forests , nor of the stars .',\n",
       "  'i put myself at their level .',\n",
       "  'i talked to them about bridge , golf , politics and neckties .',\n",
       "  'and the grownup was glad to know such a sensible man .',\n",
       "  'so i lived alone , without anyone i could really talk to , until a breakdown in the sahara desert , six years ago .',\n",
       "  'something had broken in my engine .',\n",
       "  'and as i had with me neither a mechanic nor any passengers , i readied myself to try and carry out , all alone , the difficult repairs .',\n",
       "  'for me it was a matter of life or death .',\n",
       "  'i had hardly enough water to drink for a week .',\n",
       "  'the first night i went to sleep on the sand , a thousand miles from any human habitation .',\n",
       "  'i was more isolated than a shipwrecked sailor on a raft in the middle of the ocean .',\n",
       "  'so you can imagine my surprise when at daybreak , a funny little voice woke me up .',\n",
       "  'it said : “ please ...',\n",
       "  'draw me a sheep ! ”',\n",
       "  '“ what ? ”',\n",
       "  '“ draw me a sheep ! ”',\n",
       "  'i jumped to my feet as if i ’ d been struck by lightning .',\n",
       "  'i rubbed my eyes .',\n",
       "  'i took a good look around me .',\n",
       "  'and i saw a quite extraordinary little man , who was examining me seriously .',\n",
       "  'here is the best portrait that , later , i managed to do of him .',\n",
       "  'but my drawing , of course , is much less charming than its model .',\n",
       "  \"it ' s not my fault .\",\n",
       "  \"i was discouraged in my career as a painter by the grownups , at the age of six , and i hadn ' t learned to draw anything except boa constrictors , closed and open .\",\n",
       "  'i stared at this sudden apparition wide eyed with astonishment .',\n",
       "  'remember that i was a thousand miles from any inhabited region .',\n",
       "  'and yet this little fellow seemed neither lost , nor half - dead with fatigue , nor starved or dying of thirst or fear .',\n",
       "  'he looked nothing like a child lost in the middle of the desert , a thousand miles from any inhabited region .',\n",
       "  'when i finally managed to speak , i said : “ but — what are you doing here ? ”',\n",
       "  'and he repeated , very slowly , as if it was something very serious : “ please ...',\n",
       "  'draw me a sheep ... ”',\n",
       "  'when a mystery is too overpowering , one dare not disobey .',\n",
       "  'absurd as it seemed to me a thousand miles from any human habitation and in danger of death , i took out of my pocket a sheet of paper and a pen .',\n",
       "  'but then i remembered that i had mainly studied geography , history , arithmetic and grammar , and i told the little fellow ( a little crossly ) that i didn ’ t know how to draw .',\n",
       "  \"he replied : “ it doesn ' t matter .\",\n",
       "  'draw me a sheep . ”',\n",
       "  'as i ’ d never drawn a sheep , i redrew for him one of the only two drawings that i was capable of .',\n",
       "  'the one of the closed boa constrictor .',\n",
       "  'and i was astounded to hear the little fellow respond : “ no !',\n",
       "  'no !',\n",
       "  'i don ’ t want an elephant inside a boa constrictor .',\n",
       "  'a boa constrictor is very dangerous , and an elephant is very cumbersome .',\n",
       "  'where i live everything is very small .',\n",
       "  'i need a sheep .',\n",
       "  'draw me a sheep . ”',\n",
       "  'so i drew .',\n",
       "  'he looked carefully , then said : “ no !',\n",
       "  'this one ’ s already very sick .',\n",
       "  'make another one . ”',\n",
       "  'i drew again : my friend smiled gently and indulgently : “ you can see yourself ...',\n",
       "  \"this isn ’ t a sheep , it ' s a ram .\",\n",
       "  'it has horns ...',\n",
       "  '“ so once again i redid my drawing : but it was rejected , like the previous ones : “ this one ’ s too old .',\n",
       "  'i want a sheep that will live a long time . ”',\n",
       "  'so , getting impatient , as i was eager to start dismantling my engine , i hastily sketched this drawing : and i snapped : “ this here is the box .',\n",
       "  'the sheep you want is inside . ”',\n",
       "  \"but i was very surprised to see the face of my young judge light up : “ it ' s exactly the way i wanted !\",\n",
       "  'do you think this sheep needs a lot of grass ? ”',\n",
       "  '“ why ? ”',\n",
       "  \"“ because where i ' m from everything is very small ... ”\",\n",
       "  '“ there will certainly be enough .',\n",
       "  'i gave you a very small sheep . ”',\n",
       "  'he leaned his head towards the drawing : “ not that small ...',\n",
       "  'look !',\n",
       "  \"he ' s fallen asleep ... ”\",\n",
       "  \"and that ' s how i met the little prince .\",\n",
       "  'it took me a long time to find out where he came from .',\n",
       "  'the little prince , who asked me many questions , never seemed to hear my own .',\n",
       "  'it was the words spoken by chance that , little by little , revealed everything to me .',\n",
       "  \"so , when he saw my airplane for the first time ( i won ’ t draw my airplane , it would be a drawing far too complicated for me ) , he asked me : “ what ' s that thing there ? ”\",\n",
       "  \"“ it ' s not a thing .\",\n",
       "  'it flies .',\n",
       "  \"it ' s an airplane .\",\n",
       "  'it ’ s my airplane . ”',\n",
       "  'and i was proud to have him know that i could fly .',\n",
       "  'then he cried : “ what ?',\n",
       "  'you fell from the sky ! ”',\n",
       "  '“ yes , ” i said modestly .',\n",
       "  '“ oh !',\n",
       "  \"that ' s funny !\",\n",
       "  '... ”',\n",
       "  'and the little prince broke into a lovely peal of laughter , which irritated me very much .',\n",
       "  'i prefer people to take my misfortunes seriously .',\n",
       "  'then he added : “ so , you also come from the sky !',\n",
       "  'what planet are you from ? ”',\n",
       "  'i caught a glimpse into the mystery of his presence , and i asked abruptly : “ so you come from another planet then ? ”',\n",
       "  'but he didn ’ t answer .',\n",
       "  \"he shook his head slowly whilst looking at my airplane : “ it ' s true that you can ' t have come from far away in that thing ... ”\",\n",
       "  'and he drifted into a daydream which lasted a long while .',\n",
       "  'then , taking my sheep out of his pocket , he sank himself into the contemplation of his treasure .',\n",
       "  'you can imagine how my curiosity was aroused by this small disclosure about ‘ the other planets . ’',\n",
       "  'so i tried to find out more : “ where are you from my little fellow ?',\n",
       "  'where ’ s this ‘ where i live ’ of yours ?',\n",
       "  'where do you take my sheep off to ? ”',\n",
       "  \"after a reflective silence he answered : “ what ' s good about the box you ’ ve given me is that at night , he can use it as a house . ”\",\n",
       "  '“ that ’ s right .',\n",
       "  \"and if you ’ re good , i ' ll give you a rope to tie him up with during the day .\",\n",
       "  'and a stake . ”',\n",
       "  'the offer seemed to shock the little prince : “ tie him up ?',\n",
       "  'what a funny idea ! ”',\n",
       "  \"“ but if you don ' t tie him up , he ’ ll wander off , and get lost . ”\",\n",
       "  'my friend broke into another peal of laughter : “ where do you think he ’ d go ! ”',\n",
       "  '“ anywhere .',\n",
       "  'straight ahead ... ”',\n",
       "  'then the little prince said gravely : “ that doesn ’ t matter ; where i live , everything is so small ! ”',\n",
       "  \"and perhaps with a hint of sadness , he added : “ straight ahead you can ' t go far ... ”\"],\n",
       " ['i thus learned a second very important thing : that his home planet was barely bigger than a house !',\n",
       "  \"it didn ' t surprise me much .\",\n",
       "  'i knew that , apart from the large planets like the earth , jupiter , mars , and venus , which have been given names , there are hundreds of others that are sometimes so small that one has great difficulty in spotting them through the telescope .',\n",
       "  'when an astronomer discovers one of these , he gives it a number for a name .',\n",
       "  'he might call it for example “ asteroid three hundred and twenty - five . ”',\n",
       "  'i have serious reason to believe that the planet from where the little prince came is the asteroid b - six hundred and twelve .',\n",
       "  'this asteroid has only been seen through a telescope once , in one thousand , nine hundred and nine , by a turkish astronomer .',\n",
       "  'he had then given a big presentation on his discovery at an international astronomy conference .',\n",
       "  'but nobody had believed him because of his outfit .',\n",
       "  'grownups are like that .',\n",
       "  'fortunately for the reputation of asteroid b - six hundred and twelve , a turkish dictator imposed on his people , on pain of death , to dress themselves in the european fashion .',\n",
       "  'the astronomer gave his presentation again in one thousand , nine hundred and twenty , dressed very stylishly .',\n",
       "  'and this time everybody believed him .',\n",
       "  'if i have told you these details about the asteroid b - six hundred and twelve , and revealed to you its number , it ’ s because of the grownups .',\n",
       "  'grownups love numbers .',\n",
       "  'when you talk to them about a new friend , they never ask you about any of the important things .',\n",
       "  'they never ask you : “ how does his voice sound ?',\n",
       "  'what games does he like best ?',\n",
       "  'does he collect butterflies ? ”',\n",
       "  'they ask : “ how old is he ?',\n",
       "  'how many brothers does he have ?',\n",
       "  'how much does he weigh ?',\n",
       "  'how much money does his father make ? ”',\n",
       "  'only then do they think they know him .',\n",
       "  'if you said to the grownups : “ i saw a beautiful red brick house with geraniums by the windows and doves on the roof ...',\n",
       "  ', ” they wouldn ’ t be able to picture this house in their minds .',\n",
       "  'you ’ d have to tell them : “ i saw a hundred thousand franc house . ”',\n",
       "  'and they ’ d cry : “ how pretty ! ”',\n",
       "  'so if you were to say to them : “ the proof that the little prince existed is that he was charming , he laughed , and he wanted a sheep .',\n",
       "  'if someone wants a sheep , that proves they exist , ” they ’ d shrug their shoulders and treat you like a child .',\n",
       "  'but if you were to say : “ the planet he came from is the asteroid b - six hundred and twelve ” , they ’ d be convinced , and leave you in peace and spare you their questions .',\n",
       "  'they ’ re like that .',\n",
       "  'don ’ t blame them .',\n",
       "  'children should be forgiving towards the grownups .',\n",
       "  \"but , of course , those of us who understand life , we don ' t much care for numbers !\",\n",
       "  'i ’ d have liked to begin this story in the same way as a fairy tale .',\n",
       "  'i ’ d have liked to say : “ once upon a time , there was a little prince who lived on a planet not much bigger than himself , and who needed a friend ... ”',\n",
       "  'for those who understand life , it would have seemed much more natural .',\n",
       "  'for i don ’ t want my book to be read lightly .',\n",
       "  'i feel so much sadness in recounting these memories .',\n",
       "  \"it ' s already been six years since my friend left with his sheep .\",\n",
       "  'if i try to describe him here , it ’ s so as not to forget him .',\n",
       "  'it ’ s sad to forget a friend .',\n",
       "  'not everyone has had a friend .',\n",
       "  'and if i forgot him , i could become like the grownups who are only interested in numbers .',\n",
       "  'so that ’ s why i have again bought a box of paints and some pencils .',\n",
       "  \"it ' s hard to take up drawing again at my age , when i have only ever attempted to draw a boa constrictor , closed and open , at the age of six !\",\n",
       "  \"i ' ll try , of course , to make my portraits as lifelike as possible .\",\n",
       "  \"but i ’ m not quite sure i ' ll succeed .\",\n",
       "  'some drawings go alright ; others don ’ t look like their subjects .',\n",
       "  'i also get the size a bit wrong .',\n",
       "  'here the little prince is too big .',\n",
       "  'there he ’ s too small .',\n",
       "  'i ’ m also not sure about the colour of his outfit .',\n",
       "  'so i fumble along somehow , as best i can .',\n",
       "  'i will make mistakes on certain important points too .',\n",
       "  'but you ’ ll have to forgive me that .',\n",
       "  'my friend never gave explanations .',\n",
       "  'perhaps he thought i was just like himself .',\n",
       "  \"but i , unfortunately , don ' t know how to see sheep through boxes .\",\n",
       "  'perhaps i ’ m a bit like the grownups .',\n",
       "  'i must have got older .',\n",
       "  'every day i ’ d learn something about his planet , the departure , and the trip .',\n",
       "  'the information came slowly , as his thoughts wandered .',\n",
       "  'it was in this way that , on the third day , i came to know of the tragedy of the baobabs .',\n",
       "  'this time again it was thanks to the sheep , because the little prince asked me abruptly , as if seized by a grave doubt : “ it ’ s true , isn ’ t it , that sheep eat shrubs ? ”',\n",
       "  '“ yes .',\n",
       "  \"it ' s true . ”\",\n",
       "  '“ oh !',\n",
       "  'i am glad ! ”',\n",
       "  'i didn ’ t understand why it was so important that sheep eat shrubs .',\n",
       "  'but the little prince added : “ then it follows they also eat baobabs ? ”',\n",
       "  \"i pointed out to the little prince that baobabs were not shrubs , but trees as big as churches , and that even if he took with him a whole herd of elephants , the herd wouldn ' t manage to eat up one single baobab .\",\n",
       "  'the idea of the herd of elephants made the little prince laugh : “ they ’ d have to be piled up on top of each other ... ”',\n",
       "  'but he remarked wisely : “ the baobab trees , before they grow up , start off small . ”',\n",
       "  \"“ that ' s right !\",\n",
       "  'but why do you want the sheep to eat the little baobabs ? ”',\n",
       "  'he replied : “ oh , come on ! ”',\n",
       "  'as if it were obvious .',\n",
       "  'and it took me a great mental effort to understand this problem on my own , without any help .',\n",
       "  'and indeed , on the planet of the little prince there were , like on all planets , both good plants and bad plants .',\n",
       "  'and therefore , both good seeds from good plants and bad seeds from bad plants .',\n",
       "  'but seeds are invisible .',\n",
       "  'they sleep secretly deep in the earth until , on a whim , one of them decides to wake up .',\n",
       "  'then it elongates and grows , timidly at first , toward the sun : a charming little harmless sprig .',\n",
       "  'if it ’ s a sprig of radish or rose bush , you can let it grow as it likes .',\n",
       "  'but if it ’ s a bad plant , one must pull the plant out straight away , as soon as it can be recognised .',\n",
       "  'now there were some terrible seeds on the planet of the little prince ...',\n",
       "  'there were the seeds of baobab trees .',\n",
       "  'the soil of the planet was infested with them .',\n",
       "  'a baobab , if you get to it too late , can never be got rid of .',\n",
       "  'it takes over the entire planet .',\n",
       "  'it pierces it with its roots .',\n",
       "  'and if the planet is too small , and if there are too many baobabs , they shatter it to pieces .',\n",
       "  \"“ it ' s a matter of discipline , ” the little prince told me later .\",\n",
       "  '“ after grooming oneself in the morning , the planet must be carefully groomed .',\n",
       "  'you must see to it that you regularly pull out the baobabs as soon as they can be told apart from the rose bushes , to which they look very similar when they ’ re very young .',\n",
       "  \"it ' s a very boring job , but very easy . ”\",\n",
       "  'and one day he suggested that i apply myself to making a beautiful drawing , so that the children from where i come from would understand all this .',\n",
       "  '“ if one day they travel , ” he said to me , “ it could come in useful .',\n",
       "  \"sometimes there ’ s no harm in postponing one ' s work .\",\n",
       "  'but in the case of baobabs , that always leads to a catastrophe .',\n",
       "  'i used to know a planet inhabited by a lazy man .',\n",
       "  'he had neglected three little bushes ... ”',\n",
       "  'and based on what the little prince told me , i drew this planet .',\n",
       "  'i don ’ t like to sound like a moralist .',\n",
       "  'but the danger of the baobabs is so little understood , and the risks run by anyone who might get lost on an asteroid are so large that , for once , i am breaking my normal reserve .',\n",
       "  'i say : “ children !',\n",
       "  'beware of baobabs ! ”',\n",
       "  \"it ’ s to warn my friends of the danger they ' ve long been skirting , like myself , without knowing it , that i have worked so hard on this drawing .\",\n",
       "  'the lesson which i pass on by this means was worth the effort .',\n",
       "  \"you might be wondering : why is it that in this book there aren ' t any other drawings as impressive as the drawing of the baobabs ?\",\n",
       "  'the answer is simple : i tried but i couldn ’ t succeed .',\n",
       "  'when i drew the baobabs i was spurred on by a sense of urgency .',\n",
       "  'oh !',\n",
       "  'little prince , i came to understand , gradually , in this way , your sad life .',\n",
       "  'for a long time your only entertainment was the softness of the sunsets .',\n",
       "  'i learned this new detail on the fourth day , in the morning , when you said to me : “ i ’ m very fond of sunsets .',\n",
       "  'let ’ s go and see a sunset now ... ”',\n",
       "  '“ but we have to wait ... ”',\n",
       "  '“ wait for what ? ”',\n",
       "  '“ wait until the sun goes down . ”',\n",
       "  'you seemed surprised at first , and then you chuckled at yourself .',\n",
       "  'and you said : “ i think myself at home still ! ”',\n",
       "  'indeed .',\n",
       "  'when it ’ s noon in the united states , the sun , everybody knows , is setting over france .',\n",
       "  'it would suffice to be able to go to france in one minute to be able to see a sunset .',\n",
       "  'unfortunately , france is much too far away .',\n",
       "  'but on your tiny planet , all you needed was to move your chair a few steps .',\n",
       "  'and you watched the twilight falling whenever you liked ...',\n",
       "  'one day i saw the sunset forty - four times !',\n",
       "  'and a little later you added : “ you know ...',\n",
       "  'you love the sunset , when you ’ re really sad ... ”',\n",
       "  '“ the day you saw it forty - four times , were you were really that sad then ? ”',\n",
       "  'but the little prince made no reply .'],\n",
       " [\"on the fifth day , again thanks to the sheep , this secret of the little prince ' s life was revealed to me .\",\n",
       "  'he asked abruptly , without anything leading up to it , as if it was the result of a long silent meditation on a problem : “ if a sheep eats shrubs , then does it eat flowers too : “ a sheep eats everything it finds . ”',\n",
       "  '“ even flowers that have thorns ? ”',\n",
       "  '“ yes , even flowers that have thorns . ”',\n",
       "  '“ what are the thorns for then ? ”',\n",
       "  \"i didn ' t know the answer .\",\n",
       "  'i was very busy trying to unscrew a bolt in my engine that had got stuck .',\n",
       "  'i was very worried because my breakdown was beginning to appear to be very serious , and i had so little drinking water left that i had to fear the worst .',\n",
       "  '“ what are the thorns for then ? ”',\n",
       "  'the little prince never let go of a question , once he had asked it .',\n",
       "  'i was upset over the bolt and i said the first thing that came into my head : “ the thorns are of no use at all .',\n",
       "  'flowers have thorns just for spite ! ”',\n",
       "  '“ oh ! ”',\n",
       "  'but after a moment of silence , he exclaimed with a sort of resentment : “ i don ’ t believe you !',\n",
       "  'flowers are weak creatures .',\n",
       "  'they ’ re naive .',\n",
       "  'they reassure themselves as best they can .',\n",
       "  'they think themselves frightful with their thorns ... ”',\n",
       "  'i made no reply .',\n",
       "  \"at that moment i was thinking to myself : “ if this bolt won ’ t budge , i ' ll knock it out with a hammer . ”\",\n",
       "  'the little prince interrupted my thoughts again : “ and you actually believe that flowers — ” “ no !',\n",
       "  'no !',\n",
       "  'i don ’ t believe it at all !',\n",
       "  'i answered the first thing that came to my mind .',\n",
       "  'i , myself , am busy with matters of consequence ! ”',\n",
       "  'he looked at me dumbfounded .',\n",
       "  '“ matters of consequence ! ”',\n",
       "  'he watched me , hammer in hand and my fingers black with grease , leaning on an object that would have seemed to him very ugly .',\n",
       "  '“ you talk just like the grownups ! ”',\n",
       "  'that made me feel a little ashamed .',\n",
       "  'but he went on relentlessly : “ you confuse everything ...',\n",
       "  'you mix everything up ! ”',\n",
       "  'he was really very angry .',\n",
       "  'he shook his golden curls in the breeze : “ i know a planet where there is a red faced gentleman .',\n",
       "  'he has never smelled a flower .',\n",
       "  'he has never looked at a star .',\n",
       "  'he has never loved anyone .',\n",
       "  'he has never done anything but sums .',\n",
       "  'and all day long he repeats just like you : ‘ i am busy with matters of consequence ! ’',\n",
       "  'and that makes him swell up with pride .',\n",
       "  'but this is not a man , he ’ s a mushroom ! ”',\n",
       "  '“ a what ? ”',\n",
       "  '“ a mushroom ! ”',\n",
       "  'the little prince was now white with rage .',\n",
       "  '“ flowers have been growing thorns for millions of years .',\n",
       "  'for millions of years , the sheep have eaten the flowers all the same .',\n",
       "  \"and it ' s not a matter of consequence to try to understand why they take so much trouble to grow thorns which are never of any use ?\",\n",
       "  'is the war between the flowers and sheep not important ?',\n",
       "  'is it not of more consequence and more important than the sums of a fat red faced gentleman ?',\n",
       "  \"and if i myself know of a unique flower , which grows nowhere but on my planet , that a little sheep can destroy in one stroke , just like that , one morning , without realising what he ' s done , is that not important ! ”\",\n",
       "  'he blushed , and continued : “ if someone loves a flower of which just one specimen exists amongst the millions and millions of stars , it ’ s enough to make him happy when he looks at them .',\n",
       "  'he can say : ‘ my flower is out there somewhere ... ’',\n",
       "  'but if the sheep eats the flower , for him it ’ s as if suddenly all the stars have gone out !',\n",
       "  'and you think that ’ s not important !',\n",
       "  'he couldn ’ t say anything more .',\n",
       "  'he suddenly burst into tears .',\n",
       "  'night had fallen .',\n",
       "  'i had put down my tools .',\n",
       "  'of what moment was my hammer , my bolt , or thirst , or death ?',\n",
       "  'there was on a star , on a planet , my planet , earth , a little prince to be comforted !',\n",
       "  'i took him in my arms .',\n",
       "  'i rocked him .',\n",
       "  'i said : “ the flower that you love isn ’ t in danger ...',\n",
       "  'i ’ ll draw you a muzzle for your sheep ...',\n",
       "  \"i ' ll draw you a railing for your flower ...\",\n",
       "  'i ... ”',\n",
       "  \"i wasn ' t sure what to say .\",\n",
       "  'i felt very awkward .',\n",
       "  'i didn ’ t know how to reach him , where to find him ...',\n",
       "  \"it ' s so secretive , the land of tears .\",\n",
       "  'i learned very quickly to know this flower better .',\n",
       "  \"there had always been very simple flowers on the planet of the little prince , decorated with a single row of petals , that didn ' t take up any space , and didn ’ t bother anyone .\",\n",
       "  'they would appear one morning in the grass , and by evening they ’ d have faded away .',\n",
       "  'but this one had sprouted one day , from a seed blown in from no one knows where , and the little prince had watched very closely this sprout that was not like the other sprouts .',\n",
       "  'it could have been a new kind of baobab .',\n",
       "  'but the shrub soon stopped growing and began to produce a flower .',\n",
       "  'the little prince , who witnessed the appearance of a huge bud , felt that a miraculous apparition must emerge from it , but the flower never stopped preparing for her future beauty , safe in her green chamber .',\n",
       "  'she chose her colours carefully .',\n",
       "  'she dressed slowly ; she arranged her petals one by one .',\n",
       "  'she did not want to come out all rumpled , like the poppies .',\n",
       "  'she would only want to appear in the full radiance of her beauty .',\n",
       "  'oh yes !',\n",
       "  'she was a very flirtatious creature !',\n",
       "  'and her mysterious adornment had thus lasted for days and days .',\n",
       "  'then one morning , exactly at sunrise , she suddenly showed herself .',\n",
       "  'and , after having worked with such care and attention to detail , she said with a yawn : “ oh !',\n",
       "  'i have only just woken up ...',\n",
       "  'i do apologize ...',\n",
       "  'i am not yet presentable ” the little prince couldn ’ t restrain his admiration : “ you ’ re so beautiful ! ”',\n",
       "  '“ am i not ? ”',\n",
       "  'the flower responded , sweetly .',\n",
       "  '“ and i was born at the same moment as the sun ...',\n",
       "  '” the little prince guessed easily enough that she was not very modest , but how moving she was !',\n",
       "  \"“ it ' s time , i think , for breakfast , ” she added an instant later , “ if you would have the kindness to think of my needs .\",\n",
       "  'and the little prince , completely abashed , having gone to look for a sprinkling can of fresh water , tended to the flower .',\n",
       "  'and like that , she had soon begun to torment him with her vanity .',\n",
       "  'one day , for example , speaking of her four thorns , she told the little prince : “ let them come , the tigers , with their claws ! ”',\n",
       "  '“ there aren ’ t any tigers on my planet , ” the little prince objected , “ and tigers don ’ t eat weeds . ”',\n",
       "  '“ i am not a weed , ” the flower replied sweetly .',\n",
       "  '“ please forgive me ...',\n",
       "  '“ i do not fear tigers , but i detest drafts .',\n",
       "  \"you wouldn ' t happen to have a screen ? ”\",\n",
       "  '“ detests drafts ...',\n",
       "  'that ’ s bad luck for a plant , ” remarked the little prince .',\n",
       "  '“ what a very complicated flower .',\n",
       "  '“ in the evening you will put me under a glass dome .',\n",
       "  'it is very cold where you live .',\n",
       "  'where i come from ... ”',\n",
       "  'but she interrupted herself .',\n",
       "  'she had come in the form of a seed .',\n",
       "  'she couldn ’ t have known anything of other worlds .',\n",
       "  'humiliated at having been caught out on a lie so naive , she coughed two or three times to imply the little prince was in the wrong .',\n",
       "  '“ the screen ...',\n",
       "  '? ”',\n",
       "  '“ i was just going to look for it when you spoke to me ! ”',\n",
       "  'then she forced a cough to inflict still more remorse .',\n",
       "  'so the little prince , despite the good will of his love , had soon come to doubt her .',\n",
       "  'he had taken seriously words of no importance , and had become very unhappy .',\n",
       "  '“ i shouldn ’ t have listened to her , ” he told me one day , “ you should never listen to the flowers .',\n",
       "  'we must look at them and breathe their fragrance .',\n",
       "  'mine perfumed my whole planet , but i didn ’ t know how to take pleasure in it .',\n",
       "  \"this business of the claws , which annoyed me so much , should only have filled my heart with tenderness and pity ” he continued his confidences : “ i didn ' t know how to understand !\",\n",
       "  'i should have her judged by her deeds and not by her words .',\n",
       "  'she overwhelmed me with her fragrance and light .',\n",
       "  'i should never have run away !',\n",
       "  'i should have seen the tenderness behind her contrivances .',\n",
       "  'flowers are so contradictory !',\n",
       "  'but i was too young to know how to love her . ”',\n",
       "  'i think that for his escape he took advantage of a migration of a flock of wild birds .',\n",
       "  'on the morning of his departure he put his planet in perfect order .',\n",
       "  'he carefully swept out his active volcanoes .',\n",
       "  'he owned two active volcanoes ; it was very convenient for heating his breakfast in the morning .',\n",
       "  'he also owned an extinct volcano .',\n",
       "  'but , as he used to say , “ you never know ! ”',\n",
       "  'so he cleaned out the extinct volcano , too .',\n",
       "  'if they are well cleaned out , volcanoes burn slowly and steadily , without any eruptions .',\n",
       "  'volcanic eruptions are like fires in a chimney .',\n",
       "  \"on our earth we ' re obviously much too small to clean out our volcanoes .\",\n",
       "  'that ’ s why they cause us no end of trouble .',\n",
       "  'the little prince also pulled up , with a hint of sadness , the last little shoots of the baobabs .',\n",
       "  'he believed he would never return .',\n",
       "  'but all these familiar tasks seemed , on that morning , very precious .',\n",
       "  'and as he watered the flower one last time , and prepared to shelter her under her dome , he found himself close to tears .',\n",
       "  '“ goodbye , ” he said to the flower .',\n",
       "  'but she didn ’ t answer .',\n",
       "  '“ goodbye , ” he said again .',\n",
       "  'the flower coughed .',\n",
       "  'but it was not because she had a cold .',\n",
       "  '“ i was silly , ” she said finally .',\n",
       "  '“ i ask your forgiveness .',\n",
       "  'try to be happy . ”',\n",
       "  'he was surprised by this absence of reproaches .',\n",
       "  'he stood there all bewildered , the dome held in mid - air .',\n",
       "  'he didn ’ t understand this quiet sweetness .',\n",
       "  '“ of course i love you , ” the flower said to him .',\n",
       "  '“ it ’ s my fault that you didn ’ t know .',\n",
       "  'that is of no importance .',\n",
       "  'but you have been just as foolish as i have .',\n",
       "  'try to be happy ...',\n",
       "  'let the dome be .',\n",
       "  'i do not want it anymore . ”',\n",
       "  '“ but the wind — ” “ my cold is not all that bad ...',\n",
       "  'the cool night air will do me good .',\n",
       "  'i am a flower . ”',\n",
       "  '“ but the animals — ” “ i will have to endure two or three caterpillars if i wish to become acquainted with the butterflies .',\n",
       "  'it seems that they are very beautiful .',\n",
       "  'and otherwise who else will come to visit me ?',\n",
       "  'you will be far away .',\n",
       "  'as for the large animals , i am not at all afraid of anything .',\n",
       "  'i have my claws . ”',\n",
       "  'and , naively , she showed her four thorns .',\n",
       "  \"then she added : “ don ' t linger like this , it ’ s tiresome .\",\n",
       "  'you have decided to leave .',\n",
       "  'now go ! ”',\n",
       "  'for she did not want him to see her crying .',\n",
       "  'she was such a proud flower ...'],\n",
       " ['he found himself in the neighborhood of the asteroids three two five , three two six , three two seven , three two eight , three two nine , and three three zero .',\n",
       "  'so he began by visiting them to learn more .',\n",
       "  'the first one was inhabited by a king .',\n",
       "  'the king was sitting , dressed in purple and ermine , on a very simple yet majestic throne .',\n",
       "  '“ ah !',\n",
       "  'here comes a subject , ” exclaimed the king , when he caught sight of the little prince .',\n",
       "  'and the little prince asked himself : “ how could he recognise me when he ’ s never seen me before ? ”',\n",
       "  'he didn ’ t know that for kings , the world is very much simplified .',\n",
       "  'to them , all men are subjects .',\n",
       "  '“ approach , so that i may see you better , ” said the king , who was very proud to finally be king over somebody .',\n",
       "  'the little prince looked around him for a place to sit , but the planet was completely taken over by the magnificent ermine robe .',\n",
       "  'so he remained standing , and , since he was tired , he yawned .',\n",
       "  '“ it is contrary to etiquette to yawn in the presence of a king , ” the monarch said to him .',\n",
       "  '“ i forbid you to do so . ”',\n",
       "  \"“ i can ' t stop myself , ” replied the little prince , thoroughly embarrassed .\",\n",
       "  '“ i ve come on a long journey , and i haven ’ t slept ... ”',\n",
       "  '“ ah , then , ” the king said .',\n",
       "  '“ i order you to yawn .',\n",
       "  'i have not seen anyone yawning for years .',\n",
       "  'yawns , to me , are objects of curiosity .',\n",
       "  'come , now !',\n",
       "  'yawn again !',\n",
       "  'it is an order . ”',\n",
       "  '“ that frightens me ...',\n",
       "  'i can ’ t any more ... ”',\n",
       "  'said the little prince , blushing .',\n",
       "  '“ hum !',\n",
       "  'hum ! ”',\n",
       "  'replied the king .',\n",
       "  '“ then i — i order you sometimes to yawn and sometimes to — ” he sputtered a bit , and seemed vexed .',\n",
       "  'for the king fundamentally insisted that his authority be respected .',\n",
       "  'he didn ’ t tolerate disobedience .',\n",
       "  'he was an absolute monarch .',\n",
       "  'but , because he was good at heart , he gave reasonable orders .',\n",
       "  '“ if i ordered a general , ” he would often say , “ if i ordered a general to change himself into a seabird , and if the general did not obey me , it would not be the general ’ s fault .',\n",
       "  'it would be my fault . ”',\n",
       "  '“ may i sit down ? ”',\n",
       "  'the little prince enquired timidly .',\n",
       "  '“ i order you to sit down , ” replied the king , who majestically gathered in a fold of his ermine mantle .',\n",
       "  'but the little prince was astonished .',\n",
       "  'the planet was tiny .',\n",
       "  'over what could this king really rule ?',\n",
       "  '“ sire , ” he said to him , “ excuse my asking you a question — ” “ i order you to ask me a question , ” hastened to say the king .',\n",
       "  '“ sire ...',\n",
       "  'over what do you rule ? ”',\n",
       "  '“ over everything , ” said the king , with a magnificent simplicity .',\n",
       "  '“ over everything ? ”',\n",
       "  'the king made a subtle gesture , pointing out his planet , the other planets and the stars .',\n",
       "  '“ over all that ? ”',\n",
       "  'asked the little prince .',\n",
       "  '“ over all that , ” the king answered .',\n",
       "  'for his rule was not only absolute : it was also universal .',\n",
       "  '“ and the stars obey you ? ”',\n",
       "  '“ of course , ” the king said .',\n",
       "  '“ they obey instantly .',\n",
       "  'i do not tolerate insubordination . ”',\n",
       "  'such power filled the little prince with wonder .',\n",
       "  'if he had held it himself , he would ’ ve been able to watch , not forty - four , but seventy - two , or even a hundred , or even two hundred sunsets on the same day , without ever having to move his chair !',\n",
       "  'and as he felt a bit sad as he remembered his forsaken little planet , he plucked up his courage to ask the king a favour : “ i ’ d like to see a sunset ...',\n",
       "  'do that for me ...',\n",
       "  'order the sun to set ... ”',\n",
       "  '“ if i ordered a general to fly from one flower to another like a butterfly , or to write a tragic drama , or to change himself into a sea bird , and if the general did not carry out the order received , which one of us would be in the wrong ?',\n",
       "  '” you , ” said the little prince firmly .',\n",
       "  '“ exactly .',\n",
       "  'one must ask of each person that which they can give , ” the king went on .',\n",
       "  '“ authority is based above all on reason .',\n",
       "  'if you ordered your people to go and throw themselves into the sea , they would rise up in revolution .',\n",
       "  'i have the right to demand obedience because my orders are reasonable . ”',\n",
       "  '“ then my sunset ? ”',\n",
       "  'the little prince reminded him , who never forgot a question once he had asked it .',\n",
       "  '“ you shall have your sunset .',\n",
       "  'i shall command it .',\n",
       "  'but i shall wait , according to my science of government , until conditions are favourable . ”',\n",
       "  '“ when will that be ? ”',\n",
       "  'inquired the little prince .',\n",
       "  '“ hum !',\n",
       "  'hum ! ”',\n",
       "  'replied the king , who consulted a bulky almanac .',\n",
       "  '“ hum !',\n",
       "  'hum !',\n",
       "  'that will be about — about — that will be this evening about twenty minutes to eight .',\n",
       "  'and you will see how well i am obeyed ! ”',\n",
       "  'the little prince yawned .',\n",
       "  'he was regretting his lost sunset .',\n",
       "  'and then he was already getting a little bored .',\n",
       "  \"“ i ' ve nothing more to do here , ” he said to the king .\",\n",
       "  '“ i ’ ll set off . ”',\n",
       "  '“ do not go , ” said the king , who was very proud of having a subject .',\n",
       "  '“ do not go .',\n",
       "  'i will make you a minister ! ”',\n",
       "  '“ minister of what ? ”',\n",
       "  '“ minster of — of justice ! ”',\n",
       "  '“ but there ’ s nobody here to judge ! ”',\n",
       "  '“ we do not know that , ” the king said to him .',\n",
       "  '“ i have not yet made a complete tour of my kingdom .',\n",
       "  'i am very old , i have no space for a carriage and it tires me to walk . ”',\n",
       "  '“ oh , but i ’ ve already looked ! ”',\n",
       "  'said the little prince , who leant over to give one more glance at the other side of the planet .',\n",
       "  'there was no one there either ...',\n",
       "  '“ then you shall judge yourself , ” the king answered .',\n",
       "  '“ that is the most difficult thing of all .',\n",
       "  'it is much more difficult to judge oneself than to judge someone else .',\n",
       "  'if you succeed in judging yourself rightly , then you are truly wise . ”',\n",
       "  '“ yes , ” said the little prince , “ but i can judge myself anywhere .',\n",
       "  'i don ’ t have to live here . ”',\n",
       "  '“ hum !',\n",
       "  'hum ! ”',\n",
       "  'said the king .',\n",
       "  '“ i am fairly certain that somewhere on my planet there is an old rat .',\n",
       "  'i hear him at night .',\n",
       "  'you can judge this old rat .',\n",
       "  'from time to time you will condemn him to death .',\n",
       "  'thus his life will depend on your justice .',\n",
       "  'but you will pardon him on each occasion to conserve him .',\n",
       "  'there is only one of him . ”',\n",
       "  '“ i , ” replied the little prince , “ don ’ t like to condemn anyone to death , and now i think i ’ ll go on my way . ”',\n",
       "  '“ no , ” said the king .',\n",
       "  'but the little prince , having readied himself to leave , had no wish to grieve the old monarch .',\n",
       "  '“ if your majesty wishes to be promptly obeyed , he should be able to give me a reasonable order .',\n",
       "  'he should be able , for example , to order me to leave within a minute .',\n",
       "  'it seems to me that conditions are favourable ... ”',\n",
       "  'as the king made no answer , the little prince hesitated at first , then , with a sigh , took his leave .',\n",
       "  '“ i make you my ambassador , ” the king hastily called out .',\n",
       "  'he had a magnificent air of authority .',\n",
       "  '“ the grownups are very strange , ” the little prince said to himself , as he continued on his journey .',\n",
       "  'the second planet was inhabited by a conceited man .',\n",
       "  '“ ah !',\n",
       "  'here comes a visit from an admirer ! ”',\n",
       "  'exclaimed the conceited man from afar , the moment he spotted the little prince .',\n",
       "  'because , to conceited men , all other men are admirers .',\n",
       "  '“ good morning , ” said the little prince .',\n",
       "  '“ you have a funny hat . ”',\n",
       "  '“ it ’ s for saluting , ” the conceited man replied .',\n",
       "  '“ it ’ s to raise in salute when people acclaim me .',\n",
       "  'unfortunately , nobody ever passes by this way . ”',\n",
       "  '“ oh , really ? ”',\n",
       "  'said the little prince , who didn ’ t understand .',\n",
       "  '“ clap your hands , one against the other , ” the conceited man advised .',\n",
       "  'the little prince clapped his hands , one against the other .',\n",
       "  'the conceited man raised his hat in a modest salute .',\n",
       "  '“ this is more fun than the visit to the king , ” the little prince said to himself .',\n",
       "  'and he began again to clap his hands , one against the other .',\n",
       "  'the conceited man again raised his hat in a salute .',\n",
       "  'after five minutes of this exercise the little prince grew tired of the monotony of the game : “ and what should i do , ” he asked , “ to make the hat come down ? ”',\n",
       "  'but the conceited man didn ’ t hear him .',\n",
       "  'conceited people never hear anything but praise .',\n",
       "  '“ do you really admire me a lot ? ”',\n",
       "  'he asked the little prince .',\n",
       "  \"“ what does that mean — ' to admire ' ? ”\",\n",
       "  '‘ “ to admire ’ means ‘ to recognise that i ’ m the most handsome , the best - dressed , the richest , and the most intelligent man on the planet . ’',\n",
       "  '” “ but you ’ re the only man on the planet ! ”',\n",
       "  '“ do it for me .',\n",
       "  'admire me just the same . ”',\n",
       "  '“ i admire you , ” said the little prince , shrugging his shoulders a little , “ but how can that interest you so much ? ”',\n",
       "  'and the little prince went away .',\n",
       "  '“ the grownups are certainly very odd , ” he said to himself , as he continued his journey .',\n",
       "  'the next planet was inhabited by a heavy drinker .',\n",
       "  'this was a very short visit , but it plunged the little prince into a deep sadness .',\n",
       "  '“ what are you doing there ? ”',\n",
       "  'he said to the drinker , who he found sitting in silence in front of a number of empty bottles and a number of full bottles .',\n",
       "  '“ i ’ m drinking , ” replied the drinker , gloomily .',\n",
       "  '“ why are you drinking ? ”',\n",
       "  'the little prince asked him .',\n",
       "  '“ to forget , ” replied the drinker .',\n",
       "  '“ to forget what ? ”',\n",
       "  'asked the little prince , who already felt sorry for him .',\n",
       "  '“ to forget that i ’ m ashamed , ” confessed the drinker , lowering his head .',\n",
       "  '“ ashamed of what ? ”',\n",
       "  'inquired the little prince , who wanted to help him .',\n",
       "  '“ ashamed of drinking ! ”',\n",
       "  'concluded the drinker , who then shut himself away in the silence .',\n",
       "  'and the little prince went away , puzzled .',\n",
       "  '“ the grownups are certainly very , very odd , ” he said to himself , as he continued on his journey .'],\n",
       " ['the fourth planet belonged to a businessman .',\n",
       "  'this man was so busy that he didn ’ t even raise his head when the little prince arrived .',\n",
       "  '“ good morning , ” the little prince said to him .',\n",
       "  '“ your cigarette has gone out . ”',\n",
       "  '“ three and two make five .',\n",
       "  'five and seven make twelve .',\n",
       "  'twelve and three make fifteen .',\n",
       "  'good morning .',\n",
       "  'fifteen and seven make twenty - two .',\n",
       "  'twenty - two and six make twenty - eight .',\n",
       "  'no time to light it again .',\n",
       "  'twenty - six and five make thirty - one .',\n",
       "  'phew !',\n",
       "  'then that makes five - hundred - and - one million , six - hundred - twenty - two - thousand , seven - hundred - thirty - one . ”',\n",
       "  '“ five hundred million what ? ”',\n",
       "  '“ huh ?',\n",
       "  'are you still there ?',\n",
       "  'five - hundred - and - one million ...',\n",
       "  'i ’ ve forgotten now ...',\n",
       "  'i have so much work !',\n",
       "  'i am a man of consequence .',\n",
       "  'i don ’ t amuse myself with balderdash !',\n",
       "  'two and five make seven .',\n",
       "  '“ five - hundred - and - one million what ? ”',\n",
       "  'repeated the little prince , who had never in his life let go of a question , once he had asked it .',\n",
       "  'the businessman raised his head .',\n",
       "  '“ during the fifty - four years that i ’ ve lived on this planet , i ’ ve only been disturbed three times .',\n",
       "  'the first time was twenty - two years ago , by some scatterbrain who fell from god knows where .',\n",
       "  'he made the most dreadful noise , and i made four mistakes in a sum .',\n",
       "  'the second time was eleven years ago , by an attack of rheumatism .',\n",
       "  \"i don ' t get enough exercise .\",\n",
       "  'i don ’ t have time to stroll about .',\n",
       "  'i am a man of consequence .',\n",
       "  'the third time — well , this is it !',\n",
       "  'i was saying , then , five - hundred - and - one million — ” “ millions of what ? ”',\n",
       "  'the businessman realised that there was no hope of being left in peace : “ millions of those little objects that you see sometimes in the sky . ”',\n",
       "  '“ flies ? ”',\n",
       "  '“ no , no , the little things that shine . ”',\n",
       "  '“ bees ? ”',\n",
       "  '“ no , no !',\n",
       "  'the little golden things that make lazy men daydream .',\n",
       "  'as for me , i am a man of consequence .',\n",
       "  'i have no time to daydream . ”',\n",
       "  '‘ ah !',\n",
       "  'the stars ? ”',\n",
       "  \"“ yes , that ' s it .\",\n",
       "  'the stars . ”',\n",
       "  '“ and what do you do with five - hundred million stars ? ”',\n",
       "  '“ five - hundred - and - one million , six - hundred - twenty - two thousand , seven - hundred - thirty - one .',\n",
       "  'i am a man of consequence : i am precise . ”',\n",
       "  '“ and what do you do with these stars ? ”',\n",
       "  '“ what do i do with them ? ”',\n",
       "  '“ yes . ”',\n",
       "  '“ nothing .',\n",
       "  'i own them . ”',\n",
       "  '“ you own the stars ? ”',\n",
       "  '“ yes . ”',\n",
       "  '“ but i ’ ve already seen a king who — ” “ kings don ’ t own , they ‘ reign ’ over .',\n",
       "  \"it ' s very different . ”\",\n",
       "  '“ and how does owning the stars help you ? ”',\n",
       "  '“ it helps by making me rich . ”',\n",
       "  '“ and how does being rich help you ? ”',\n",
       "  '“ to buy more stars , if someone discovers some more . ”',\n",
       "  '“ this man , ” the little prince said to himself , “ reasons a bit like my poor drinker ... ”',\n",
       "  'but he still had some questions : “ how can you own the stars ?',\n",
       "  '“ “ who owns them ? ”',\n",
       "  'the businessman retorted , grumpily .',\n",
       "  \"“ i don ' t know .\",\n",
       "  'nobody does . ”',\n",
       "  '“ then they belong to me , because i thought of it first . ”',\n",
       "  '“ is that all that ’ s necessary ? ”',\n",
       "  '“ certainly .',\n",
       "  'when you find a diamond that belongs to nobody , it ’ s yours .',\n",
       "  'when you discover an island that belongs to nobody , it ’ s yours .',\n",
       "  'when you get an idea first , you take out a patent : it ’ s yours .',\n",
       "  'and i own the stars , because no one before me ever thought of owning them .',\n",
       "  '“ yes , that ’ s true , ” said the little prince .',\n",
       "  '“ and what do you do with them ? ”',\n",
       "  '“ i administer them .',\n",
       "  'i count them and recount them , ” said the businessman .',\n",
       "  '“ it ’ s difficult .',\n",
       "  'but i am a man of consequence . ”',\n",
       "  'the little prince was still not satisfied .',\n",
       "  '“ if i owned a scarf , i could put it around my neck and take it away with me .',\n",
       "  'if i owned a flower , i could pick my flower and take it away with me .',\n",
       "  'but you can ’ t pick the stars . ”',\n",
       "  '“ no .',\n",
       "  'but i can put them in the bank . ”',\n",
       "  '“ what does that mean ? ”',\n",
       "  '“ that means that i write the number of my stars on a little paper .',\n",
       "  'and then i lock this paper in a drawer . ”',\n",
       "  '“ and that ’ s all ? ”',\n",
       "  '“ that ’ s enough . ”',\n",
       "  '“ that ’ s funny , ” thought the little prince .',\n",
       "  '“ it ’ s rather poetic .',\n",
       "  'but it ’ s of no great consequence . ”',\n",
       "  'on matters of consequence , the little prince had ideas which were very different from those of the grownups .',\n",
       "  '“ i myself , ” he continued , “ own a flower that i water every day .',\n",
       "  'i own three volcanoes , that i sweep out every week , as i also sweep out the one that ’ s extinct .',\n",
       "  'you never know .',\n",
       "  'it ’ s of some use to my volcanoes , and it ’ s of some use to my flower , that i own them .',\n",
       "  'but you ’ re of no use to the stars ... ”',\n",
       "  'the businessman opened his mouth , but he found nothing to say in response , and the little prince went away .',\n",
       "  '“ the grownups are certainly altogether extraordinary , ” he said to himself , as he continued on the journey .',\n",
       "  'the fifth planet was very strange .',\n",
       "  'it was the smallest of them all .',\n",
       "  'there was just enough room on it to accommodate a street lamp and a lamplighter .',\n",
       "  'the little prince couldn ’ t work out the purpose of having a street lamp and a lamplighter , somewhere out in the skies , on a planet without any houses or people .',\n",
       "  'he said to himself nevertheless : “ it may well be that this man is absurd .',\n",
       "  'but , he ’ s less absurd than the king , than the conceited man , the businessman , or the drinker .',\n",
       "  'at least his work has some meaning .',\n",
       "  'when he lights his lamp , it ’ s as if he ’ s bringing to life one more star , or one more flower .',\n",
       "  'when he puts out his lamp , he sends the flower , or the star , to sleep .',\n",
       "  'that ’ s a beautiful occupation .',\n",
       "  'it serves a real purpose , because it ’ s pretty . ”',\n",
       "  'when he arrived on the planet he respectfully saluted the lamplighter .',\n",
       "  '“ good morning .',\n",
       "  'why have you just put out your lamp ? ”',\n",
       "  '“ those are the orders , ” replied the lamplighter .',\n",
       "  '“ good morning . ”',\n",
       "  '“ what are the orders ? ”',\n",
       "  '“ that i put out my lamp .',\n",
       "  'good evening . ”',\n",
       "  'and he lit it again .',\n",
       "  '“ but why have you just lit it again ? ”',\n",
       "  '“ those are the orders , ” replied the lamplighter .',\n",
       "  '“ i don ’ t understand , ” said the little prince .',\n",
       "  '“ there ’ s nothing to understand , ” said the lamplighter .',\n",
       "  '“ orders are orders .',\n",
       "  'good morning . ”',\n",
       "  'and he put out his lamp .',\n",
       "  'then he sponged his forehead with a handkerchief , decorated with red squares .',\n",
       "  '“ i have a terrible profession .',\n",
       "  'in the old days it was reasonable .',\n",
       "  'i ’ d put the lamp out in the morning , and in the evening i ’ d light it .',\n",
       "  'i had the rest of the day to rest , and the rest of the night to sleep ... ”',\n",
       "  '“ and since then , have the orders changed ? ”',\n",
       "  '“ the orders haven ’ t changed , ” said the lamplighter .',\n",
       "  '“ that ’ s the tragedy !',\n",
       "  'every year the planet has turned faster and faster , and the orders haven ’ t changed ! ”',\n",
       "  '“ so what then ? ”',\n",
       "  'said the little prince .',\n",
       "  '“ so now that it spins round once every minute , i no longer have a moment ’ s rest .',\n",
       "  'once every minute i light the lamp and put it out again ! ”',\n",
       "  '“ that ’ s funny !',\n",
       "  'where you live , a day only lasts a minute ! ”',\n",
       "  '“ it ’ s not funny at all ! ”',\n",
       "  'said the lamplighter .',\n",
       "  '“ we ’ ve already been speaking for a month . ”',\n",
       "  '“ a month ? ”',\n",
       "  '“ yes .',\n",
       "  'thirty minutes .',\n",
       "  'thirty days .',\n",
       "  'good evening . ”',\n",
       "  'and he lit his lamp again .',\n",
       "  'the little prince watched him and felt that he loved this lamplighter who was so faithful to his orders .',\n",
       "  'he remembered the sunsets which he himself had gone to seek in the past , by moving his chair .',\n",
       "  'he wanted to help his friend .',\n",
       "  '“ you know — i know a way you can rest whenever you want ... ”',\n",
       "  '“ i always want to , ” said the lamplighter .',\n",
       "  'for it ’ s possible to be both faithful and lazy at the same time .',\n",
       "  'the little prince went on : “ your planet is so small that you can go right round it in three strides .',\n",
       "  'you only have to walk along rather slowly to always stay in the sun .',\n",
       "  'when you want to rest , you can walk — and the day will last as long as you like . ”',\n",
       "  \"“ that doesn ' t do me much good , ” said the lamplighter .\",\n",
       "  '“ what i really love in life is to sleep . ”',\n",
       "  '“ that ’ s bad luck , ” said the little prince .',\n",
       "  '“ that is bad luck , ” said the lamplighter .',\n",
       "  '“ good morning . ”',\n",
       "  'and he put out his lamp .',\n",
       "  '“ that man , ” said the little prince to himself , as he continued further on his journey , “ that man would be despised by all the others : by the king , by the conceited man , by the drinker , and by the businessman .',\n",
       "  'yet he ’ s the only one that doesn ’ t seem ridiculous to me .',\n",
       "  'perhaps it ’ s because he thinks of something other than himself . ”',\n",
       "  'he breathed a sigh of regret , and said to himself : “ that man is the only one with whom i could ’ ve made friends .',\n",
       "  'but his planet is really very small .',\n",
       "  'there ’ s no room on it for two people .',\n",
       "  'what the little prince didn ’ t dare admit to himself was that he missed this blessed planet most of all because of the one thousand , four hundred and forty sunsets every day !'],\n",
       " ['the sixth planet was ten times larger than the last .',\n",
       "  'it was inhabited by an old gentleman who wrote enormous books .',\n",
       "  '“ oh , look !',\n",
       "  'here comes an explorer ! ”',\n",
       "  'he cried out when he caught sight of the little prince .',\n",
       "  'the little prince sat down on the table and panted a little .',\n",
       "  'he had already travelled so far !',\n",
       "  '“ where do you come from ? ”',\n",
       "  'the old gentleman said to him .',\n",
       "  '“ what ’ s that big book ? ”',\n",
       "  'said the little prince .',\n",
       "  '“ what do you do here ? ”',\n",
       "  '“ i am a geographer , ” said the old gentleman .',\n",
       "  '“ what ’ s a geographer ? ”',\n",
       "  '“ he is a scholar who knows the location of the seas , the rivers , the towns , the mountains , and the deserts . ”',\n",
       "  '“ that ’ s very interesting , ” said the little prince .',\n",
       "  '“ that really is , at last , a real profession ! ”',\n",
       "  'and he glanced around at the planet of the geographer .',\n",
       "  'he had never seen such a majestic planet before .',\n",
       "  '“ your planet is very beautiful , ” he said .',\n",
       "  '“ are there oceans ? ”',\n",
       "  '“ i wouldn ’ t know , ” said the geographer .',\n",
       "  '“ oh . ”',\n",
       "  '( the little prince was disappointed .',\n",
       "  ') “ and mountains ? ”',\n",
       "  '“ i wouldn ’ t know , ” said the geographer .',\n",
       "  '“ and towns , and rivers , and deserts ? ”',\n",
       "  '“ i wouldn ’ t know that , either , ” said the geographer .',\n",
       "  '“ but you ’ re a geographer ! ”',\n",
       "  '“ that ’ s true , ” the geographer said , “ but i am not an explorer .',\n",
       "  'i don ’ t have a single explorer .',\n",
       "  'it is not for the geographer to count the towns , the rivers , the mountains , the seas , the oceans , and the deserts .',\n",
       "  'the geographer is too important to go strolling about .',\n",
       "  'he doesn ’ t leave his desk .',\n",
       "  'but he receives the explorers .',\n",
       "  'he asks them questions , and he writes down their recollections .',\n",
       "  \"and if any of their recollections seem interesting to him , the geographer orders an inquiry into that explorer ' s moral character . ”\",\n",
       "  '“ why ’ s that ? ”',\n",
       "  '“ because an explorer who told lies would cause havoc to geography books .',\n",
       "  'so would an explorer who drank too much . ”',\n",
       "  '“ why ’ s that ? ”',\n",
       "  'asked the little prince .',\n",
       "  '“ because intoxicated men see double .',\n",
       "  'so the geographer would record two mountains in a place where there was only one . ”',\n",
       "  '“ i know someone , ” said the little prince , “ who ’ d make a bad explorer . ”',\n",
       "  '“ that ’ s possible .',\n",
       "  'so , when the moral character of the explorer appears to be in order , an inquiry is done into his discovery . ”',\n",
       "  '“ you go to see it ? ”',\n",
       "  '“ no .',\n",
       "  'that would be too complicated .',\n",
       "  'but one requires the explorer to provide proof .',\n",
       "  'if for example , the discovery in question was of a large mountain , one would require that he bring back large stones from it . ”',\n",
       "  'the geographer suddenly became excited .',\n",
       "  '“ but you — you come from far away !',\n",
       "  'you are an explorer !',\n",
       "  'you must describe your planet to me ! ”',\n",
       "  'and the geographer , having opened his big register , sharpened his pencil .',\n",
       "  'the recitals of explorers are first recorded in pencil .',\n",
       "  'one waits until the explorer has provided proof before recording them in ink .',\n",
       "  '“ well ? ”',\n",
       "  'said the geographer .',\n",
       "  '“ oh , where i live , ” said the little prince , “ it ’ s not very interesting , everything is very small .',\n",
       "  'i have three volcanoes .',\n",
       "  'two active volcanoes , and one extinct one .',\n",
       "  'but you never know . ”',\n",
       "  '“ one never knows , ” said the geographer .',\n",
       "  '“ i also have a flower . ”',\n",
       "  '“ we do not record flowers , ” said the geographer .',\n",
       "  '“ why ’ s that ?',\n",
       "  'it ’ s the prettiest thing ! ”',\n",
       "  '“ because flowers are ephemeral . ”',\n",
       "  \"“ what does that mean — ' ephemeral ' ? ”\",\n",
       "  '“ geography books , ” said the geographer , “ of all books , are the most concerned with matters of consequence .',\n",
       "  'they never become out - dated .',\n",
       "  'it is very rare that a mountain changes position .',\n",
       "  'it is very rare that an ocean empties itself of its water .',\n",
       "  'we write about eternal things . ”',\n",
       "  '“ but extinct volcanoes can wake up , ” interrupted the little prince .',\n",
       "  \"“ what does ' ephemeral ' mean ? ”\",\n",
       "  '“ whether volcanoes are extinct or active is of no consequence to us , ” said the geographer .',\n",
       "  '“ the thing that matters to us is the mountain .',\n",
       "  'it does not change . ”',\n",
       "  \"“ but what does ' ephemeral ' mean ? ”\",\n",
       "  'repeated the little prince , who had never in his life let go of a question , once he had asked it .',\n",
       "  '“ it means , ‘ which is at risk of imminent disappearance . ’',\n",
       "  '\" “ is my flower at risk of imminent disappearance ? ”',\n",
       "  '“ of course . ”',\n",
       "  '“ my flower is ephemeral , ” the little prince said to himself , “ and she has only four thorns to defend herself against the world .',\n",
       "  'and i ’ ve left her all alone on my planet ! ”',\n",
       "  'that was his first moment of regret .',\n",
       "  'but he took heart once again : “ what place would you advise me to visit ? ”',\n",
       "  'he asked .',\n",
       "  '“ the planet earth , ” replied the geographer .',\n",
       "  '“ it has a good reputation ... ”',\n",
       "  'and the little prince went away , thinking of his flower .',\n",
       "  'so the seventh planet was the earth .',\n",
       "  'the earth isn ’ t just any old planet !',\n",
       "  'it has one hundred and eleven kings ( not forgetting , of course , the negro kings amongst them ) , seven thousand geographers , nine hundred thousand businessmen , seven million , five hundred thousand heavy drinkers , three hundred and eleven million conceited men , that ’ s to say , about two billion grownups .',\n",
       "  'to give you an idea of the size of the earth , i ’ ll tell you that before the invention of electricity it was necessary to maintain , over the span of the six continents , a veritable army of four hundred and sixty - two thousand , five hundred and eleven street lamp lighters .',\n",
       "  'seen from a distance it made a wonderful spectacle .',\n",
       "  'the movements of this army were regulated like those of an opera ballet .',\n",
       "  'first came the turn of the lamplighters of new zealand and australia .',\n",
       "  'having set their lamps alight , they would go off to bed .',\n",
       "  'next came the turn of the lamplighters of china and siberia to enter into the dance .',\n",
       "  'then they too would disappear into the wings .',\n",
       "  'then came the turn of the lamplighters of russia and the indies .',\n",
       "  'then those of africa and europe .',\n",
       "  'then those of south america .',\n",
       "  'then those of north america .',\n",
       "  'and never would they make a mistake in their order of entry on stage .',\n",
       "  'it was magnificent .',\n",
       "  'only the lamp lighter of the single lamp of the north pole , and his colleague at the single lamp of the south pole led lives of leisure : they worked twice a year .',\n",
       "  'when one wants to be witty , it can happen that one bends the truth a little .',\n",
       "  'i haven ’ t been entirely honest in telling you about the lamplighters .',\n",
       "  'i run the risk of giving a false idea of our planet to those who don ’ t know it .',\n",
       "  'men take up very little space on the earth .',\n",
       "  'if the two billion people who inhabit the earth were to stand upright and squash together a little , like for a meeting , they would easily fit on one public square twenty miles long and twenty miles wide .',\n",
       "  'all humanity could be piled up on the smallest pacific islet .',\n",
       "  'the grownups , of course , won ’ t believe you .',\n",
       "  'they picture themselves as taking up a lot of space .',\n",
       "  'they think themselves as important as the baobabs .',\n",
       "  'therefore you should advise them to do the math .',\n",
       "  'they adore numbers , and that will please them .',\n",
       "  'but don ’ t waste your time on this chore .',\n",
       "  'there ’ s no point .',\n",
       "  'you trust me .',\n",
       "  'the little prince , having arrived on earth , was very surprised not to see anyone .',\n",
       "  'he had already started to worry that he ’ d got the wrong planet , when a moon - coloured coil stirred in the sand .',\n",
       "  '“ good evening , ” said the little prince courteously .',\n",
       "  '“ good evening , ” said the snake .',\n",
       "  '“ on what planet have i come down on ? ”',\n",
       "  'asked the little prince .',\n",
       "  '“ onto earth , in africa , ” the snake answered .',\n",
       "  '“ oh !',\n",
       "  '...',\n",
       "  'so there ’ s no one on earth ? ”',\n",
       "  '“ this is the desert .',\n",
       "  'there is no one in the deserts .',\n",
       "  'the earth is large , ” said the snake .',\n",
       "  'the little prince sat down on a stone , and raised his eyes toward the sky .',\n",
       "  '“ i wonder , ” he said , “ if the stars are lit so that each of us can one day find his own again .',\n",
       "  'look at my planet .',\n",
       "  'it ’ s right there above us ...',\n",
       "  'but it ’ s so far away ! ”',\n",
       "  '“ it is beautiful , ” said the snake .',\n",
       "  '“ what has brought you here ? ”',\n",
       "  '“ i ’ ve been having some trouble with a flower , ” said the little prince .',\n",
       "  '“ ah ! ”',\n",
       "  'said the snake .',\n",
       "  'and they were silent .',\n",
       "  '“ where are the men ? ”',\n",
       "  'asked the little prince at last .',\n",
       "  '“ it ’ s a bit lonely in the desert ... ”',\n",
       "  '“ it is also lonely amongst men , ” the snake said .',\n",
       "  'the little prince gazed at him for a long time .',\n",
       "  \"“ you ' re a funny animal , ” he said finally , “ as thin as a finger ... ”\",\n",
       "  '“ but i am more powerful than the finger of a king , ” said the snake .',\n",
       "  'the little prince smiled .',\n",
       "  '“ you ’ re not very powerful ...',\n",
       "  'you haven ’ t even got any legs ...',\n",
       "  'you can ’ t even travel ... ”',\n",
       "  '“ i can carry you further than a ship , ” said the snake .',\n",
       "  \"he wrapped himself around the little prince ' s ankle , like a golden bracelet .\",\n",
       "  '“ whoever i touch , i send him back to the earth from which he came , ” he continued .',\n",
       "  '“ but you are pure , and you come from a star ... ”',\n",
       "  'the little prince made no reply .',\n",
       "  '“ i feel sorry for you , so weak , on this earth made of granite .',\n",
       "  'i can help you if someday you become too homesick for your planet .',\n",
       "  'i can . ”',\n",
       "  '“ oh !',\n",
       "  'i understand very well , ” said the little prince , “ but why do you always speak in riddles ? ”',\n",
       "  '“ i solve them all , ” said the snake .',\n",
       "  'and they were silent .',\n",
       "  'the little prince crossed the desert and met only with one flower .',\n",
       "  'a flower with three petals , a nondescript flower belonging to no one .',\n",
       "  '“ good morning , ” said the little prince .',\n",
       "  '“ good morning , ” said the flower .',\n",
       "  '“ where are the men ? ”',\n",
       "  'asked the little prince politely .',\n",
       "  'the flower had once seen a caravan passing .',\n",
       "  '“ men ?',\n",
       "  'i think there exists six or seven of them .',\n",
       "  'i saw them years ago .',\n",
       "  'but you never know where to find them .',\n",
       "  'they are blown here and there by the wind .',\n",
       "  'they lack roots , it makes things very difficult for them ” “ goodbye , ” said the little prince .',\n",
       "  '“ goodbye , ” said the flower .',\n",
       "  'the little prince climbed a high mountain .',\n",
       "  'the only mountains he ’ d ever known were the three volcanoes that came up to his knees .',\n",
       "  'and he used the extinct volcano as a footstool .',\n",
       "  '“ from a mountain as high as this one , ” he said to himself , “ i ’ ll be able to see the entire planet all at once , and all the people ... ”',\n",
       "  'but he saw nothing but sharp needles of rock .',\n",
       "  '“ good morning , ” he said courteously .',\n",
       "  '“ good morning ...',\n",
       "  'good morning ...',\n",
       "  'good morning ...',\n",
       "  ', ” answered the echo .',\n",
       "  '“ who are you ? ”',\n",
       "  'said the little prince .',\n",
       "  '“ who are you ...',\n",
       "  'who are you ...',\n",
       "  'who are you ...',\n",
       "  '? ”',\n",
       "  'answered the echo .',\n",
       "  '“ be my friends .',\n",
       "  'i ’ m all alone , ” he said .',\n",
       "  '“ i ’ m all alone ...',\n",
       "  'all alone ...',\n",
       "  'all alone ...',\n",
       "  ', ” answered the echo .',\n",
       "  '“ what a funny planet ! ”',\n",
       "  'he thought .',\n",
       "  '“ it ’ s all dry , and all jagged , and all barren .',\n",
       "  'and the people have no imagination .',\n",
       "  'they repeat whatever you say to them ...',\n",
       "  'on my planet i had a flower : she was always the first to speak ... ”'],\n",
       " ['but it happened that the little prince , having walked for a long time through the sands , rocks , and snow , at last came across a road .',\n",
       "  'and all roads lead to the dwellings of men .',\n",
       "  '“ good morning , ” he said .',\n",
       "  'it was a garden covered in roses .',\n",
       "  '“ good morning , ” said the roses .',\n",
       "  '“ good morning !',\n",
       "  'good morning !',\n",
       "  'good morning ! ”',\n",
       "  'the little prince gazed at them .',\n",
       "  'they all looked just like his flower .',\n",
       "  '“ who are you ? ”',\n",
       "  'he asked them , stunned .',\n",
       "  \"“ we ' re roses , ” the roses said .\",\n",
       "  \"“ we ' re roses !\",\n",
       "  \"we ' re roses !\",\n",
       "  \"we ' re roses ! ”\",\n",
       "  '“ oh ! ”',\n",
       "  'said the little prince ...',\n",
       "  'and he suddenly felt very unhappy .',\n",
       "  'his flower had told him that she was the only one of her kind in the universe .',\n",
       "  'and here were five thousand of them , all alike , in one single garden !',\n",
       "  '“ she ’ d be very upset , ” he said to himself , “ if she saw this ...',\n",
       "  'she ’ d cough and cough and pretend to die to avoid being laughed at .',\n",
       "  'and i ’ d have to pretend to nurse her back to life , to humble myself also , because if i didn ’ t , she really would allow herself to die ...',\n",
       "  '” then he said to himself : “ i thought i was rich , with a flower that was one of a kind , and all i have is a common rose .',\n",
       "  \"that , and my three volcanoes that come up to my knees , of one which is perhaps forever extinct ; that doesn ' t make me a very great prince .\",\n",
       "  'and lying in the grass , he started to cry .',\n",
       "  'it was then that the fox appeared : “ good morning , ” said the fox .',\n",
       "  '“ good morning , ” responded the little prince politely , who then turned around , but saw nothing .',\n",
       "  '“ i ’ m right here , ” the voice said , “ under the apple tree ... ”',\n",
       "  '“ who are you ? ”',\n",
       "  'asked the little prince .',\n",
       "  '“ you ’ re very pretty . ”',\n",
       "  '“ i ’ m a fox , ” the fox said .',\n",
       "  '“ come and play with me , ” proposed the little prince .',\n",
       "  '“ i ’ m so unhappy . ”',\n",
       "  '“ i can ’ t play with you , ” said the fox .',\n",
       "  '“ i ’ m not tamed . ”',\n",
       "  '“ oh !',\n",
       "  'i ’ m sorry , ” said the little prince .',\n",
       "  \"but , after some thought , he added : “ what does that mean — ' tame ' ? ”\",\n",
       "  '“ you aren ’ t from here , ” said the fox .',\n",
       "  '“ what is it that you ’ re looking for ? ”',\n",
       "  '“ i ’ m looking for men , ” said the little prince .',\n",
       "  \"“ what does ' tame ' mean ? ”\",\n",
       "  '“ men , ” said the fox , “ they have guns , and they hunt .',\n",
       "  'it ’ s very bothersome .',\n",
       "  'they also raise chickens .',\n",
       "  'it ’ s their sole interest .',\n",
       "  'are you looking for chickens ? ”',\n",
       "  '“ no , ” said the little prince .',\n",
       "  '“ i ’ m looking for friends .',\n",
       "  \"what does ' tame ' mean ? ”\",\n",
       "  '“ it ’ s something that ’ s too often forgotten , ” said the fox .',\n",
       "  '“ it means ‘ to establish bonds . ’',\n",
       "  '” ‘ “ to establish bonds ? ”',\n",
       "  '’ “ that ’ s right , ” said the fox .',\n",
       "  '“ to me , you ’ re still only a little boy , just like a hundred thousand other little boys .',\n",
       "  'and i don ’ t need you .',\n",
       "  'and you don ’ t need me either .',\n",
       "  'to you , i ’ m only a fox , just like a hundred thousand other foxes .',\n",
       "  'but if you tame me , we ’ ll need each other .',\n",
       "  'to me , you ’ ll be unique in the entire world .',\n",
       "  'to you , i ’ ll be unique in the entire world ... ”',\n",
       "  '“ i ’ m beginning to understand , ” said the little prince .',\n",
       "  '“ there ’ s a flower ...',\n",
       "  'i think she ’ s tamed me ... ”',\n",
       "  '“ it ’ s possible , ” said the fox .',\n",
       "  '“ on earth you see all kinds of things . ”',\n",
       "  '“ oh , but she ’ s not on earth ! ”',\n",
       "  'said the little prince .',\n",
       "  'the fox seemed very intrigued : “ on another planet ? ”',\n",
       "  '“ yes . ”',\n",
       "  '“ are there hunters on that planet ? ”',\n",
       "  '“ no . ”',\n",
       "  \"“ that ' s interesting !\",\n",
       "  'and chickens ? ”',\n",
       "  '“ no . ”',\n",
       "  '“ nothing ’ s perfect , ” sighed the fox .',\n",
       "  'but the fox came back to his idea .',\n",
       "  '“ my life is very monotonous .',\n",
       "  'i hunt chickens ; men hunt me .',\n",
       "  'all the chickens look alike , and all the men look alike .',\n",
       "  'so i get a bit bored .',\n",
       "  'but if you tame me , it would bring some sunlight into my life .',\n",
       "  'i ’ d come to know a sound of footsteps unlike any other .',\n",
       "  'other footsteps send me hurrying back underground .',\n",
       "  'yours would call me out of my burrow like music .',\n",
       "  'and then look : you see the wheat fields down there ?',\n",
       "  'i don ’ t eat bread .',\n",
       "  'wheat is of no use to me .',\n",
       "  'the wheat fields mean nothing to me .',\n",
       "  'and that ’ s sad .',\n",
       "  'but your hair is the colour of gold .',\n",
       "  'so it ’ ll be wonderful when you ’ ve tamed me !',\n",
       "  'the wheat , which is golden , will remind me of you .',\n",
       "  'and i ’ ll love the sound of the wind blowing through the wheat ... ”',\n",
       "  'the fox went silent and gazed at the little prince for a long time .',\n",
       "  '“ please ...',\n",
       "  'tame me ! ”',\n",
       "  'he said .',\n",
       "  '“ i really want to , ” the little prince replied , “ but i don ’ t have much time .',\n",
       "  'i have friends to discover , and many things to understand . ”',\n",
       "  '“ one only understands the things that one tames , ” said the fox .',\n",
       "  '“ men no longer have the time to get to know anything .',\n",
       "  'they buy things ready made in the shops .',\n",
       "  'but as there aren ’ t any shops that sell friends , men no longer have any friends .',\n",
       "  'if you want a friend , tame me .',\n",
       "  '“ what should i do ? ”',\n",
       "  'asked the little prince .',\n",
       "  '“ you have to be very patient , ” replied the fox .',\n",
       "  '“ first you ’ ll sit down a little way away from me , like this , in the grass .',\n",
       "  'i ’ ll watch you out of the corner of my eye and you won ’ t say anything .',\n",
       "  'words are a source of misunderstandings .',\n",
       "  'but every day you ’ ll be able to sit a little closer ... ”',\n",
       "  'the next day the little prince came back .',\n",
       "  '“ it would ’ ve been better to come back at the same time of day , ” said the fox .',\n",
       "  \"“ if you come , for example , at four o ' clock in the afternoon , from three o ' clock i ’ d start to feel happy .\",\n",
       "  'as the time got nearer , i ’ d feel happier and happier .',\n",
       "  \"already by four o ' clock , i ’ d be jumping about and getting restless ; i ’ d come to learn the price of happiness !\",\n",
       "  'but if you come at just any time , i ‘ d never know at what time my heart should be ready to greet you ...',\n",
       "  'we must observe the rites . ”',\n",
       "  '“ what ’ s a rite ? ”',\n",
       "  'asked the little prince .',\n",
       "  '“ they are also something too often forgotten , ” said the fox .',\n",
       "  '“ they are what make one day different from other days , one hour different from other hours .',\n",
       "  'there ’ s a rite , for example , among my hunters .',\n",
       "  'on thursdays they dance with the girls of the village .',\n",
       "  'so thursday is a wonderful day !',\n",
       "  'i can go for a walk as far as the vineyards .',\n",
       "  'if the hunters danced on just any day , all the days would be alike , and i ’ d never have any rest . ”',\n",
       "  'so the little prince tamed the fox .',\n",
       "  'and when the time to leave drew near ...',\n",
       "  '“ oh , ” said the fox , “ i ’ ll cry . ”',\n",
       "  '“ it ’ s your fault , ” said the little prince .',\n",
       "  '“ i never wished you any harm ; but you wanted me to tame you ... ”',\n",
       "  '“ i know , ” said the fox .',\n",
       "  '“ but you ’ re going to cry ! ”',\n",
       "  'said the little prince .',\n",
       "  '“ i know , ” said the fox .',\n",
       "  '“ so all this has done you no good at all ! ”',\n",
       "  '“ it has done me good , ” said the fox , “ because of the colour of the wheat . ”',\n",
       "  'and then he added : “ go and see the roses again .',\n",
       "  'you ’ ll understand that yours is unique in the entire world .',\n",
       "  'then come back to say goodbye to me , and i ’ ll make you a present of a secret . ”',\n",
       "  'the little prince went away to see the roses again : “ you aren ’ t like my rose at all , you are nothing yet , ” he told them .',\n",
       "  'no one has tamed you , and you haven ’ t tamed anyone .',\n",
       "  'you ’ re like my fox used to be .',\n",
       "  'he was only a fox , just like a hundred thousand others .',\n",
       "  'but i ’ ve made him my friend , and now he ’ s unique in the entire world . ”',\n",
       "  'and the roses were very embarrassed .',\n",
       "  '“ you are beautiful , but you are empty , ” he went on .',\n",
       "  '“ one could not die for you .',\n",
       "  'of course , an ordinary passer - by would think that my rose looked just like you .',\n",
       "  'but she alone is more important than all of you : because it ’ s her that i watered ; because it ’ s her that i put under the glass dome ; because it ’ s her that i sheltered behind the screen ; because it ’ s for her that i killed the caterpillars ( except two or three , to become butterflies ) ; because it ’ s her that i listened to grumble , or boast , or even sometimes when she said nothing .',\n",
       "  'because she ’ s my rose .',\n",
       "  'and he went back to the fox : “ goodbye , ” he said .',\n",
       "  '“ goodbye , ” said the fox .',\n",
       "  \"“ here ' s my secret .\",\n",
       "  'it ’ s very simple : one only sees clearly with the heart .',\n",
       "  'what is essential is invisible to the eye . ”',\n",
       "  '“ what is essential is invisible to the eye , ” repeated the little prince , so as to remember .',\n",
       "  '“ it is the time you have wasted on your rose that makes your rose so important . ”',\n",
       "  '“ it is the time that i have wasted on my rose ... ”',\n",
       "  'said the little prince , so as to remember .',\n",
       "  '“ the men have forgotten this truth , ” said the fox .',\n",
       "  '“ but you must not forget it .',\n",
       "  'you become forever responsible for that which you have tamed .',\n",
       "  'you are responsible for your rose ... ”',\n",
       "  '“ i am responsible for my rose , ” repeated the little prince , so as to remember .',\n",
       "  '“ good morning , ” said the little prince .',\n",
       "  '“ good morning , ” said the railway switchman .',\n",
       "  '“ what do you do here ? ”',\n",
       "  'the little prince asked .',\n",
       "  '“ i sort travelers , in packs of a thousand , ” said the switchman .',\n",
       "  '“ i dispatch the trains that carry them : sometimes to the right , sometimes to the left . ”',\n",
       "  \"and a brilliantly lit express train , rumbling like thunder , shook the switchman ' s cabin .\",\n",
       "  '“ they really are in a hurry , ” said the little prince .',\n",
       "  '“ what is it that they ’ re looking for ? ”',\n",
       "  '“ not even the locomotive engineer knows that , ” said the switchman .',\n",
       "  'a second brilliantly lit express thundered by in the opposite direction .',\n",
       "  '“ are they back already ? ”',\n",
       "  'asked the little prince .',\n",
       "  '“ these aren ’ t the same ones , ” said the switchman .',\n",
       "  '“ it ’ s an exchange . ”',\n",
       "  '“ weren ’ t they happy where they were ? ”',\n",
       "  '“ no one is ever happy where they are , ” said the switchman .',\n",
       "  'a third brilliantly lit express thundered by .',\n",
       "  '“ are they chasing after the first travelers ? ”',\n",
       "  'asked the little prince .',\n",
       "  '“ they aren ’ t chasing after anything at all , ” said the switchman .',\n",
       "  '“ they ’ re asleep in there , or if not , they ’ re yawning .',\n",
       "  'only the children are squashing their noses up against the windows . ”',\n",
       "  '“ only the children know what they ’ re after , ” said the little prince .',\n",
       "  '“ they waste their time with a rag doll and it becomes very important to them ; and if someone takes it away from them , they cry ... ”',\n",
       "  '“ they ’ re lucky , ” said the switchman .'],\n",
       " ['“ good morning , ” said the little prince .',\n",
       "  '“ good morning , ” said the merchant .',\n",
       "  'this was a merchant who sold pills that had been created to quench thirst .',\n",
       "  'you could take one pill a week , and you no longer felt the need to drink anything .',\n",
       "  '“ why are you selling those ? ”',\n",
       "  'asked the little prince .',\n",
       "  '“ it ’ s a big time saver , ” said the merchant .',\n",
       "  '“ experts have done calculations .',\n",
       "  'you save fifty - three minutes per week . ”',\n",
       "  '“ and what do i do with the fifty - three minutes ? ”',\n",
       "  '“ you can do anything you like with them ... ”',\n",
       "  '“ myself , ” the little prince said to himself , “ if i had fifty - three minutes to spend as i liked , i ’ d walk very slowly toward a spring of fresh water . ”',\n",
       "  'we were at the eighth day since my accident in the desert , and i ’ d listened to the story of the merchant as i drank the last drop of my water supply .',\n",
       "  '“ ah , ” i said to the little prince , “ these memories of yours are very charming ; but i haven ’ t managed to repair my plane yet , i have nothing left to drink , and i , too , would be happy if i could walk slowly towards a spring of fresh water ! ”',\n",
       "  '“ my friend the fox — ” he said to me .',\n",
       "  '“ my dear fellow , our situation has nothing to do with the fox anymore ! ”',\n",
       "  '“ why not ? ”',\n",
       "  '“ because we will die of thirst .',\n",
       "  'he didn ’ t follow my reasoning , and he answered me : “ it ’ s nice to have had a friend , even if you ’ re about to die .',\n",
       "  'myself , i ’ m glad to have had a fox as a friend ... ”',\n",
       "  '“ he never considers the danger , ” i said to myself .',\n",
       "  '“ he ’ s never been hungry or thirsty .',\n",
       "  'a little sunshine is all he needs ... ”',\n",
       "  'but he looked at me and replied to my thought : “ i ’ m also thirsty .',\n",
       "  'let ’ s look for a well .',\n",
       "  'i made a gesture of weariness : it ’ s absurd to look for a well , at random , in the immensity of the desert .',\n",
       "  'but we started walking anyway .',\n",
       "  'when we had walked for hours in silence , night fell , and the stars began to come out .',\n",
       "  'i saw them as if in a dream , as my thirst had made me feverish .',\n",
       "  \"the little prince ' s words danced in my memory : “ so you ’ re also thirsty ? ”\",\n",
       "  'i asked him .',\n",
       "  'but he didn ’ t reply to my question .',\n",
       "  'he said simply : “ water can be good for the heart too ... ”',\n",
       "  'i didn ’ t understand his answer , but i said nothing .',\n",
       "  'i knew better than to press my questions .',\n",
       "  'he was tired .',\n",
       "  'he sat down .',\n",
       "  'i sat down beside him .',\n",
       "  'and , after a silence , he spoke again : “ the stars are beautiful because of a flower that can ’ t be seen . ”',\n",
       "  'i replied , “ that ’ s true . ”',\n",
       "  'and i looked , without saying anything , at the folds of sand in the moonlight .',\n",
       "  '“ the desert is beautiful , ” the little prince added .',\n",
       "  'and it was true .',\n",
       "  'i have always loved the desert .',\n",
       "  'you sit down on a sand dune .',\n",
       "  'you see nothing .',\n",
       "  'you hear nothing .',\n",
       "  'and yet something radiates forth in the silence ...',\n",
       "  '“ what makes the desert beautiful , ” said the little prince , “ is that somewhere it hides a well ... ”',\n",
       "  'i was surprised to suddenly understand this mysterious radiation of the sands .',\n",
       "  'when i was a little boy i lived in an old house , and legend told that a treasure was buried there .',\n",
       "  'of course , no one had ever been able to find it , or perhaps no one had even looked for it .',\n",
       "  'but it cast an enchantment over that house .',\n",
       "  'my home was hiding a secret in the depths of its heart ...',\n",
       "  '“ yes , ” i said to the little prince .',\n",
       "  '“ whether the house , the stars , or the desert , what gives them their beauty is something invisible ! ”',\n",
       "  '“ i ’ m glad , ” he said , “ that you agree with my fox . ”',\n",
       "  'as the little prince fell asleep , i took him in my arms and set out walking again .',\n",
       "  'i felt deeply moved .',\n",
       "  'it seemed to me that i was carrying a very fragile treasure .',\n",
       "  'it even seemed to me that there was nothing more fragile on earth .',\n",
       "  'i looked in the moonlight at his pale forehead , his closed eyes , his locks of hair that trembled in the wind , and i said to myself : “ what i see here is only a shell .',\n",
       "  'that which is most important is invisible ... ”',\n",
       "  'as his slightly parted lips gave way to a half - smile , i continued : “ what i find so deeply moving about this little sleeping prince is his devotion to a flower ; it ’ s the image of a rose that shines in him like the flame of a lamp , even when he ’ s sleeping .',\n",
       "  'and i came to think of him as even more fragile .',\n",
       "  'one has to look after lamps : a gust of wind can put them out ...',\n",
       "  'and , continuing to walk , i found the well at daybreak .',\n",
       "  '“ men , ” said the little prince , “ stuff themselves into express trains , but they don ’ t know what they ’ re looking for .',\n",
       "  'so they rush about , and go round in circles ... ”',\n",
       "  'and he added : “ it ’ s not worth it ... ”',\n",
       "  'the well that we had reached wasn ’ t like the other wells of the sahara .',\n",
       "  'the wells of the sahara are mere holes dug in the sand .',\n",
       "  'this one looked like a village well .',\n",
       "  'but there was no village there , and i thought i was dreaming .',\n",
       "  '“ it ’ s strange , ” i said to the little prince , “ everything ’ s been prepared : the pulley , the bucket , and the rope ... ”',\n",
       "  'he laughed , took the rope , and put the pulley to work .',\n",
       "  'and the pulley moaned like an old weathervane when there has long been no wind .',\n",
       "  '“ can you hear that ? ”',\n",
       "  'said the little prince , “ we ’ ve woken up the well , and it ’ s singing ... ”',\n",
       "  'i didn ’ t want him to tire himself out .',\n",
       "  '“ let me do it , ” i said , “ it ’ s too heavy for you . ”',\n",
       "  'i hoisted the bucket slowly to the edge of the well and set it down good and level .',\n",
       "  'the song of the pulley continued in my ears , and in the still trembling water i could see the sunlight shimmer .',\n",
       "  '“ i ’ m thirsty for this water , ” said the little prince .',\n",
       "  '“ give me some to drink ... ”',\n",
       "  'and i knew then what he ’ d been looking for !',\n",
       "  'i raised the bucket to his lips .',\n",
       "  'he drank , his eyes closed .',\n",
       "  'it was as sweet as some special festival treat .',\n",
       "  'this water was something very different from ordinary nourishment .',\n",
       "  'it was born of the walk under the stars , of the song of the pulley , of the effort of my arms .',\n",
       "  'it was good for the heart , like a present .',\n",
       "  'when i was a little boy , the lights of the christmas tree , the music of the midnight mass , the tenderness in the smiles produced , in a similar way , the radiance of the gift that i received .',\n",
       "  '“ the men where you live , ” said the little prince , “ grow five thousand roses in a single garden ...',\n",
       "  'and they don ’ t find what they ’ re looking for in it . ”',\n",
       "  '“ they don ’ t find it , ” i replied .',\n",
       "  '“ and yet what they ’ re looking for could be found in a single rose , or in a little water ... ”',\n",
       "  '“ that ’ s true , ” i said .',\n",
       "  'and the little prince added : “ but the eyes are blind .',\n",
       "  'you have to search with the heart ... ”',\n",
       "  'i had drunk the water .',\n",
       "  'i breathed easily .',\n",
       "  'the sand at sunrise is the color of honey .',\n",
       "  'this honey color was also making me feel good .',\n",
       "  'why then did i have this sense of grief ...',\n",
       "  '“ you have to keep your promise , ” said the little prince softly , who had again sat down beside me .',\n",
       "  '“ what promise ?',\n",
       "  '“ you know ...',\n",
       "  'a muzzle for my sheep ...',\n",
       "  'i ’ m responsible for this flower ... ”',\n",
       "  'i took my sketches out of my pocket .',\n",
       "  'the little prince saw them , and laughed as he said : “ your baobabs - they look a bit like cabbages . ”',\n",
       "  '“ oh ! ”',\n",
       "  'and i ’ d been so proud of my baobabs !',\n",
       "  '“ your fox ...',\n",
       "  'his ears ...',\n",
       "  'they look a bit like horns ...',\n",
       "  'and they ’ re too long ! ”',\n",
       "  'and then he laughed again .',\n",
       "  '“ you aren ’ t being fair , my little fellow .',\n",
       "  \"i don ' t know how to draw anything except boa constrictors , closed and open . ”\",\n",
       "  '“ oh , it ’ ll be all ok , ” he said , “ children understand . ”',\n",
       "  'so i made a pencil sketch of a muzzle .',\n",
       "  'and i felt a pang in my heart as i gave it to him .',\n",
       "  '“ you have plans that i don ’ t know about ... ”',\n",
       "  'but he didn ’ t respond .',\n",
       "  'he said to me : “ you know , my descent to earth ...',\n",
       "  'tomorrow will be its anniversary . ”',\n",
       "  'then after a silence he went on : “ i came down very near here . ”',\n",
       "  'and he blushed .',\n",
       "  'and once again , without understanding why , i felt a peculiar sense of sorrow .',\n",
       "  'one question occurred to me however : “ so it wasn ’ t by chance that the morning i first met you , a week ago , you were out walking like that , all alone , a thousand miles from any inhabited region ?',\n",
       "  'you were going back to the place where you landed ? ”',\n",
       "  'the little prince blushed again .',\n",
       "  'and i added , hesitantly : “ perhaps because of the anniversary ...',\n",
       "  '? ”',\n",
       "  'the little prince blushed once more .',\n",
       "  'he never answered questions , but when you blush , that means ‘ yes , ’ doesn ’ t it ?',\n",
       "  '“ oh , ” i said to him , “ i ’ m worried — ” but he responded : “ now you must work .',\n",
       "  'you must go back to your engine .',\n",
       "  'i will wait for you here .',\n",
       "  'come back tomorrow evening .',\n",
       "  'but i wasn ’ t reassured .',\n",
       "  'i remembered the fox .',\n",
       "  'you run the risk of weeping a little , if you allow yourself to be tamed ...'],\n",
       " ['there was , next to the well , the ruin of an old stone wall .',\n",
       "  'when i came back from my work , the next evening , i saw from a distance my little price sitting on top of it , his feet hanging down .',\n",
       "  'and i heard him say : “ don ’ t you remember then ? ”',\n",
       "  'he said .',\n",
       "  '“ this isn ’ t the exact spot . ”',\n",
       "  'another voice must have answered him , because he replied : “ yes , yes !',\n",
       "  'it ’ s the right day , but this isn ’ t the right place . ”',\n",
       "  'i continued my walk toward the wall .',\n",
       "  'i still didn ’ t see or hear anyone .',\n",
       "  'yet the little prince replied again : ” ...',\n",
       "  'that ’ s right .',\n",
       "  'you ’ ll see where my tracks begin in the sand .',\n",
       "  'you just have to wait there for me .',\n",
       "  'i ’ ll be there tonight ... ”',\n",
       "  'i was twenty meters from the wall , and i still saw nothing .',\n",
       "  'the little prince spoke again , after a pause : “ do you have good poison ?',\n",
       "  'are you sure you won ’ t make me suffer too long ? ”',\n",
       "  'i froze , my heart skipped a beat ; but i still didn ’ t understand .',\n",
       "  '“ now go away , ” he said , “ i want to come down from here . ”',\n",
       "  'i then lowered my eyes to the foot of the wall , and i leapt up !',\n",
       "  'right there , facing the little prince was one of those yellow snakes that can kill you in thirty seconds flat .',\n",
       "  'even as i dug around in my pocket to take out my revolver , i made a running step back .',\n",
       "  'but , at the noise i made , the snake let himself flow easily across the sand , like the dying spray of a fountain , and in no apparent hurry , slipped between the stones with a light metallic sound .',\n",
       "  'i reached the wall just in time to catch my little fellow in my arms , who was white as snow .',\n",
       "  '“ what ’ s going on here ?',\n",
       "  'why are you talking with snakes ? ”',\n",
       "  'i ’ d loosened the golden muffler that he always wore .',\n",
       "  'i ’ d moistened his temples and had him drink .',\n",
       "  'and now i didn ’ t dare ask him anything more .',\n",
       "  'he looked at me gravely and put his arms around my neck .',\n",
       "  'i felt his heart beat like the heart of a dying bird , when shot with a rifle .',\n",
       "  'he said to me : “ i ’ m glad that you ’ ve found what was wrong with your engine .',\n",
       "  'now you ’ ll be able to go back home — ” “ how did you know ! ”',\n",
       "  'i was just coming to tell him that , against all odds , my work had been successful .',\n",
       "  'he made no answer to my question , but he added : “ i ’ m also going back home today ... ”',\n",
       "  'then he said sadly : “ it ’ s a lot further ...',\n",
       "  'it ’ s much more difficult ... ”',\n",
       "  'i felt very clearly that something extraordinary was happening .',\n",
       "  'i held him tightly in my arms like a small child ; and yet it seemed to me that he was plummeting down into an abyss , and that i could do nothing to restrain him ...',\n",
       "  'he had a serious look , as if lost far away .',\n",
       "  '“ i have your sheep .',\n",
       "  'and i have the box for the sheep .',\n",
       "  'and i have the muzzle ... ”',\n",
       "  'and he smiled sadly .',\n",
       "  'i waited a long while .',\n",
       "  'i could feel that he was reviving little by little .',\n",
       "  '“ my little fellow , ” i said to him , “ you ’ re afraid ... ”',\n",
       "  'he was afraid , of course .',\n",
       "  'but he laughed softly : “ i ’ ll be much more afraid this evening ... ”',\n",
       "  'again i felt myself frozen by the sense of something irreparable .',\n",
       "  'and i knew that i couldn ’ t bear the idea of never hearing that laughter again .',\n",
       "  'for me , it was like a spring of fresh water in the desert .',\n",
       "  '“ little fellow , ” i said , “ i want to hear you laugh again . ”',\n",
       "  'but he said to me : “ tonight , it ’ ll be a year .',\n",
       "  'my star will be right above the spot where i came down to earth , a year ago ... ”',\n",
       "  '“ little fellow , is this all a bad dream - this business with the snake , and the meeting - place , and the star ...',\n",
       "  '? ”',\n",
       "  'but he didn ’ t answer my question .',\n",
       "  'he said to me : “ that which is important can ’ t be seen ... ”',\n",
       "  '“ i know ... ”',\n",
       "  '“ it ’ s like with the flower .',\n",
       "  'if you love a flower that ’ s on a star , it ’ s sweet to look at the sky at night .',\n",
       "  'all the stars are covered with flowers ... ”',\n",
       "  '“ i know ... ”',\n",
       "  '“ it ’ s like with the water .',\n",
       "  'the water you gave me to drink was like music , because of the pulley , and the rope ...',\n",
       "  'you remember ...',\n",
       "  'it was good . ”',\n",
       "  '“ i know . ”',\n",
       "  '“ at night you ’ ll look at the stars .',\n",
       "  'where i live everything is too small for me to point out to you where my star is .',\n",
       "  'it ’ s better like that .',\n",
       "  'my star will be for you just one of the stars .',\n",
       "  'so you ’ ll love to look at all of the stars ...',\n",
       "  'they ’ ll all be your friends .',\n",
       "  'and , besides , i ’ m going to make you a present ... ”',\n",
       "  'he laughed again .',\n",
       "  '“ ah , little fellow , dear little fellow !',\n",
       "  'i love to hear that laugh ! ”',\n",
       "  '“ that ’ s my present .',\n",
       "  'just that .',\n",
       "  'it ’ ll be like with the water ... ”',\n",
       "  '“ what are you trying to say ? ”',\n",
       "  '“ everyone has the same stars , but they are not the same to everyone .',\n",
       "  'for some , who are travelers , the stars are guides .',\n",
       "  'for others they are nothing but little lights .',\n",
       "  'for others , who are scholars , they are problems .',\n",
       "  'for my businessman they were wealth .',\n",
       "  'but none of these stars say anything back .',\n",
       "  'you will have the stars as no one else has them ... ”',\n",
       "  '“ what are you trying to say ? ”',\n",
       "  '“ when you look at the sky at night , because i ’ ll be living on one of them , because i ’ ll be laughing on one of them , for you it ’ ll be like all the stars are laughing .',\n",
       "  'you - only you - will have stars that can laugh ! ”',\n",
       "  'and he laughed again .',\n",
       "  '“ and when your sorrow is comforted ( time heals all wounds ) you ’ ll be glad to have known me .',\n",
       "  'you ’ ll always be my friend .',\n",
       "  'you ’ ll want to laugh with me .',\n",
       "  'and sometimes , you ’ ll open your window , just like that , for fun ...',\n",
       "  'and your friends will be very surprised to see you laughing whilst watching the sky .',\n",
       "  'so you ’ ll tell them , “ yes , the stars always make me laugh ! ”',\n",
       "  'and they ’ ll think you ’ re crazy .',\n",
       "  'i will have played a dirty trick on you ...',\n",
       "  'and he laughed again .',\n",
       "  '“ it ‘ ll be as if i ’ d given you , instead of stars , lots and lots of little bells that can laugh ... ”',\n",
       "  'and he laughed some more .',\n",
       "  'then he suddenly became serious again : “ tonight ...',\n",
       "  'you know ...',\n",
       "  'don ’ t come . ”',\n",
       "  '“ i won ’ t leave you . ”',\n",
       "  '“ it ’ ll look as if i ’ m suffering ...',\n",
       "  'it ’ ll look a bit as if i ’ m dying .',\n",
       "  'it ’ s like that .',\n",
       "  'don ’ t come to see that .',\n",
       "  'it ’ s not worth it ... ”',\n",
       "  '“ i won ’ t leave you . ”',\n",
       "  'but he was worried .',\n",
       "  '“ i ’ m telling you this — it ’ s also because of the snake .',\n",
       "  'he mustn ’ t bite you ...',\n",
       "  'snakes are mean .',\n",
       "  'they can bite you just for fun ... ”',\n",
       "  '“ i won ’ t leave you . ”',\n",
       "  'but something reassured him : “ it ’ s true that they have no poison left for a second bite . ”',\n",
       "  'that night i didn ’ t see him set out .',\n",
       "  'he got away without making a sound .',\n",
       "  'when i managed to catch him up , he was walking along determinedly , at a brisk pace .',\n",
       "  'he said to me only : “ oh !',\n",
       "  'you came ... ”',\n",
       "  'and he took me by the hand .',\n",
       "  'but he was still worrying .',\n",
       "  '“ you ’ ve made a mistake .',\n",
       "  'you ’ ll suffer .',\n",
       "  'it ’ ll look as if i ’ m dead , and that won ’ t be true ...',\n",
       "  '” i said nothing .',\n",
       "  '“ you understand .',\n",
       "  'it ’ s too far .',\n",
       "  'i can ’ t carry this body with me .',\n",
       "  'it ’ s too heavy . ”',\n",
       "  'i said nothing .',\n",
       "  '“ but it ’ ll be like an old abandoned shell .',\n",
       "  'there ’ s nothing sad about old shells ... ”',\n",
       "  'i said nothing .',\n",
       "  'he got a bit discouraged .',\n",
       "  'but he made one more effort : “ you know , it ’ ll be nice .',\n",
       "  'i ’ ll also look at the stars .',\n",
       "  'all the stars will be wells with a rusty pulley .',\n",
       "  'all the stars will pour out fresh water for me to drink ... ”',\n",
       "  'i said nothing .',\n",
       "  '“ it ’ ll be so much fun !',\n",
       "  'you ’ ll have five hundred million little bells , and i ’ ll have five hundred million springs of fresh water ... ”',\n",
       "  'and then he too was silent , because he was crying .',\n",
       "  '“ here ’ s the place .',\n",
       "  'let me go on by myself . ”',\n",
       "  'and he sat down because he was afraid .',\n",
       "  'he said : “ you know - my flower ...',\n",
       "  'i ’ m responsible for her .',\n",
       "  'and she ’ s so weak !',\n",
       "  'and she ’ s so naive !',\n",
       "  'she has four thorns , of no use at all , to protect herself against the entire world ... ”',\n",
       "  'i sat down too because i was no longer able to stand .',\n",
       "  'he said : “ there ...',\n",
       "  'that ’ s everything ... ”',\n",
       "  'he hesitated a bit , and then stood back up .',\n",
       "  'he took one step .',\n",
       "  'i couldn ’ t move .',\n",
       "  'there was nothing but a yellow flash close to his ankle .',\n",
       "  'he remained motionless for an instant .',\n",
       "  'he didn ’ t cry out .',\n",
       "  'he fell as gently as a tree falls .',\n",
       "  'there was not even any sound , because of the sand .',\n",
       "  'and now of course , it ’ s already been six years ...',\n",
       "  'i have never yet told this story .',\n",
       "  'the companions who met me were very happy to see me alive again .',\n",
       "  'i was sad , but i told them : “ it ’ s because i ’ m tired ... ”',\n",
       "  'now my sorrow is comforted a little .',\n",
       "  'i mean ...',\n",
       "  'not entirely .',\n",
       "  'but i do know that he got back to his planet , because at daybreak i didn ’ t find his body .',\n",
       "  'it wasn ’ t a very heavy body ...',\n",
       "  'and i love to listen to the stars at night .',\n",
       "  'it ’ s just like five hundred million little bells ...',\n",
       "  'but there is one extraordinary thing .',\n",
       "  'when i drew the muzzle for the little prince , i forgot to add the leather strap to it .',\n",
       "  'he would never have been able to fasten it to the sheep .',\n",
       "  'so i wonder : what happened on his planet ?',\n",
       "  'it may well be the sheep ate the flower ...',\n",
       "  'sometimes i tell myself : “ surely not !',\n",
       "  'the little prince shuts his flower under her glass dome every night , and he watches over his sheep very carefully ... ”',\n",
       "  'then i ’ m happy .',\n",
       "  'and all the stars laugh sweetly .',\n",
       "  'other times i tell myself : “ everyone is absent - minded at some point , and that ’ s all it takes !',\n",
       "  'one evening he would ’ ve forgotten the glass dome , or maybe the sheep got out quietly during the night ... ”',\n",
       "  'and then the little bells turn to tears ...',\n",
       "  'herein lies a great mystery .',\n",
       "  'for you , who also love the little prince , just like for me , nothing in the universe is the same if somewhere out there , a sheep that we have never seen has — has it ?',\n",
       "  '- eaten a rose ...',\n",
       "  'look at the sky .',\n",
       "  'ask yourselves : has the sheep - yes or no - eaten the flower ?',\n",
       "  'and you will see how everything changes ...',\n",
       "  'and no grownup will ever understand that this is a matter of such importance !',\n",
       "  'this , to me , is the most beautiful and most sad landscape in the world .',\n",
       "  'it ’ s the same landscape as the one on the previous page , but i have drawn it again to show it to you properly .',\n",
       "  'it ’ s here that the little prince appeared on earth , and then disappeared .',\n",
       "  'look at this landscape carefully , so as to be sure to recognize it if one day you travel in africa , in the desert .',\n",
       "  'and if you happen to pass by there , i beg you , don ’ t hurry on , wait a while exactly under the star .',\n",
       "  'if a child then comes to you , if he laughs , if he has golden hair , if he doesn ’ t respond when questioned , you ’ ll easily guess who it is .',\n",
       "  'so think of me !',\n",
       "  'save me from this sorrow : write to me quickly , to tell me he ’ s back ...']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875ab69cdf0447c38eb0ef4f82750371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "run 0 -> -4.48814926878467\n",
      "run 1 -> -3.592814371257485\n",
      "run 2 -> -2.0051194539249146\n",
      "run 3 -> -3.3243486073674755\n",
      "run 4 -> -2.6402640264026402\n",
      "run 5 -> -3.1426269137792104\n",
      "run 6 -> -1.4569000404694457\n",
      "run 7 -> -1.688374336710082\n",
      "run 8 -> -0.8232065856526852\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "for i in range(9):\n",
    "    a = len(' '.join(iterator_list[i]).split())\n",
    "    b = len(tokenizer.wordpiece_tokenizer.tokenize(' '.join(iterator_list[i])))\n",
    "    print(f'run {i} ->', 100*(a-b)/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['once', ',', 'when', 'i', 'was', 'six', 'years', 'old', ',', 'i', 'saw', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'shuffle_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9e501f8062d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwordpiece_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffle_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_at\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'shuffle_words' is not defined"
     ]
    }
   ],
   "source": [
    "import random \n",
    "sequence = 'once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’'\n",
    "print(tokenizer.wordpiece_tokenizer.tokenize(sequence))\n",
    "len(shuffle_words(sequence, start_at=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_tmp, index_tmp = shuffle_sentence_context(\n",
    "    iterator_list[0][:2], \n",
    "    context_size=6, \n",
    "    pretrained_model='bert-base-uncased',\n",
    "    seed=1111)\n",
    "for b in batch_tmp:\n",
    "    print(b)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') # to replace with tokenizer of interest\n",
    "\n",
    "for i, j in enumerate(batch_tmp):\n",
    "    j  ='[CLS] ' + j + ' [SEP]'\n",
    "    print(tokenizer.wordpiece_tokenizer.tokenize(j)[index_tmp[i][0]+1:1+index_tmp[i][1]])\n",
    "#len(tokenizer.wordpiece_tokenizer.tokenize(' '.join(context[i]) + ' ' + ' '.join(words[:i+1])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "iterator_list[0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_tmp, index_tmp = batchify_sentences(\n",
    "    iterator_list[0][:3],\n",
    "    'bert-base-uncased',\n",
    "    1, \n",
    "    1, \n",
    "    0,\n",
    "    10,\n",
    "    transformation='shuffle',\n",
    "    vocabulary=None,\n",
    "    dictionary=None,\n",
    "    seed=111\n",
    ")\n",
    "for i, j in enumerate(batch_tmp):\n",
    "    #j  ='[CLS] ' + j + ' [SEP]'\n",
    "    #print(index_tmp[i])\n",
    "    #print(tokenizer.wordpiece_tokenizer.tokenize(j))\n",
    "    print('##', i, ' - ', j)\n",
    "    #print('##', i, ' - ', tokenizer.wordpiece_tokenizer.tokenize(j)[index_tmp[i][0]:index_tmp[i][1]])\n",
    "    #print(tokenizer.wordpiece_tokenizer.tokenize(j)[1+index_tmp[i][0]:1+index_tmp[i][1]])\n",
    "    #print()\n",
    "    #print()\n",
    "#print(batch_tmp[-2])\n",
    "#print(batch_tmp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [0,0,0,3, 4, 5]\n",
    "l[len(l):len(l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#tokenizer.wordpiece_tokenizer.tokenize('he mustn ’ t bite you ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#import utils\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "#from transformers import BertTokenizer\n",
    "#\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#lengths = []\n",
    "#\n",
    "#for index in range(9):\n",
    "#    batches, indexes = utils.batchify_per_sentence_with_pre_and_post_context(\n",
    "#                iterator_list[index], \n",
    "#                1, \n",
    "#                12, \n",
    "#                0, \n",
    "#                'bert-base-uncased', \n",
    "#                max_length=512)\n",
    "#    #lengths.append(np.array(sorted([len(item.split()) for item in batches])))\n",
    "#    lengths.append(np.array(sorted([len(tokenizer.wordpiece_tokenizer.tokenize(item)) for item in batches])))\n",
    "#\n",
    "#    #sns.boxplot(lengths[-1])\n",
    "#    #plt.show()\n",
    "#    #print()\n",
    "#\n",
    "#print(np.mean(np.array([np.mean(item) for item in lengths])))\n",
    "#print(np.median(np.array([np.median(item) for item in lengths])))\n",
    "#print(np.mean(np.array([np.median(item) for item in lengths])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import utils\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "#\n",
    "#for index in range(9):\n",
    "#    batches, indexes = utils.batchify_per_sentence_with_pre_and_post_context(\n",
    "#                iterator_list[index], \n",
    "#                1, \n",
    "#                10, \n",
    "#                0, \n",
    "#                'bert-base-uncased', \n",
    "#                max_length=512)\n",
    "#    #print(len(batches))\n",
    "#    #print(sorted([len(item.split()) for item in batches]))\n",
    "#    #sns.boxplot(sorted([len(item.split()) for item in batches]))\n",
    "#    #plt.show()\n",
    "#    #print()\n",
    "#    indexes_tmp = []\n",
    "#    for i in range(len(indexes)):\n",
    "#        if type(indexes[i])==list and type(indexes[i][0])==list:\n",
    "#            indexes_tmp.append(indexes[i][-1])\n",
    "#        else:\n",
    "#            if i > 0:\n",
    "#                indexes_tmp.append((\n",
    "#                indexes[i][-1-2][0], \n",
    "#                indexes[i][-1-2][1]))\n",
    "#            else:\n",
    "#                indexes_tmp.append(None)\n",
    "#\n",
    "#    indexes_tmp[0] = (indexes[0][0][0], indexes[0][-1][1])\n",
    "#    print(indexes_tmp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_bert_models = ['bert-base-uncased']\n",
    "names = [\n",
    "    'bert-base-uncased_pre-2_1_post-0_token-8-0'\n",
    "\n",
    "         ]\n",
    "config_paths = [None] * 34\n",
    "saving_path_folders = [\n",
    "    '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/{}/bert-base-uncased_pre-2_1_post-0_token-8-0'.format(language),\n",
    "    \n",
    "]\n",
    "prediction_types = ['shuffle'] * 34\n",
    "number_of_sentence_list = [1] * 34\n",
    "number_of_sentence_before_list = [1]\n",
    "number_of_sentence_after_list = [0] * 21\n",
    "attention_length_before_list = [1] * 34\n",
    "attention_length_after_list = [0] * 34\n",
    "\n",
    "stop_attention_at_sent_before_list = [None] * 34\n",
    "stop_attention_before_sent_list = [0] * 34\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased_pre-2_1_post-0_token-8-0  - Extracting activations ...\n",
      "############# Run 0 #############\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Careful last sentence selected...\n",
      "Batch number:  0  -  [CLS] once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'once', ',', 'when', 'i', 'was', 'six', 'years', 'old', ',', 'i', 'saw', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (1, 2) ['once']\n",
      "\n",
      "['once']\n",
      "[0] [CLS]\n",
      "[1] once\n",
      "[2] ,\n",
      "[3] when\n",
      "[4] i\n",
      "[5] was\n",
      "[6] six\n",
      "[7] years\n",
      "[8] old\n",
      "[9] ,\n",
      "[10] i\n",
      "[11] saw\n",
      "[12] a\n",
      "[13] magnificent\n",
      "[14] picture\n",
      "[15] in\n",
      "[16] a\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "2 2\n",
      "Batch number:  1  -  [CLS] once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'once', ',', 'when', 'i', 'was', 'six', 'years', 'old', ',', 'i', 'saw', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (2, 3) [',']\n",
      "\n",
      "[',']\n",
      "[0] [CLS]\n",
      "[1] once\n",
      "[2] ,\n",
      "[3] when\n",
      "[4] i\n",
      "[5] was\n",
      "[6] six\n",
      "[7] years\n",
      "[8] old\n",
      "[9] ,\n",
      "[10] i\n",
      "[11] saw\n",
      "[12] a\n",
      "[13] magnificent\n",
      "[14] picture\n",
      "[15] in\n",
      "[16] a\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "3 3\n",
      "Batch number:  2  -  [CLS] once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'once', ',', 'when', 'i', 'was', 'six', 'years', 'old', ',', 'i', 'saw', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (3, 4) ['when']\n",
      "\n",
      "['when']\n",
      "[0] [CLS]\n",
      "[1] once\n",
      "[2] ,\n",
      "[3] when\n",
      "[4] i\n",
      "[5] was\n",
      "[6] six\n",
      "[7] years\n",
      "[8] old\n",
      "[9] ,\n",
      "[10] i\n",
      "[11] saw\n",
      "[12] a\n",
      "[13] magnificent\n",
      "[14] picture\n",
      "[15] in\n",
      "[16] a\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "4 4\n",
      "Batch number:  3  -  [CLS] once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'once', ',', 'when', 'i', 'was', 'six', 'years', 'old', ',', 'i', 'saw', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (4, 5) ['i']\n",
      "\n",
      "['i']\n",
      "[0] [CLS]\n",
      "[1] once\n",
      "[2] ,\n",
      "[3] when\n",
      "[4] i\n",
      "[5] was\n",
      "[6] six\n",
      "[7] years\n",
      "[8] old\n",
      "[9] ,\n",
      "[10] i\n",
      "[11] saw\n",
      "[12] a\n",
      "[13] magnificent\n",
      "[14] picture\n",
      "[15] in\n",
      "[16] a\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "5 5\n",
      "Batch number:  4  -  [CLS] when , once i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'when', ',', 'once', 'i', 'was', 'six', 'years', 'old', ',', 'i', 'saw', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (5, 6) ['was']\n",
      "\n",
      "['was']\n",
      "[0] [CLS]\n",
      "[1] when\n",
      "[2] ,\n",
      "[3] once\n",
      "[4] i\n",
      "[5] was\n",
      "[6] six\n",
      "[7] years\n",
      "[8] old\n",
      "[9] ,\n",
      "[10] i\n",
      "[11] saw\n",
      "[12] a\n",
      "[13] magnificent\n",
      "[14] picture\n",
      "[15] in\n",
      "[16] a\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "6 6\n",
      "Batch number:  5  -  [CLS] when , i once was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'when', ',', 'i', 'once', 'was', 'six', 'years', 'old', ',', 'i', 'saw', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (6, 7) ['six']\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['six']\n",
      "[0] [CLS]\n",
      "[1] when\n",
      "[2] ,\n",
      "[3] i\n",
      "[4] once\n",
      "[5] was\n",
      "[6] six\n",
      "[7] years\n",
      "[8] old\n",
      "[9] ,\n",
      "[10] i\n",
      "[11] saw\n",
      "[12] a\n",
      "[13] magnificent\n",
      "[14] picture\n",
      "[15] in\n",
      "[16] a\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "7 7\n",
      "Batch number:  6  -  [CLS] when , once was i six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'when', ',', 'once', 'was', 'i', 'six', 'years', 'old', ',', 'i', 'saw', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (7, 8) ['years']\n",
      "\n",
      "['years']\n",
      "[0] [CLS]\n",
      "[1] when\n",
      "[2] ,\n",
      "[3] once\n",
      "[4] was\n",
      "[5] i\n",
      "[6] six\n",
      "[7] years\n",
      "[8] old\n",
      "[9] ,\n",
      "[10] i\n",
      "[11] saw\n",
      "[12] a\n",
      "[13] magnificent\n",
      "[14] picture\n",
      "[15] in\n",
      "[16] a\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "8 8\n",
      "Batch number:  7  -  [CLS] was , when i once six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'was', ',', 'when', 'i', 'once', 'six', 'years', 'old', ',', 'i', 'saw', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (8, 9) ['old']\n",
      "\n",
      "['old']\n",
      "[0] [CLS]\n",
      "[1] was\n",
      "[2] ,\n",
      "[3] when\n",
      "[4] i\n",
      "[5] once\n",
      "[6] six\n",
      "[7] years\n",
      "[8] old\n",
      "[9] ,\n",
      "[10] i\n",
      "[11] saw\n",
      "[12] a\n",
      "[13] magnificent\n",
      "[14] picture\n",
      "[15] in\n",
      "[16] a\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "9 9\n",
      "Batch number:  8  -  [CLS] once , i when was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'once', ',', 'i', 'when', 'was', 'six', 'years', 'old', ',', 'i', 'saw', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (9, 10) [',']\n",
      "\n",
      "[',']\n",
      "[0] [CLS]\n",
      "[1] once\n",
      "[2] ,\n",
      "[3] i\n",
      "[4] when\n",
      "[5] was\n",
      "[6] six\n",
      "[7] years\n",
      "[8] old\n",
      "[9] ,\n",
      "[10] i\n",
      "[11] saw\n",
      "[12] a\n",
      "[13] magnificent\n",
      "[14] picture\n",
      "[15] in\n",
      "[16] a\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "10 10\n",
      "Batch number:  9  -  [CLS] i , when six years was once old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'i', ',', 'when', 'six', 'years', 'was', 'once', 'old', ',', 'i', 'saw', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (10, 11) ['i']\n",
      "\n",
      "['i']\n",
      "[0] [CLS]\n",
      "[1] i\n",
      "[2] ,\n",
      "[3] when\n",
      "[4] six\n",
      "[5] years\n",
      "[6] was\n",
      "[7] once\n",
      "[8] old\n",
      "[9] ,\n",
      "[10] i\n",
      "[11] saw\n",
      "[12] a\n",
      "[13] magnificent\n",
      "[14] picture\n",
      "[15] in\n",
      "[16] a\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "11 11\n",
      "Batch number:  10  -  [CLS] was , once old when years six i , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'was', ',', 'once', 'old', 'when', 'years', 'six', 'i', ',', 'i', 'saw', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (11, 12) ['saw']\n",
      "\n",
      "['saw']\n",
      "[0] [CLS]\n",
      "[1] was\n",
      "[2] ,\n",
      "[3] once\n",
      "[4] old\n",
      "[5] when\n",
      "[6] years\n",
      "[7] six\n",
      "[8] i\n",
      "[9] ,\n",
      "[10] i\n",
      "[11] saw\n",
      "[12] a\n",
      "[13] magnificent\n",
      "[14] picture\n",
      "[15] in\n",
      "[16] a\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "12 12\n",
      "Batch number:  11  -  [CLS] when , old was years i once six , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'when', ',', 'old', 'was', 'years', 'i', 'once', 'six', ',', 'i', 'saw', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (12, 13) ['a']\n",
      "\n",
      "['a']\n",
      "[0] [CLS]\n",
      "[1] when\n",
      "[2] ,\n",
      "[3] old\n",
      "[4] was\n",
      "[5] years\n",
      "[6] i\n",
      "[7] once\n",
      "[8] six\n",
      "[9] ,\n",
      "[10] i\n",
      "[11] saw\n",
      "[12] a\n",
      "[13] magnificent\n",
      "[14] picture\n",
      "[15] in\n",
      "[16] a\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "13 13\n",
      "Batch number:  12  -  [CLS] i , old six when was years once , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'i', ',', 'old', 'six', 'when', 'was', 'years', 'once', ',', 'i', 'saw', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (13, 14) ['magnificent']\n",
      "\n",
      "['magnificent']\n",
      "[0] [CLS]\n",
      "[1] i\n",
      "[2] ,\n",
      "[3] old\n",
      "[4] six\n",
      "[5] when\n",
      "[6] was\n",
      "[7] years\n",
      "[8] once\n",
      "[9] ,\n",
      "[10] i\n",
      "[11] saw\n",
      "[12] a\n",
      "[13] magnificent\n",
      "[14] picture\n",
      "[15] in\n",
      "[16] a\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "14 14\n",
      "Batch number:  13  -  [CLS] saw , was years when i old i , six once a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'saw', ',', 'was', 'years', 'when', 'i', 'old', 'i', ',', 'six', 'once', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (14, 15) ['picture']\n",
      "\n",
      "['picture']\n",
      "[0] [CLS]\n",
      "[1] saw\n",
      "[2] ,\n",
      "[3] was\n",
      "[4] years\n",
      "[5] when\n",
      "[6] i\n",
      "[7] old\n",
      "[8] i\n",
      "[9] ,\n",
      "[10] six\n",
      "[11] once\n",
      "[12] a\n",
      "[13] magnificent\n",
      "[14] picture\n",
      "[15] in\n",
      "[16] a\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "15 15\n",
      "Batch number:  14  -  [CLS] old , i was i once saw when , years a six magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'old', ',', 'i', 'was', 'i', 'once', 'saw', 'when', ',', 'years', 'a', 'six', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (15, 16) ['in']\n",
      "\n",
      "['in']\n",
      "[0] [CLS]\n",
      "[1] old\n",
      "[2] ,\n",
      "[3] i\n",
      "[4] was\n",
      "[5] i\n",
      "[6] once\n",
      "[7] saw\n",
      "[8] when\n",
      "[9] ,\n",
      "[10] years\n",
      "[11] a\n",
      "[12] six\n",
      "[13] magnificent\n",
      "[14] picture\n",
      "[15] in\n",
      "[16] a\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "16 16\n",
      "Batch number:  15  -  [CLS] six , a i was old when years , once saw magnificent i picture in a book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'six', ',', 'a', 'i', 'was', 'old', 'when', 'years', ',', 'once', 'saw', 'magnificent', 'i', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (16, 17) ['a']\n",
      "\n",
      "['a']\n",
      "[0] [CLS]\n",
      "[1] six\n",
      "[2] ,\n",
      "[3] a\n",
      "[4] i\n",
      "[5] was\n",
      "[6] old\n",
      "[7] when\n",
      "[8] years\n",
      "[9] ,\n",
      "[10] once\n",
      "[11] saw\n",
      "[12] magnificent\n",
      "[13] i\n",
      "[14] picture\n",
      "[15] in\n",
      "[16] a\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "17 17\n",
      "Batch number:  16  -  [CLS] saw , when old years i i six , was once picture a magnificent in a book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'saw', ',', 'when', 'old', 'years', 'i', 'i', 'six', ',', 'was', 'once', 'picture', 'a', 'magnificent', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (17, 18) ['book']\n",
      "\n",
      "['book']\n",
      "[0] [CLS]\n",
      "[1] saw\n",
      "[2] ,\n",
      "[3] when\n",
      "[4] old\n",
      "[5] years\n",
      "[6] i\n",
      "[7] i\n",
      "[8] six\n",
      "[9] ,\n",
      "[10] was\n",
      "[11] once\n",
      "[12] picture\n",
      "[13] a\n",
      "[14] magnificent\n",
      "[15] in\n",
      "[16] a\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "18 18\n",
      "Batch number:  17  -  [CLS] six , i was magnificent saw picture years , when i once a old in a book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'six', ',', 'i', 'was', 'magnificent', 'saw', 'picture', 'years', ',', 'when', 'i', 'once', 'a', 'old', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (18, 19) ['about']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [01:13, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['about']\n",
      "[0] [CLS]\n",
      "[1] six\n",
      "[2] ,\n",
      "[3] i\n",
      "[4] was\n",
      "[5] magnificent\n",
      "[6] saw\n",
      "[7] picture\n",
      "[8] years\n",
      "[9] ,\n",
      "[10] when\n",
      "[11] i\n",
      "[12] once\n",
      "[13] a\n",
      "[14] old\n",
      "[15] in\n",
      "[16] a\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "19 19\n",
      "Batch number:  18  -  [CLS] a , years old i six was saw , once when magnificent i a in picture book about the primeval forest called ‘ real - life stories . ’ [SEP]\n",
      "['[CLS]', 'a', ',', 'years', 'old', 'i', 'six', 'was', 'saw', ',', 'once', 'when', 'magnificent', 'i', 'a', 'in', 'picture', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'real', '-', 'life', 'stories', '.', '’', '[SEP]']\n",
      "indexes: (19, 20) ['the']\n",
      "\n",
      "['the']\n",
      "[0] [CLS]\n",
      "[1] a\n",
      "[2] ,\n",
      "[3] years\n",
      "[4] old\n",
      "[5] i\n",
      "[6] six\n",
      "[7] was\n",
      "[8] saw\n",
      "[9] ,\n",
      "[10] once\n",
      "[11] when\n",
      "[12] magnificent\n",
      "[13] i\n",
      "[14] a\n",
      "[15] in\n",
      "[16] picture\n",
      "[17] book\n",
      "[18] about\n",
      "[19] the\n",
      "[20, 21] prime##val\n",
      "[22] forest\n",
      "[23] called\n",
      "[24] ‘\n",
      "[25] real\n",
      "[26] -\n",
      "[27] life\n",
      "[28] stories\n",
      "[29] .\n",
      "[30] ’\n",
      "[31] [SEP]\n",
      "20 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7c0c4fcd3d8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"############# Run {} #############\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mactivations\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mhidden_states_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mattention_heads_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/Parietal/NLP_models/BERT/model.py\u001b[0m in \u001b[0;36mextract_activations\u001b[0;34m(self, iterator, language)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m'shuffle'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_special_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'shuffle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mhidden_states_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/Parietal/NLP_models/BERT/model.py\u001b[0m in \u001b[0;36mget_special_activations\u001b[0;34m(self, iterator, language, transformation)\u001b[0m\n\u001b[1;32m    492\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m                     \u001b[0mhidden_states_activations_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# retrieve all the hidden states (dimension = layer_count * len(tokenized_text) * feature_count)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m                     \u001b[0mhidden_states_activations\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_activations_from_token_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states_activations_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#verify if we have to add 1 to indexes values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/Parietal/NLP_models/BERT/utils.py\u001b[0m in \u001b[0;36mextract_activations_from_token_activations\u001b[0;34m(activation, mapping, indexes, tokenizer, tokenized_text)\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0mkey_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_stop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mword_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_stop\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# len(mapping.keys()) - 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0mword_activation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0mword_activation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "for index, bert_model in enumerate(pretrained_bert_models):\n",
    "    extractor = BertExtractor(bert_model, \n",
    "                              language, \n",
    "                              names[index], \n",
    "                              prediction_types[index], \n",
    "                              output_hidden_states=True, \n",
    "                              output_attentions=False, \n",
    "                              attention_length_before=attention_length_before_list[index],\n",
    "                              attention_length_after=attention_length_after_list[index],\n",
    "                              config_path=config_paths[index], \n",
    "                              max_length=512, \n",
    "                              number_of_sentence=number_of_sentence_list[index], \n",
    "                              number_of_sentence_before=number_of_sentence_before_list[index], \n",
    "                              number_of_sentence_after=number_of_sentence_after_list[index],\n",
    "                              stop_attention_at_sent_before=stop_attention_at_sent_before_list[index],\n",
    "                              stop_attention_before_sent=stop_attention_before_sent_list[index],\n",
    "                             )\n",
    "    print(extractor.name, ' - Extracting activations ...')\n",
    "    for run_index, iterator in tqdm(enumerate(iterator_list)):\n",
    "        gc.collect()\n",
    "        print(\"############# Run {} #############\".format(run_index))\n",
    "        activations  = extractor.extract_activations(iterator, language)\n",
    "        hidden_states_activations = activations[0]\n",
    "        attention_heads_activations = activations[1]\n",
    "        #(cls_hidden_states_activations, cls_attention_activations) = activations[2]\n",
    "        #(sep_hidden_states_activations, sep_attention_activations) = activations[3]\n",
    "        #activations = pd.concat([hidden_states_activations, attention_heads_activations], axis=1)\n",
    "        #cls_activations = pd.concat([cls_hidden_states_activations, cls_attention_activations], axis=1)\n",
    "        #sep_activations = pd.concat([sep_hidden_states_activations, sep_attention_activations], axis=1)\n",
    "\n",
    "        #transform(\n",
    "        #    hidden_states_activations, \n",
    "        #    saving_path_folders[index], \n",
    "        #    'activations', \n",
    "        #    run_index=run_index,\n",
    "        #    n_layers_hidden=13,\n",
    "        #    n_layers_attention=0, \n",
    "        #    hidden_size=768)\n",
    "\n",
    "        #transform(cls_activations, saving_path_folders[index], 'cls')\n",
    "        #transform(sep_activations, saving_path_folders[index], 'sep')\n",
    "        #check_folder(saving_path_folders[index])\n",
    "        #hidden_states_activations.to_csv(os.path.join(saving_path_folders[index], 'activations_run{}.csv'.format(run_index + 1)), index=False)\n",
    "        #cls_activations.to_csv(os.path.join(saving_path_folders[index], 'cls_run{}.csv'.format(run_index + 1)), index=False)\n",
    "        #sep_activations.to_csv(os.path.join(saving_path_folders[index], 'sep_run{}.csv'.format(run_index + 1)), index=False)\n",
    "        del activations\n",
    "        #del cls_activations\n",
    "        #del sep_activations\n",
    "        del hidden_states_activations\n",
    "        #del attention_heads_activations\n",
    "        #del cls_hidden_states_activations\n",
    "        #del cls_attention_activations\n",
    "        #del sep_hidden_states_activations\n",
    "        #del sep_attention_activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator_list[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate control activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = 'bert-base-cased'\n",
    "language = 'english'\n",
    "name = 'bert-base-cased_control_'\n",
    "prediction_type = 'sentence'\n",
    "saving_path_folder = '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/stimuli-representations/{}'.format(language)\n",
    "seeds = [24, 213, 1111, 61, 183]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_layer(model, layer_nb):\n",
    "    \"\"\"Randomize layer weights and put bias to zero.\n",
    "    The input \"layer_nb\" goes from 1 to 12 to be coherent with the rest of the analysis.\n",
    "    It is then transfomed in the function.\n",
    "    \"\"\"\n",
    "    layer_nb = layer_nb - 1\n",
    "    model.encoder.layer[layer_nb].attention.self.query.weight = torch.nn.parameter.Parameter(torch.rand_like(model.encoder.layer[layer_nb].attention.self.query.weight))\n",
    "    model.encoder.layer[layer_nb].attention.self.query.bias = torch.nn.parameter.Parameter(torch.zeros_like(model.encoder.layer[layer_nb].attention.self.query.bias))\n",
    "    model.encoder.layer[layer_nb].attention.self.key.weight = torch.nn.parameter.Parameter(torch.rand_like(model.encoder.layer[layer_nb].attention.self.key.weight))\n",
    "    model.encoder.layer[layer_nb].attention.self.key.bias = torch.nn.parameter.Parameter(torch.zeros_like(model.encoder.layer[layer_nb].attention.self.key.bias))\n",
    "    model.encoder.layer[layer_nb].attention.self.value.weight = torch.nn.parameter.Parameter(torch.rand_like(model.encoder.layer[layer_nb].attention.self.value.weight))\n",
    "    model.encoder.layer[layer_nb].attention.self.value.bias = torch.nn.parameter.Parameter(torch.zeros_like(model.encoder.layer[layer_nb].attention.self.value.bias))\n",
    "    model.encoder.layer[layer_nb].attention.output.dense.weight = torch.nn.parameter.Parameter(torch.rand_like(model.encoder.layer[layer_nb].attention.output.dense.weight))\n",
    "    model.encoder.layer[layer_nb].attention.output.dense.bias = torch.nn.parameter.Parameter(torch.zeros_like(model.encoder.layer[layer_nb].attention.output.dense.bias))\n",
    "    model.encoder.layer[layer_nb].attention.output.LayerNorm.weight = torch.nn.parameter.Parameter(torch.rand_like(model.encoder.layer[layer_nb].attention.output.LayerNorm.weight))\n",
    "    model.encoder.layer[layer_nb].attention.output.LayerNorm.bias = torch.nn.parameter.Parameter(torch.zeros_like(model.encoder.layer[layer_nb].attention.output.LayerNorm.bias))\n",
    "    model.encoder.layer[layer_nb].intermediate.dense.weight = torch.nn.parameter.Parameter(torch.rand_like(model.encoder.layer[layer_nb].intermediate.dense.weight))\n",
    "    model.encoder.layer[layer_nb].intermediate.dense.bias = torch.nn.parameter.Parameter(torch.zeros_like(model.encoder.layer[layer_nb].intermediate.dense.bias))\n",
    "    model.encoder.layer[layer_nb].output.dense.weight = torch.nn.parameter.Parameter(torch.rand_like(model.encoder.layer[layer_nb].output.dense.weight))\n",
    "    model.encoder.layer[layer_nb].output.dense.bias = torch.nn.parameter.Parameter(torch.zeros_like(model.encoder.layer[layer_nb].output.dense.bias))\n",
    "    model.encoder.layer[layer_nb].output.LayerNorm.weight = torch.nn.parameter.Parameter(torch.rand_like(model.encoder.layer[layer_nb].output.LayerNorm.weight))\n",
    "    model.encoder.layer[layer_nb].output.LayerNorm.bias = torch.nn.parameter.Parameter(torch.zeros_like(model.encoder.layer[layer_nb].output.LayerNorm.bias))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_attention_query(model, layer_nb):\n",
    "    \"\"\"Randomize attention query weights of a given layer and put bias to zero.\n",
    "    \"\"\"\n",
    "    layer_nb = layer_nb - 1\n",
    "    model.encoder.layer[layer_nb].attention.self.query.weight = torch.nn.parameter.Parameter(torch.rand_like(model.encoder.layer[layer_nb].attention.self.query.weight))\n",
    "    model.encoder.layer[layer_nb].attention.self.query.bias = torch.nn.parameter.Parameter(torch.zeros_like(model.encoder.layer[layer_nb].attention.self.query.bias))\n",
    "    return model\n",
    "\n",
    "def randomize_attention_key(model, layer_nb):\n",
    "    \"\"\"Randomize attention key weights of a given layer and put bias to zero.\n",
    "    \"\"\"\n",
    "    layer_nb = layer_nb - 1\n",
    "    model.encoder.layer[layer_nb].attention.self.key.weight = torch.nn.parameter.Parameter(torch.rand_like(model.encoder.layer[layer_nb].attention.self.key.weight))\n",
    "    model.encoder.layer[layer_nb].attention.self.key.bias = torch.nn.parameter.Parameter(torch.zeros_like(model.encoder.layer[layer_nb].attention.self.key.bias))\n",
    "    return model\n",
    "\n",
    "def randomize_attention_value(model, layer_nb):\n",
    "    \"\"\"Randomize attention value weights of a given layer and put bias to zero.\n",
    "    \"\"\"\n",
    "    layer_nb = layer_nb - 1\n",
    "    model.encoder.layer[layer_nb].attention.self.value.weight = torch.nn.parameter.Parameter(torch.rand_like(model.encoder.layer[layer_nb].attention.self.value.weight))\n",
    "    model.encoder.layer[layer_nb].attention.self.value.bias = torch.nn.parameter.Parameter(torch.zeros_like(model.encoder.layer[layer_nb].attention.self.value.bias))\n",
    "    return model\n",
    "\n",
    "def randomize_attention_output_dense(model, layer_nb):\n",
    "    \"\"\"Randomize attention dense network weights of a given layer and put bias to zero.\n",
    "    \"\"\"\n",
    "    layer_nb = layer_nb - 1\n",
    "    model.encoder.layer[layer_nb].attention.output.dense.weight = torch.nn.parameter.Parameter(torch.rand_like(model.encoder.layer[layer_nb].attention.output.dense.weight))\n",
    "    model.encoder.layer[layer_nb].attention.output.dense.bias = torch.nn.parameter.Parameter(torch.zeros_like(model.encoder.layer[layer_nb].attention.output.dense.bias))\n",
    "    return model\n",
    "\n",
    "\n",
    "def randomize_intermediate_dense(model, layer_nb):\n",
    "    \"\"\"Randomize intermediate dense network weights of a given layer and put bias to zero.\n",
    "    \"\"\"\n",
    "    layer_nb = layer_nb - 1\n",
    "    model.encoder.layer[layer_nb].intermediate.dense.weight = torch.nn.parameter.Parameter(torch.rand_like(model.encoder.layer[layer_nb].intermediate.dense.weight))\n",
    "    model.encoder.layer[layer_nb].intermediate.dense.bias = torch.nn.parameter.Parameter(torch.zeros_like(model.encoder.layer[layer_nb].intermediate.dense.bias))\n",
    "    return model\n",
    "\n",
    "def randomize_outptut_dense(model, layer_nb):\n",
    "    \"\"\"Randomize output dense network weights of a given layer and put bias to zero.\n",
    "    \"\"\"\n",
    "    layer_nb = layer_nb - 1\n",
    "    model.encoder.layer[layer_nb].output.dense.weight = torch.nn.parameter.Parameter(torch.rand_like(model.encoder.layer[layer_nb].output.dense.weight))\n",
    "    model.encoder.layer[layer_nb].output.dense.bias = torch.nn.parameter.Parameter(torch.zeros_like(model.encoder.layer[layer_nb].output.dense.bias))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_embeddings(model):\n",
    "    \"\"\"Randomize embeddings weights and put bias to zero.\n",
    "    \"\"\"\n",
    "    model.embeddings.word_embeddings.weight = torch.nn.parameter.Parameter(torch.rand_like(model.embeddings.word_embeddings.weight))\n",
    "    model.embeddings.position_embeddings.weight = torch.nn.parameter.Parameter(torch.rand_like(model.embeddings.position_embeddings.weight))\n",
    "    model.embeddings.token_type_embeddings.weight = torch.nn.parameter.Parameter(torch.rand_like(model.embeddings.token_type_embeddings.weight))\n",
    "    model.embeddings.LayerNorm.weight = torch.nn.parameter.Parameter(torch.rand_like(model.embeddings.LayerNorm.weight))\n",
    "    model.embeddings.LayerNorm.bias = torch.nn.parameter.Parameter(torch.zeros_like(model.embeddings.LayerNorm.bias))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    for layer in range(13):\n",
    "        extractor = BertExtractor(bert_model, language, name, prediction_type, output_hidden_states=True, output_attentions=True, config_path=None)\n",
    "        if layer==0:\n",
    "            extractor.model = randomize_embeddings(extractor.model)\n",
    "        else:\n",
    "            extractor.model = randomize_layer(extractor.model, layer)\n",
    "        print(extractor.name + str(seed), ' - Extracting activations for layer {}...'.format(layer))\n",
    "        for run_index, iterator in tqdm(enumerate(iterator_list)):\n",
    "            print(\"############# Run {} #############\".format(run_index))\n",
    "            activations  = extractor.extract_activations(iterator, language)\n",
    "            hidden_states_activations = activations[0]\n",
    "            attention_heads_activations = activations[1]\n",
    "            (cls_hidden_states_activations, cls_attention_activations) = activations[2]\n",
    "            (sep_hidden_states_activations, sep_attention_activations) = activations[3]\n",
    "            activations = pd.concat([hidden_states_activations, attention_heads_activations], axis=1)\n",
    "            cls_activations = pd.concat([cls_hidden_states_activations, cls_attention_activations], axis=1)\n",
    "            sep_activations = pd.concat([sep_hidden_states_activations, sep_attention_activations], axis=1)\n",
    "\n",
    "            # activations\n",
    "            heads = np.arange(1, 13)\n",
    "            columns_to_retrieve = ['hidden_state-layer-{}-{}'.format(layer, i) for i in range(1, 769)]\n",
    "            if layer > 0:\n",
    "                columns_to_retrieve += ['attention-layer-{}-head-{}-{}'.format(layer, head, i) for head in heads for i in range(1, 65)]\n",
    "            activations = activations[columns_to_retrieve]\n",
    "\n",
    "            # CLS\n",
    "            heads = np.arange(1, 13)\n",
    "            columns_to_retrieve = ['CLS-hidden_state-layer-{}-{}'.format(layer, i) for i in range(1, 769)]\n",
    "            if layer > 0:\n",
    "                columns_to_retrieve += ['CLS-attention-layer-{}-head-{}-{}'.format(layer, head, i) for head in heads for i in range(1, 65)]\n",
    "            cls_activations = cls_activations[columns_to_retrieve]\n",
    "\n",
    "            # SEP\n",
    "            heads = np.arange(1, 13)\n",
    "            columns_to_retrieve = ['SEP-hidden_state-layer-{}-{}'.format(layer, i) for i in range(1, 769)]\n",
    "            if layer > 0:\n",
    "                columns_to_retrieve += ['SEP-attention-layer-{}-head-{}-{}'.format(layer, head, i) for head in heads for i in range(1, 65)]\n",
    "            sep_activations = sep_activations[columns_to_retrieve]\n",
    "\n",
    "            save_path = os.path.join(saving_path_folder, name + str(seed) + '_layer-{}'.format(layer))\n",
    "            check_folder(save_path)\n",
    "            print('\\tSaving in {}.'.format(save_path))\n",
    "            activations.to_csv(os.path.join(save_path, 'activations_run{}.csv'.format(run_index + 1)), index=False)\n",
    "            cls_activations.to_csv(os.path.join(save_path, 'cls_run{}.csv'.format(run_index + 1)), index=False)\n",
    "            sep_activations.to_csv(os.path.join(save_path, 'sep_run{}.csv'.format(run_index + 1)), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test activation extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import utils \n",
    "import random\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "config = {\n",
    "    'number_of_sentence': 1, \n",
    "    'number_of_sentence_before': 3, \n",
    "    'number_of_sentence_after': 3, \n",
    "    'attention_length_before': 1000, \n",
    "    'attention_length_after': 1000,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "extractor_full = BertExtractor('bert-base-uncased', \n",
    "                              'english', \n",
    "                              'test', \n",
    "                              'sentence', \n",
    "                              output_hidden_states=True, \n",
    "                              output_attentions=False, \n",
    "                              attention_length_before=config['attention_length_before'],\n",
    "                              attention_length_after=config['attention_length_after'],\n",
    "                              config_path=None, \n",
    "                              number_of_sentence=config['number_of_sentence'], \n",
    "                              number_of_sentence_before=config['number_of_sentence_before'], \n",
    "                              number_of_sentence_after=config['number_of_sentence_after'], \n",
    "                             )\n",
    "extractor_masked = BertExtractor('bert-base-uncased', \n",
    "                              'english', \n",
    "                              'test', \n",
    "                              'control-context', \n",
    "                              output_hidden_states=True, \n",
    "                              output_attentions=False, \n",
    "                              attention_length_before=config['attention_length_before'],\n",
    "                              attention_length_after=config['attention_length_after'],\n",
    "                              config_path=None, \n",
    "                              number_of_sentence=config['number_of_sentence'], \n",
    "                              number_of_sentence_before=config['number_of_sentence_before'], \n",
    "                              number_of_sentence_after=config['number_of_sentence_after'], \n",
    "                             )\n",
    "#extractor_shuffle = BertExtractor('bert-base-uncased', \n",
    "#                              'english', \n",
    "#                              'test', \n",
    "#                              'shuffle', \n",
    "#                              output_hidden_states=True, \n",
    "#                              output_attentions=False, \n",
    "#                              attention_length_before=config['attention_length_before'],\n",
    "#                              attention_length_after=config['attention_length_after'],\n",
    "#                              config_path=None, \n",
    "#                              number_of_sentence=config['number_of_sentence'], \n",
    "#                              number_of_sentence_before=config['number_of_sentence_before'], \n",
    "#                              number_of_sentence_after=config['number_of_sentence_after'], \n",
    "#                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Full sentences\n",
    "batches_full, indexes_full = bert_utils.batchify_per_sentence_with_pre_and_post_context(\n",
    "            iterator_list[0], \n",
    "            config['number_of_sentence'], \n",
    "            config['number_of_sentence_before'], \n",
    "            config['number_of_sentence_after'], \n",
    "            'bert-base-uncased',\n",
    "        )\n",
    "\n",
    "# Tokens are masked\n",
    "batches_masked, indexes_masked = bert_utils.batchify_per_sentence_with_pre_and_post_context(\n",
    "            iterator_list[0], \n",
    "            config['number_of_sentence'], \n",
    "            config['number_of_sentence_before'], \n",
    "            config['number_of_sentence_after'], \n",
    "            'bert-base-uncased', \n",
    "            )\n",
    "\n",
    "## Shuffling\n",
    "#batches_shuffle, indexes_shuffle = bert_utils.batchify_sentences(\n",
    "#            iterator_list[0], \n",
    "#            config['number_of_sentence'], \n",
    "#            config['number_of_sentence_before'], \n",
    "#            config['number_of_sentence_after'], \n",
    "#            pretrained_model='bert-base-uncased', \n",
    "#            past_context_size=config['attention_length_before'],\n",
    "#            future_context_size=config['attention_length_after'],\n",
    "#            transformation='shuffle',\n",
    "#            vocabulary=None,\n",
    "#            dictionary=None,\n",
    "#            seed=1111,\n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert_utils\n",
    "\n",
    "batch = batches_masked[0]\n",
    "batch\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer']\n",
      "(S (ADVP (RB once)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (PRP i)) (VP (VBD was) (ADJP (NP (CD six) (NNS years)) (JJ old))))) (, ,) (NP (PRP i)) (VP (VBD saw) (NP (NP (DT a) (JJ magnificent) (NN picture)) (PP (IN in) (NP (NP (NP (DT a) (NN book)) (PP (IN about) (NP (DT the) (JJ primeval) (NN forest)))) (VP (VBN called) (S (`` ‘) (NP (JJ real) (: -) (NN life) (NNS stories)))))))) (. .) ('' ’))\n"
     ]
    }
   ],
   "source": [
    "syntax = __import__('04_syntax_generator')\n",
    "nlp = syntax.set_nlp_pipeline()\n",
    "nlp = syntax.add_constituent_parser(nlp)\n",
    "doc = nlp(batch)\n",
    "sent = list(doc.sents)[0]\n",
    "print(sent._.parse_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i wanted to know if they were really a person of true understanding . but they always responded : “ it ' s a hat . ” so i would never speak to them of boa constrictors , nor of primeval forests , nor of the stars . i put myself at their level .\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = batches_masked[30]\n",
    "tokenized_text = tokenizer.wordpiece_tokenizer.tokenize(batch)\n",
    "inputs_ids = torch.tensor([tokenizer.convert_tokens_to_ids(tokenized_text)])\n",
    "inputs_ids = torch.cat(inputs_ids.size(1) * [inputs_ids])\n",
    "mapping = bert_utils.match_tokenized_to_untokenized(tokenized_text, batch)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer']\n",
      "torch.Size([46, 46])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-fdb603857492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mconstituent_parsing_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_constituent_parsing_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_punctuation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstituent_parsing_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstituent_parsing_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/Parietal/NLP_models/BERT/bert_utils.py\u001b[0m in \u001b[0;36mget_constituent_parsing_list\u001b[0;34m(text, level, skip_punctuation, incremental)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mconstituent_parsing_list\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mof\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \"\"\"\n\u001b[0;32m--> 478\u001b[0;31m     \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyntax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_nlp_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m     \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyntax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constituent_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0mconstituent_parsing_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyntax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstituent_parsing_at_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_punctuation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_punctuation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mincremental\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/src/lib/04_syntax_generator.py\u001b[0m in \u001b[0;36mset_nlp_pipeline\u001b[0;34m(name, to_remove, max_length)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \"\"\"Load and prepare Spacy NLP pipeline.\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_remove\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/parietal/lib/python3.7/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \"\"\"\n\u001b[1;32m     50\u001b[0m     return util.load_model(\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     )\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/parietal/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_lang_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"blank:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# installed as package\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# path to model data directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/parietal/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_package\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \"\"\"\n\u001b[1;32m    356\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/parietal/lib/python3.7/site-packages/en_core_web_lg/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_init_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/envs/parietal/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     )\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/parietal/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/parietal/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(self, path, exclude)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0;31m# Convert to list here in case exclude is (default) tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m             \u001b[0mexclude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"vocab\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeserializers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_link_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/parietal/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(path, readers, exclude)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;31m# Split to support file names like meta.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/parietal/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mdeserialize_vocab\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdeserialize_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/parietal/lib/python3.7/site-packages/spacy/vocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.from_disk\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/parietal/lib/python3.7/site-packages/spacy/vectors.pyx\u001b[0m in \u001b[0;36mspacy.vectors.Vectors.from_disk\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/parietal/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(path, readers, exclude)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;31m# Split to support file names like meta.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/parietal/lib/python3.7/site-packages/spacy/vectors.pyx\u001b[0m in \u001b[0;36mspacy.vectors.Vectors.from_disk.load_vectors\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/parietal/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 440\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/parietal/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for i in [0, 1, 2, 3, 4, 5]:\n",
    "    constituent_parsing_list = bert_utils.get_constituent_parsing_list(batch, level=i, skip_punctuation=True, incremental=False)\n",
    "    attention_mask = create_attention_mask(tokenized_text, mapping, constituent_parsing_list, constituent_parsing_level=i)\n",
    "    print(torch.tensor(attention_mask).size())\n",
    "\n",
    "    \n",
    "    plt.imshow(attention_mask)\n",
    "    plt.title(f'level :{i}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attention_mask(tokenized_text, mapping, index_list, constituent_parsing_level=1):\n",
    "    \"\"\"Create the attention mask associated with the input tokenized text for a given level \n",
    "    in the constituent parsing tree.\n",
    "    Args:\n",
    "        - tokenized_text: list of int\n",
    "        - mapping: dict (resulting from match_tokenized_to_untokenized)\n",
    "        - index_list: list (of list of int) e.g.: [[0, 1], [2], [2, 3]]\n",
    "        - constituent_parsing_level: int (number of levels to consider in the constituent parsing tree)\n",
    "    Returns:\n",
    "        - attention_mask: nd.array (dim 2)\n",
    "    \"\"\"\n",
    "    n = len(tokenized_text)\n",
    "    attention_mask = np.zeros((n, n))\n",
    "    for j, key in enumerate(mapping.keys()):\n",
    "        for i, v in enumerate(index_list):\n",
    "            if j in v:\n",
    "                for token_i in mapping[i]:\n",
    "                    for token_j in mapping[j]:\n",
    "                        attention_mask[token_i, token_j] = 1\n",
    "    return attention_mask\n",
    "\n",
    "def get_constituent_parsing_list(text, level=1, skip_punctuation=True, incremental=False):\n",
    "    \"\"\"Retrieve the list of words index to which each word in the input text should pay attention too\n",
    "    based on the constituent parsing tree and the defined level.\n",
    "    Args:\n",
    "        - text: str\n",
    "        - level: int, level in the parsing tree\n",
    "        - skip_punctuation: bool, do not touch punctuation\n",
    "        - incremental: bool, masking relations with future words\n",
    "    Returns:\n",
    "        - constituent_parsing_list: list (of list of int)\n",
    "    \"\"\"\n",
    "    nlp = syntax.set_nlp_pipeline()\n",
    "    nlp = syntax.add_constituent_parser(nlp)\n",
    "    constituent_parsing_list = syntax.constituent_parsing_at_level(text, nlp, level=level, skip_punctuation=skip_punctuation, incremental=incremental)\n",
    "    return constituent_parsing_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing full\n",
    "indexes_full_tmp = []\n",
    "for i in range(len(indexes_full)):\n",
    "    if type(indexes_full[i])==list and type(indexes_full[i][0])==list:\n",
    "        indexes_full_tmp.append(indexes_full[i][-1])\n",
    "    else:\n",
    "        if i > 0:\n",
    "            indexes_full_tmp.append((\n",
    "            indexes_full[i][-config['number_of_sentence']-config['number_of_sentence_after']][0], \n",
    "            indexes_full[i][-config['number_of_sentence']-config['number_of_sentence_after']][1]))\n",
    "        else:\n",
    "            indexes_full_tmp.append(None)\n",
    "\n",
    "\n",
    "            \n",
    "# Preprocessing masked\n",
    "indexes_masked_tmp = []\n",
    "# If beginning and end indexes of each sentences are recorded, we only keep the sentence(s) of interest\n",
    "for i in range(len(indexes_masked)):\n",
    "    if type(indexes_masked[i])==list and type(indexes_masked[i][0])==list:\n",
    "        indexes_masked_tmp.append(indexes_masked[i][-1])\n",
    "    else:\n",
    "        if i > 0:\n",
    "            indexes_masked_tmp.append((\n",
    "            indexes_masked[i][-config['number_of_sentence']-config['number_of_sentence_after']][0], \n",
    "            indexes_masked[i][-config['number_of_sentence']-config['number_of_sentence_after']][1]))\n",
    "        else:\n",
    "            indexes_masked_tmp.append(None)\n",
    "\n",
    "#if config['number_of_sentence_before']==0:\n",
    "#    indexes_masked_tmp[0] = (indexes_masked[0][0][0][0], indexes_masked[0][-1][1])\n",
    "#else:\n",
    "#    indexes_masked_tmp[0] = (indexes_masked[0][0][0], indexes_masked[0][-1][1])\n",
    "\n",
    "\n",
    "# Preprocessing shuffle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]]) torch.Size([1, 75])\n",
      "once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’\n",
      "t\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-8ff2788b5a42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# activation generation full\n",
    "output = []\n",
    "for index, batch in enumerate(batches_full):\n",
    "    batch = batch.strip() # Remove trailing character\n",
    "\n",
    "    batch = '[CLS] ' + batch + ' [SEP]'\n",
    "    tokenized_text = tokenizer.wordpiece_tokenizer.tokenize(batch)\n",
    "    inputs_ids = torch.tensor([tokenizer.convert_tokens_to_ids(tokenized_text)])\n",
    "    mapping = bert_utils.match_tokenized_to_untokenized(tokenized_text, batch)\n",
    "    #print(mapping)\n",
    "\n",
    "    attention_mask = torch.tensor([[1 for x in tokenized_text]])\n",
    "    print(attention_mask, attention_mask.shape)\n",
    "    \n",
    "    #print('input shape: ', inputs_ids.shape)\n",
    "    #print(batch)\n",
    "    #print(tokenized_text)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoded_layers = extractor_full.model(inputs_ids, attention_mask=attention_mask) # last_hidden_state, pooler_output, hidden_states, attentions\n",
    "\n",
    "        hidden_states_activations_ = np.vstack(encoded_layers[2]) # retrieve all the hidden states (dimension = layer_count * len(tokenized_text) * feature_count)\n",
    "\n",
    "        #print(len(encoded_layers[2]))\n",
    "        #print('output shape:', hidden_states_activations_.shape)\n",
    "        \n",
    "        new_activations = []\n",
    "        key_start = None\n",
    "        key_stop = None\n",
    "        \n",
    "        #print('Mapping:')\n",
    "        #for key in mapping.keys():\n",
    "        #    print(batch.split()[key], ''.join([tokenized_text[i] for i in mapping[key]]))\n",
    "        #print('A priori Token of interest:', tokenized_text[indexes_full_tmp[index][0]:indexes_full_tmp[index][1]])\n",
    "            \n",
    "        for key_, value in mapping.items(): \n",
    "            if (value[0] - 1) == (indexes_full_tmp[index][0]): #because we added [CLS] token at the beginning\n",
    "                key_start = key_\n",
    "        for key_, value in mapping.items(): \n",
    "            if value[-1] == (indexes_full_tmp[index][1]): #because we added [CLS] token at the beginning\n",
    "                key_stop = key_\n",
    "                \n",
    "        #print(key_start, key_stop)\n",
    "        #print('Extracting sentence:')\n",
    "        print(' '.join([tokenizer.decode(tokenizer.convert_tokens_to_ids([tokenized_text[word] for word in mapping[index]])) for index in range(key_start, key_stop + 1)]))\n",
    "        #print('dimension match:', len(tokenized_text)==hidden_states_activations_.shape[1])\n",
    "        output.append(' '.join([tokenizer.decode(tokenizer.convert_tokens_to_ids([tokenized_text[word] for word in mapping[index]])) for index in range(key_start, key_stop + 1)]))\n",
    "        \n",
    "        for word_index in range(key_start, key_stop + 1): # len(mapping.keys()) - 1\n",
    "            word_activation = []\n",
    "            word_activation.append([hidden_states_activations_[:,index, :] for index in mapping[word_index]])\n",
    "            word_activation = np.vstack(word_activation)\n",
    "            new_activations.append(np.mean(word_activation, axis=0).reshape(1,-1))\n",
    "        \n",
    "        #print(np.vstack(new_activations).shape)\n",
    "    if input()!='':\n",
    "        break\n",
    "\n",
    "\n",
    "assert ' '.join(output) == ' '.join(iterator_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def Euclidean_Dist(df1, df2):\n",
    "    return np.linalg.norm(df1 - df2)\n",
    "\n",
    "def compute_distance(d1, d2, method='correlation', filter_data=False):\n",
    "    #from sklearn.decomposition import PCA\n",
    "    #d1_ = PCA(300).fit_transform(d1.values)\n",
    "    #d2_ = PCA(300).fit_transform(d2.values)\n",
    "    #d1 = pd.DataFrame(data=d1_, columns=['component-{}'.format(i) for i in range(300)])\n",
    "    #d2 = pd.DataFrame(data=d2_, columns=['component-{}'.format(i) for i in range(300)])\n",
    "    if filter_data:\n",
    "        # Keep only hidden states\n",
    "        d1 = d1[d1.columns[:768*13]]\n",
    "        d2 = d2[d2.columns[:768*13]]\n",
    "    if method=='correlation':\n",
    "        result = d1.corrwith(d2, axis=1, method='pearson')\n",
    "    elif method=='euclidean':\n",
    "        result = d1.corrwith(d2, axis=1, method=Euclidean_Dist)\n",
    "    elif method=='cosine':\n",
    "        result = d1.corrwith(d2, axis=1, method=distance.cosine)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ it showed a boa constrictor swallowing a wild animal . here is a copy of the drawing . it said in the book : “ boa constrictors swallow their prey whole , without chewing . [SEP]\n",
      "torch.Size([1, 75])\n",
      "torch.Size([75, 75])\n",
      "input shape:  torch.Size([30, 75])\n",
      "attention_mask shape:  torch.Size([30, 75])\n",
      "[CLS] once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ it showed a boa constrictor swallowing a wild animal . here is a copy of the drawing . it said in the book : “ boa constrictors swallow their prey whole , without chewing . [SEP]\n",
      "output shape at each layer: torch.Size([30, 75, 768])\n",
      "output shape after concat: (13, 30, 768)\n",
      "(13, 75, 768)\n",
      "13\n",
      "output shape after filling: (13, 75, 768)\n",
      "0\n",
      "0\n",
      "0.9321492070672021\n",
      "a\n",
      "\n",
      "[CLS] once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ it showed a boa constrictor swallowing a wild animal . here is a copy of the drawing . it said in the book : “ boa constrictors swallow their prey whole , without chewing . [SEP]\n",
      "torch.Size([1, 75])\n",
      "torch.Size([75, 75])\n",
      "input shape:  torch.Size([30, 75])\n",
      "attention_mask shape:  torch.Size([30, 75])\n",
      "[CLS] once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ it showed a boa constrictor swallowing a wild animal . here is a copy of the drawing . it said in the book : “ boa constrictors swallow their prey whole , without chewing . [SEP]\n",
      "output shape at each layer: torch.Size([30, 75, 768])\n",
      "output shape after concat: (13, 30, 768)\n",
      "(13, 75, 768)\n",
      "13\n",
      "output shape after filling: (13, 75, 768)\n",
      "0\n",
      "0\n",
      "0.9489089751362715\n",
      "a\n",
      "\n",
      "[CLS] once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ it showed a boa constrictor swallowing a wild animal . here is a copy of the drawing . it said in the book : “ boa constrictors swallow their prey whole , without chewing . [SEP]\n",
      "torch.Size([1, 75])\n",
      "torch.Size([75, 75])\n",
      "input shape:  torch.Size([30, 75])\n",
      "attention_mask shape:  torch.Size([30, 75])\n",
      "[CLS] once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ it showed a boa constrictor swallowing a wild animal . here is a copy of the drawing . it said in the book : “ boa constrictors swallow their prey whole , without chewing . [SEP]\n",
      "output shape at each layer: torch.Size([30, 75, 768])\n",
      "output shape after concat: (13, 30, 768)\n",
      "(13, 75, 768)\n",
      "13\n",
      "output shape after filling: (13, 75, 768)\n",
      "0\n",
      "0\n",
      "1.0\n",
      "a\n",
      "\n",
      "[CLS] once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ it showed a boa constrictor swallowing a wild animal . here is a copy of the drawing . it said in the book : “ boa constrictors swallow their prey whole , without chewing . [SEP]\n",
      "torch.Size([1, 75])\n",
      "torch.Size([75, 75])\n",
      "input shape:  torch.Size([30, 75])\n",
      "attention_mask shape:  torch.Size([30, 75])\n",
      "[CLS] once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’ it showed a boa constrictor swallowing a wild animal . here is a copy of the drawing . it said in the book : “ boa constrictors swallow their prey whole , without chewing . [SEP]\n",
      "output shape at each layer: torch.Size([30, 75, 768])\n",
      "output shape after concat: (13, 30, 768)\n",
      "(13, 75, 768)\n",
      "13\n",
      "output shape after filling: (13, 75, 768)\n",
      "0\n",
      "0\n",
      "1.0\n",
      "a\n",
      "a\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-5bce1f8e3a06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# activation generation masked\n",
    "output = []\n",
    "for variable in [5, 10, 100, 1000]:\n",
    "    for index_batch, batch in enumerate(batches_masked):\n",
    "        batch = batch.strip() # Remove trailing character\n",
    "\n",
    "        batch = '[CLS] ' + batch + ' [SEP]'\n",
    "        tokenized_text = tokenizer.wordpiece_tokenizer.tokenize(batch)\n",
    "        inputs_ids = torch.tensor([tokenizer.convert_tokens_to_ids(tokenized_text)])\n",
    "\n",
    "        inputs_ids_ref = torch.tensor([tokenizer.convert_tokens_to_ids(tokenized_text)])\n",
    "        attention_mask_ref = torch.tensor([[1 for x in tokenized_text]])\n",
    "        print(batch)\n",
    "        print(inputs_ids.shape)\n",
    "\n",
    "        inputs_ids = torch.cat(inputs_ids.size(1) * [inputs_ids])\n",
    "        print(inputs_ids.shape)\n",
    "\n",
    "        attention_mask =  torch.diag_embed(torch.tensor([[0 for x in tokenized_text]]))\n",
    "\n",
    "        for i in range(min(len(tokenized_text), config['attention_length_before'])): \n",
    "            attention_mask = torch.add(attention_mask, torch.diag_embed(torch.tensor([[1 for x in range(len(tokenized_text) - i)]]), offset=-i))\n",
    "        for i in range(1, min(len(tokenized_text), variable + 1)): #config['attention_length_after']\n",
    "            attention_mask = torch.add(attention_mask, torch.diag_embed(torch.tensor([[1 for x in range(len(tokenized_text) - i)]]), offset=i))\n",
    "        mapping = bert_utils.match_tokenized_to_untokenized(tokenized_text, batch)\n",
    "\n",
    "        attention_mask = attention_mask.squeeze(0)\n",
    "\n",
    "        beg = indexes_masked_tmp[index_batch][0] + 1 # because of the special token at the beginning\n",
    "        end = indexes_masked_tmp[index_batch][1] + 1 # because of special token\n",
    "\n",
    "        inputs_ids = inputs_ids[beg:end, :]\n",
    "        attention_mask = attention_mask[beg:end, :]\n",
    "\n",
    "\n",
    "        print('input shape: ', inputs_ids.shape)\n",
    "        print('attention_mask shape: ', attention_mask.shape)\n",
    "        print(batch)\n",
    "        #print(tokenized_text)\n",
    "        #print(attention_mask)\n",
    "        #print('Mapping:')\n",
    "        #for key in mapping.keys():\n",
    "        #    print(batch.split()[key], ''.join([tokenized_text[i] for i in mapping[key]]))\n",
    "        #print('A priori Token of interest:', tokenized_text[beg:end])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoded_layers = extractor_masked.model(inputs_ids, attention_mask=attention_mask) # last_hidden_state, pooler_output, hidden_states, attentions\n",
    "            encoded_layers_ref = extractor_masked.model(inputs_ids_ref, attention_mask=attention_mask_ref) # last_hidden_state, pooler_output, hidden_states, attentions\n",
    "\n",
    "            print('output shape at each layer:', encoded_layers[2][0].shape)\n",
    "            hidden_states_activations_ = np.vstack([torch.cat([encoded_layers[2][layer][i, beg + i, :].unsqueeze(0) for i in range(encoded_layers[2][layer].size(0))], dim=0).unsqueeze(0).detach().numpy() for layer in range(len(encoded_layers[2]))]) # retrieve all the hidden states (dimension = layer_count * len(tokenized_text) * feature_count)\n",
    "            print('output shape after concat:', hidden_states_activations_.shape)\n",
    "            hidden_states_activations_ = np.concatenate([np.zeros((hidden_states_activations_.shape[0], beg , hidden_states_activations_.shape[-1])), hidden_states_activations_, np.zeros((hidden_states_activations_.shape[0], len(tokenized_text) - end, hidden_states_activations_.shape[-1]))], axis=1)\n",
    "\n",
    "            hidden_states_activations_ref = np.vstack(encoded_layers_ref[2]) # retrieve all the hidden states (dimension = layer_count * len(tokenized_text) * feature_count)\n",
    "\n",
    "            print(hidden_states_activations_ref.shape)\n",
    "            print(len(encoded_layers[2]))\n",
    "            print('output shape after filling:', hidden_states_activations_.shape)\n",
    "\n",
    "            method = 'correlation'\n",
    "            print(np.sum(np.isnan(hidden_states_activations_)))\n",
    "            print(np.sum(np.isnan(hidden_states_activations_ref)))\n",
    "            print(np.mean([compute_distance(\n",
    "                pd.DataFrame(hidden_states_activations_[i, beg:end, :]), \n",
    "                pd.DataFrame(hidden_states_activations_ref[i, beg:end, :]), \n",
    "                method=method) for i in range(13)]))\n",
    "\n",
    "        #    \n",
    "        #    new_activations = []\n",
    "        #    key_start = None\n",
    "        #    key_stop = None\n",
    "        #    \n",
    "        #    assert indexes_masked_tmp[index_batch][0]==indexes_full_tmp[index_batch][0]\n",
    "        #    assert indexes_masked_tmp[index_batch][1]==indexes_full_tmp[index_batch][1]\n",
    "        #    \n",
    "        #    for key_, value in mapping.items(): \n",
    "        #        if (value[0] - 1) == (indexes_masked_tmp[index_batch][0]): #because we added [CLS] token at the beginning\n",
    "        #            key_start = key_\n",
    "        #    for key_, value in mapping.items(): \n",
    "        #        if value[-1] == (indexes_masked_tmp[index_batch][1]): #because we added [CLS] token at the beginning\n",
    "        #            key_stop = key_\n",
    "        #            \n",
    "        #    #print(key_start, key_stop)\n",
    "        #    #print('Extracting sentence:')\n",
    "        #    print(' '.join([tokenizer.decode(tokenizer.convert_tokens_to_ids([tokenized_text[word] for word in mapping[index]])) for index in range(key_start, key_stop + 1)]))\n",
    "        #    #print('dimension match:', len(tokenized_text)==hidden_states_activations_.shape[1])\n",
    "        #    output.append(' '.join([tokenizer.decode(tokenizer.convert_tokens_to_ids([tokenized_text[word] for word in mapping[index]])) for index in range(key_start, key_stop + 1)]))\n",
    "        #    \n",
    "        #    for word_index in range(key_start, key_stop + 1): # len(mapping.keys()) - 1\n",
    "        #        word_activation = []\n",
    "        #        word_activation.append([hidden_states_activations_[:,index, :] for index in mapping[word_index]])\n",
    "        #        word_activation = np.vstack(word_activation)\n",
    "        #        new_activations.append(np.mean(word_activation, axis=0).reshape(1,-1))\n",
    "        #    \n",
    "        #    #print(np.vstack(new_activations).shape)\n",
    "        if input()!='':\n",
    "            break\n",
    "    if input()!='':\n",
    "        break\n",
    "\n",
    "assert ' '.join(output) == ' '.join(iterator_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "once\n",
      ",\n",
      "when\n",
      "i\n",
      "was\n",
      "six\n",
      "years\n",
      "old\n",
      ",\n",
      "i\n",
      "saw\n",
      "a\n",
      "magnificent\n",
      "picture\n",
      "in\n",
      "a\n",
      "book\n",
      "about\n",
      "the\n",
      "primeval\n",
      "forest\n",
      "called\n",
      "‘\n",
      "real\n",
      "-\n",
      "life\n",
      "stories\n",
      ".\n",
      "’\n",
      "it\n",
      "showed\n",
      "a\n",
      "boa\n",
      "constrictor\n",
      "swallowing\n",
      "a\n",
      "wild\n",
      "animal\n",
      ".\n",
      "here\n",
      "is\n",
      "a\n",
      "copy\n",
      "of\n",
      "the\n",
      "drawing\n",
      ".\n",
      "it\n",
      "said\n",
      "in\n",
      "the\n",
      "book\n",
      ":\n",
      "“\n",
      "boa\n",
      "constrictors\n",
      "swallow\n",
      "their\n",
      "prey\n",
      "whole\n",
      ",\n",
      "without\n",
      "chewing\n",
      ".\n",
      "then\n",
      "they\n",
      "are\n",
      "not\n",
      "able\n",
      "to\n",
      "move\n",
      ",\n",
      "and\n",
      "they\n",
      "sleep\n",
      "for\n",
      "the\n",
      "six\n",
      "months\n",
      "it\n",
      "takes\n",
      "for\n",
      "digestion\n",
      ".\n",
      "”\n",
      "so\n",
      "i\n",
      "thought\n",
      "a\n",
      "lot\n",
      "about\n",
      "the\n",
      "adventures\n",
      "of\n",
      "the\n",
      "jungle\n",
      "and\n",
      ",\n",
      "in\n",
      "turn\n",
      ",\n",
      "i\n",
      "managed\n",
      ",\n",
      "with\n",
      "a\n",
      "coloured\n",
      "pencil\n",
      ",\n",
      "to\n",
      "make\n",
      "my\n",
      "first\n",
      "drawing\n",
      ".\n",
      "my\n",
      "drawing\n",
      "number\n",
      "one\n",
      ".\n",
      "it\n",
      "looked\n",
      "like\n",
      "this\n",
      ":\n",
      "i\n",
      "showed\n",
      "my\n",
      "masterpiece\n",
      "to\n",
      "the\n",
      "grownups\n",
      "and\n",
      "i\n",
      "asked\n",
      "them\n",
      "if\n",
      "my\n",
      "drawing\n",
      "frightened\n",
      "them\n",
      ".\n",
      "they\n",
      "answered\n",
      "me\n",
      ":\n",
      "“\n",
      "why\n",
      "would\n",
      "anyone\n",
      "be\n",
      "frightened\n",
      "by\n",
      "a\n",
      "hat\n",
      "?\n",
      "”\n",
      "my\n",
      "drawing\n",
      "was\n",
      "not\n",
      "of\n",
      "a\n",
      "hat\n",
      ".\n",
      "it\n",
      "showed\n",
      "a\n",
      "boa\n",
      "constrictor\n",
      "digesting\n",
      "an\n",
      "elephant\n",
      ".\n",
      "i\n",
      "then\n",
      "drew\n",
      "the\n",
      "inside\n",
      "of\n",
      "the\n",
      "boa\n",
      "constrictor\n",
      ",\n",
      "so\n",
      "that\n",
      "the\n",
      "grownups\n",
      "could\n",
      "understand\n",
      ".\n",
      "they\n",
      "always\n",
      "need\n",
      "to\n",
      "have\n",
      "things\n",
      "explained\n",
      ".\n",
      "my\n",
      "drawing\n",
      "number\n",
      "two\n",
      "looked\n",
      "like\n",
      "this\n",
      ":\n",
      "the\n",
      "grownups\n",
      "advised\n",
      "me\n",
      "to\n",
      "leave\n",
      "aside\n",
      "drawings\n",
      "of\n",
      "boa\n",
      "constrictors\n",
      ",\n",
      "open\n",
      "or\n",
      "closed\n",
      ",\n",
      "and\n",
      "to\n",
      "apply\n",
      "myself\n",
      "instead\n",
      "to\n",
      "geography\n",
      ",\n",
      "history\n",
      ",\n",
      "arithmetic\n",
      "and\n",
      "grammar\n",
      ".\n",
      "thus\n",
      "i\n",
      "abandoned\n",
      ",\n",
      "at\n",
      "the\n",
      "age\n",
      "of\n",
      "six\n",
      ",\n",
      "a\n",
      "magnificent\n",
      "career\n",
      "as\n",
      "a\n",
      "painter\n",
      ".\n",
      "i\n",
      "was\n",
      "discouraged\n",
      "by\n",
      "the\n",
      "failure\n",
      "of\n",
      "my\n",
      "drawing\n",
      "number\n",
      "one\n",
      "and\n",
      "of\n",
      "my\n",
      "drawing\n",
      "number\n",
      "two\n",
      ".\n",
      "grownups\n",
      "never\n",
      "understand\n",
      "anything\n",
      "by\n",
      "themselves\n",
      ",\n",
      "and\n",
      "it\n",
      "’\n",
      "s\n",
      "tiresome\n",
      "for\n",
      "children\n",
      "to\n",
      "always\n",
      "explain\n",
      "things\n",
      "for\n",
      "them\n",
      "again\n",
      "and\n",
      "again\n",
      ".\n",
      "so\n",
      "i\n",
      "had\n",
      "to\n",
      "choose\n",
      "another\n",
      "profession\n",
      ",\n",
      "and\n",
      "i\n",
      "learned\n",
      "to\n",
      "fly\n",
      "airplanes\n",
      ".\n",
      "i\n",
      "flew\n",
      "a\n",
      "little\n",
      "in\n",
      "many\n",
      "places\n",
      "around\n",
      "the\n",
      "world\n",
      ".\n",
      "and\n",
      "geography\n",
      ",\n",
      "it\n",
      "'\n",
      "s\n",
      "true\n",
      ",\n",
      "has\n",
      "served\n",
      "me\n",
      "well\n",
      ".\n",
      "i\n",
      "could\n",
      "recognize\n",
      ",\n",
      "at\n",
      "first\n",
      "glance\n",
      ",\n",
      "china\n",
      "from\n",
      "arizona\n",
      ".\n",
      "it\n",
      "’\n",
      "s\n",
      "very\n",
      "useful\n",
      "if\n",
      "you\n",
      "get\n",
      "lost\n",
      "at\n",
      "night\n",
      ".\n",
      "i\n",
      "have\n",
      "had\n",
      ",\n",
      "during\n",
      "my\n",
      "life\n",
      ",\n",
      "a\n",
      "lot\n",
      "of\n",
      "contact\n",
      "with\n",
      "many\n",
      "persons\n",
      "of\n",
      "consequence\n",
      ".\n",
      "i\n",
      "have\n",
      "lived\n",
      "a\n",
      "lot\n",
      "amongst\n",
      "the\n",
      "grownups\n",
      ".\n",
      "i\n",
      "have\n",
      "seen\n",
      "them\n",
      "from\n",
      "close\n",
      "up\n",
      ".\n",
      "it\n",
      "hasnt\n",
      "much\n",
      "improved\n",
      "my\n",
      "opinion\n",
      "of\n",
      "them\n",
      ".\n",
      "whenever\n",
      "i\n",
      "met\n",
      "one\n",
      "of\n",
      "them\n",
      "that\n",
      "seemed\n",
      "a\n",
      "bit\n",
      "more\n",
      "clear\n",
      "-\n",
      "sighted\n",
      ",\n",
      "i\n",
      "tried\n",
      "the\n",
      "experiment\n",
      "of\n",
      "showing\n",
      "them\n",
      "my\n",
      "drawing\n",
      "number\n",
      "one\n",
      ",\n",
      "that\n",
      "i\n",
      "'\n",
      "ve\n",
      "always\n",
      "kept\n",
      ".\n",
      "i\n",
      "wanted\n",
      "to\n",
      "know\n",
      "if\n",
      "they\n",
      "were\n",
      "really\n",
      "a\n",
      "person\n",
      "of\n",
      "true\n",
      "understanding\n",
      ".\n",
      "but\n",
      "they\n",
      "always\n",
      "responded\n",
      ":\n",
      "“\n",
      "it\n",
      "'\n",
      "s\n",
      "a\n",
      "hat\n",
      ".\n",
      "”\n",
      "so\n",
      "i\n",
      "would\n",
      "never\n",
      "speak\n",
      "to\n",
      "them\n",
      "of\n",
      "boa\n",
      "constrictors\n",
      ",\n",
      "nor\n",
      "of\n",
      "primeval\n",
      "forests\n",
      ",\n",
      "nor\n",
      "of\n",
      "the\n",
      "stars\n",
      ".\n",
      "i\n",
      "put\n",
      "myself\n",
      "at\n",
      "their\n",
      "level\n",
      ".\n",
      "i\n",
      "talked\n",
      "to\n",
      "them\n",
      "about\n",
      "bridge\n",
      ",\n",
      "golf\n",
      ",\n",
      "politics\n",
      "and\n",
      "neckties\n",
      ".\n",
      "and\n",
      "the\n",
      "grownup\n",
      "was\n",
      "glad\n",
      "to\n",
      "know\n",
      "such\n",
      "a\n",
      "sensible\n",
      "man\n",
      ".\n",
      "so\n",
      "i\n",
      "lived\n",
      "alone\n",
      ",\n",
      "without\n",
      "anyone\n",
      "i\n",
      "could\n",
      "really\n",
      "talk\n",
      "to\n",
      ",\n",
      "until\n",
      "a\n",
      "breakdown\n",
      "in\n",
      "the\n",
      "sahara\n",
      "desert\n",
      ",\n",
      "six\n",
      "years\n",
      "ago\n",
      ".\n",
      "something\n",
      "had\n",
      "broken\n",
      "in\n",
      "my\n",
      "engine\n",
      ".\n",
      "and\n",
      "as\n",
      "i\n",
      "had\n",
      "with\n",
      "me\n",
      "neither\n",
      "a\n",
      "mechanic\n",
      "nor\n",
      "any\n",
      "passengers\n",
      ",\n",
      "i\n",
      "readied\n",
      "myself\n",
      "to\n",
      "try\n",
      "and\n",
      "carry\n",
      "out\n",
      ",\n",
      "all\n",
      "alone\n",
      ",\n",
      "the\n",
      "difficult\n",
      "repairs\n",
      ".\n",
      "for\n",
      "me\n",
      "it\n",
      "was\n",
      "a\n",
      "matter\n",
      "of\n",
      "life\n",
      "or\n",
      "death\n",
      ".\n",
      "i\n",
      "had\n",
      "hardly\n",
      "enough\n",
      "water\n",
      "to\n",
      "drink\n",
      "for\n",
      "a\n",
      "week\n",
      ".\n",
      "the\n",
      "first\n",
      "night\n",
      "i\n",
      "went\n",
      "to\n",
      "sleep\n",
      "on\n",
      "the\n",
      "sand\n",
      ",\n",
      "a\n",
      "thousand\n",
      "miles\n",
      "from\n",
      "any\n",
      "human\n",
      "habitation\n",
      ".\n",
      "i\n",
      "was\n",
      "more\n",
      "isolated\n",
      "than\n",
      "a\n",
      "shipwrecked\n",
      "sailor\n",
      "on\n",
      "a\n",
      "raft\n",
      "in\n",
      "the\n",
      "middle\n",
      "of\n",
      "the\n",
      "ocean\n",
      ".\n",
      "so\n",
      "you\n",
      "can\n",
      "imagine\n",
      "my\n",
      "surprise\n",
      "when\n",
      "at\n",
      "daybreak\n",
      ",\n",
      "a\n",
      "funny\n",
      "little\n",
      "voice\n",
      "woke\n",
      "me\n",
      "up\n",
      ".\n",
      "it\n",
      "said\n",
      ":\n",
      "“\n",
      "please\n",
      "...\n",
      "draw\n",
      "me\n",
      "a\n",
      "sheep\n",
      "!\n",
      "”\n",
      "“\n",
      "what\n",
      "?\n",
      "”\n",
      "“\n",
      "draw\n",
      "me\n",
      "a\n",
      "sheep\n",
      "!\n",
      "”\n",
      "i\n",
      "jumped\n",
      "to\n",
      "my\n",
      "feet\n",
      "as\n",
      "if\n",
      "i\n",
      "’\n",
      "d\n",
      "been\n",
      "struck\n",
      "by\n",
      "lightning\n",
      ".\n",
      "i\n",
      "rubbed\n",
      "my\n",
      "eyes\n",
      ".\n",
      "i\n",
      "took\n",
      "a\n",
      "good\n",
      "look\n",
      "around\n",
      "me\n",
      ".\n",
      "and\n",
      "i\n",
      "saw\n",
      "a\n",
      "quite\n",
      "extraordinary\n",
      "little\n",
      "man\n",
      ",\n",
      "who\n",
      "was\n",
      "examining\n",
      "me\n",
      "seriously\n",
      ".\n",
      "here\n",
      "is\n",
      "the\n",
      "best\n",
      "portrait\n",
      "that\n",
      ",\n",
      "later\n",
      ",\n",
      "i\n",
      "managed\n",
      "to\n",
      "do\n",
      "of\n",
      "him\n",
      ".\n",
      "but\n",
      "my\n",
      "drawing\n",
      ",\n",
      "of\n",
      "course\n",
      ",\n",
      "is\n",
      "much\n",
      "less\n",
      "charming\n",
      "than\n",
      "its\n",
      "model\n",
      ".\n",
      "it\n",
      "'\n",
      "s\n",
      "not\n",
      "my\n",
      "fault\n",
      ".\n",
      "i\n",
      "was\n",
      "discouraged\n",
      "in\n",
      "my\n",
      "career\n",
      "as\n",
      "a\n",
      "painter\n",
      "by\n",
      "the\n",
      "grownups\n",
      ",\n",
      "at\n",
      "the\n",
      "age\n",
      "of\n",
      "six\n",
      ",\n",
      "and\n",
      "i\n",
      "hadn\n",
      "'\n",
      "t\n",
      "learned\n",
      "to\n",
      "draw\n",
      "anything\n",
      "except\n",
      "boa\n",
      "constrictors\n",
      ",\n",
      "closed\n",
      "and\n",
      "open\n",
      ".\n",
      "i\n",
      "stared\n",
      "at\n",
      "this\n",
      "sudden\n",
      "apparition\n",
      "wide\n",
      "eyed\n",
      "with\n",
      "astonishment\n",
      ".\n",
      "remember\n",
      "that\n",
      "i\n",
      "was\n",
      "a\n",
      "thousand\n",
      "miles\n",
      "from\n",
      "any\n",
      "inhabited\n",
      "region\n",
      ".\n",
      "and\n",
      "yet\n",
      "this\n",
      "little\n",
      "fellow\n",
      "seemed\n",
      "neither\n",
      "lost\n",
      ",\n",
      "nor\n",
      "half\n",
      "-\n",
      "dead\n",
      "with\n",
      "fatigue\n",
      ",\n",
      "nor\n",
      "starved\n",
      "or\n",
      "dying\n",
      "of\n",
      "thirst\n",
      "or\n",
      "fear\n",
      ".\n",
      "he\n",
      "looked\n",
      "nothing\n",
      "like\n",
      "a\n",
      "child\n",
      "lost\n",
      "in\n",
      "the\n",
      "middle\n",
      "of\n",
      "the\n",
      "desert\n",
      ",\n",
      "a\n",
      "thousand\n",
      "miles\n",
      "from\n",
      "any\n",
      "inhabited\n",
      "region\n",
      ".\n",
      "when\n",
      "i\n",
      "finally\n",
      "managed\n",
      "to\n",
      "speak\n",
      ",\n",
      "i\n",
      "said\n",
      ":\n",
      "“\n",
      "but\n",
      "—\n",
      "what\n",
      "are\n",
      "you\n",
      "doing\n",
      "here\n",
      "?\n",
      "”\n",
      "and\n",
      "he\n",
      "repeated\n",
      ",\n",
      "very\n",
      "slowly\n",
      ",\n",
      "as\n",
      "if\n",
      "it\n",
      "was\n",
      "something\n",
      "very\n",
      "serious\n",
      ":\n",
      "“\n",
      "please\n",
      "...\n",
      "draw\n",
      "me\n",
      "a\n",
      "sheep\n",
      "...\n",
      "”\n",
      "when\n",
      "a\n",
      "mystery\n",
      "is\n",
      "too\n",
      "overpowering\n",
      ",\n",
      "one\n",
      "dare\n",
      "not\n",
      "disobey\n",
      ".\n",
      "absurd\n",
      "as\n",
      "it\n",
      "seemed\n",
      "to\n",
      "me\n",
      "a\n",
      "thousand\n",
      "miles\n",
      "from\n",
      "any\n",
      "human\n",
      "habitation\n",
      "and\n",
      "in\n",
      "danger\n",
      "of\n",
      "death\n",
      ",\n",
      "i\n",
      "took\n",
      "out\n",
      "of\n",
      "my\n",
      "pocket\n",
      "a\n",
      "sheet\n",
      "of\n",
      "paper\n",
      "and\n",
      "a\n",
      "pen\n",
      ".\n",
      "but\n",
      "then\n",
      "i\n",
      "remembered\n",
      "that\n",
      "i\n",
      "had\n",
      "mainly\n",
      "studied\n",
      "geography\n",
      ",\n",
      "history\n",
      ",\n",
      "arithmetic\n",
      "and\n",
      "grammar\n",
      ",\n",
      "and\n",
      "i\n",
      "told\n",
      "the\n",
      "little\n",
      "fellow\n",
      "(\n",
      "a\n",
      "little\n",
      "crossly\n",
      ")\n",
      "that\n",
      "i\n",
      "didn\n",
      "’\n",
      "t\n",
      "know\n",
      "how\n",
      "to\n",
      "draw\n",
      ".\n",
      "he\n",
      "replied\n",
      ":\n",
      "“\n",
      "it\n",
      "doesn\n",
      "'\n",
      "t\n",
      "matter\n",
      ".\n",
      "draw\n",
      "me\n",
      "a\n",
      "sheep\n",
      ".\n",
      "”\n",
      "as\n",
      "i\n",
      "’\n",
      "d\n",
      "never\n",
      "drawn\n",
      "a\n",
      "sheep\n",
      ",\n",
      "i\n",
      "redrew\n",
      "for\n",
      "him\n",
      "one\n",
      "of\n",
      "the\n",
      "only\n",
      "two\n",
      "drawings\n",
      "that\n",
      "i\n",
      "was\n",
      "capable\n",
      "of\n",
      ".\n",
      "the\n",
      "one\n",
      "of\n",
      "the\n",
      "closed\n",
      "boa\n",
      "constrictor\n",
      ".\n",
      "and\n",
      "i\n",
      "was\n",
      "astounded\n",
      "to\n",
      "hear\n",
      "the\n",
      "little\n",
      "fellow\n",
      "respond\n",
      ":\n",
      "“\n",
      "no\n",
      "!\n",
      "no\n",
      "!\n",
      "i\n",
      "don\n",
      "’\n",
      "t\n",
      "want\n",
      "an\n",
      "elephant\n",
      "inside\n",
      "a\n",
      "boa\n",
      "constrictor\n",
      ".\n",
      "a\n",
      "boa\n",
      "constrictor\n",
      "is\n",
      "very\n",
      "dangerous\n",
      ",\n",
      "and\n",
      "an\n",
      "elephant\n",
      "is\n",
      "very\n",
      "cumbersome\n",
      ".\n",
      "where\n",
      "i\n",
      "live\n",
      "everything\n",
      "is\n",
      "very\n",
      "small\n",
      ".\n",
      "i\n",
      "need\n",
      "a\n",
      "sheep\n",
      ".\n",
      "draw\n",
      "me\n",
      "a\n",
      "sheep\n",
      ".\n",
      "”\n",
      "so\n",
      "i\n",
      "drew\n",
      ".\n",
      "he\n",
      "looked\n",
      "carefully\n",
      ",\n",
      "then\n",
      "said\n",
      ":\n",
      "“\n",
      "no\n",
      "!\n",
      "this\n",
      "one\n",
      "’\n",
      "s\n",
      "already\n",
      "very\n",
      "sick\n",
      ".\n",
      "make\n",
      "another\n",
      "one\n",
      ".\n",
      "”\n",
      "i\n",
      "drew\n",
      "again\n",
      ":\n",
      "my\n",
      "friend\n",
      "smiled\n",
      "gently\n",
      "and\n",
      "indulgently\n",
      ":\n",
      "“\n",
      "you\n",
      "can\n",
      "see\n",
      "yourself\n",
      "...\n",
      "this\n",
      "isn\n",
      "’\n",
      "t\n",
      "a\n",
      "sheep\n",
      ",\n",
      "it\n",
      "'\n",
      "s\n",
      "a\n",
      "ram\n",
      ".\n",
      "it\n",
      "has\n",
      "horns\n",
      "...\n",
      "“\n",
      "so\n",
      "once\n",
      "again\n",
      "i\n",
      "redid\n",
      "my\n",
      "drawing\n",
      ":\n",
      "but\n",
      "it\n",
      "was\n",
      "rejected\n",
      ",\n",
      "like\n",
      "the\n",
      "previous\n",
      "ones\n",
      ":\n",
      "“\n",
      "this\n",
      "one\n",
      "’\n",
      "s\n",
      "too\n",
      "old\n",
      ".\n",
      "i\n",
      "want\n",
      "a\n",
      "sheep\n",
      "that\n",
      "will\n",
      "live\n",
      "a\n",
      "long\n",
      "time\n",
      ".\n",
      "”\n",
      "so\n",
      ",\n",
      "getting\n",
      "impatient\n",
      ",\n",
      "as\n",
      "i\n",
      "was\n",
      "eager\n",
      "to\n",
      "start\n",
      "dismantling\n",
      "my\n",
      "engine\n",
      ",\n",
      "i\n",
      "hastily\n",
      "sketched\n",
      "this\n",
      "drawing\n",
      ":\n",
      "and\n",
      "i\n",
      "snapped\n",
      ":\n",
      "“\n",
      "this\n",
      "here\n",
      "is\n",
      "the\n",
      "box\n",
      ".\n",
      "the\n",
      "sheep\n",
      "you\n",
      "want\n",
      "is\n",
      "inside\n",
      ".\n",
      "”\n",
      "but\n",
      "i\n",
      "was\n",
      "very\n",
      "surprised\n",
      "to\n",
      "see\n",
      "the\n",
      "face\n",
      "of\n",
      "my\n",
      "young\n",
      "judge\n",
      "light\n",
      "up\n",
      ":\n",
      "“\n",
      "it\n",
      "'\n",
      "s\n",
      "exactly\n",
      "the\n",
      "way\n",
      "i\n",
      "wanted\n",
      "!\n",
      "do\n",
      "you\n",
      "think\n",
      "this\n",
      "sheep\n",
      "needs\n",
      "a\n",
      "lot\n",
      "of\n",
      "grass\n",
      "?\n",
      "”\n",
      "“\n",
      "why\n",
      "?\n",
      "”\n",
      "“\n",
      "because\n",
      "where\n",
      "i\n",
      "'\n",
      "m\n",
      "from\n",
      "everything\n",
      "is\n",
      "very\n",
      "small\n",
      "...\n",
      "”\n",
      "“\n",
      "there\n",
      "will\n",
      "certainly\n",
      "be\n",
      "enough\n",
      ".\n",
      "i\n",
      "gave\n",
      "you\n",
      "a\n",
      "very\n",
      "small\n",
      "sheep\n",
      ".\n",
      "”\n",
      "he\n",
      "leaned\n",
      "his\n",
      "head\n",
      "towards\n",
      "the\n",
      "drawing\n",
      ":\n",
      "“\n",
      "not\n",
      "that\n",
      "small\n",
      "...\n",
      "look\n",
      "!\n",
      "he\n",
      "'\n",
      "s\n",
      "fallen\n",
      "asleep\n",
      "...\n",
      "”\n",
      "and\n",
      "that\n",
      "'\n",
      "s\n",
      "how\n",
      "i\n",
      "met\n",
      "the\n",
      "little\n",
      "prince\n",
      ".\n",
      "it\n",
      "took\n",
      "me\n",
      "a\n",
      "long\n",
      "time\n",
      "to\n",
      "find\n",
      "out\n",
      "where\n",
      "he\n",
      "came\n",
      "from\n",
      ".\n",
      "the\n",
      "little\n",
      "prince\n",
      ",\n",
      "who\n",
      "asked\n",
      "me\n",
      "many\n",
      "questions\n",
      ",\n",
      "never\n",
      "seemed\n",
      "to\n",
      "hear\n",
      "my\n",
      "own\n",
      ".\n",
      "it\n",
      "was\n",
      "the\n",
      "words\n",
      "spoken\n",
      "by\n",
      "chance\n",
      "that\n",
      ",\n",
      "little\n",
      "by\n",
      "little\n",
      ",\n",
      "revealed\n",
      "everything\n",
      "to\n",
      "me\n",
      ".\n",
      "so\n",
      ",\n",
      "when\n",
      "he\n",
      "saw\n",
      "my\n",
      "airplane\n",
      "for\n",
      "the\n",
      "first\n",
      "time\n",
      "(\n",
      "i\n",
      "won\n",
      "’\n",
      "t\n",
      "draw\n",
      "my\n",
      "airplane\n",
      ",\n",
      "it\n",
      "would\n",
      "be\n",
      "a\n",
      "drawing\n",
      "far\n",
      "too\n",
      "complicated\n",
      "for\n",
      "me\n",
      ")\n",
      ",\n",
      "he\n",
      "asked\n",
      "me\n",
      ":\n",
      "“\n",
      "what\n",
      "'\n",
      "s\n",
      "that\n",
      "thing\n",
      "there\n",
      "?\n",
      "”\n",
      "“\n",
      "it\n",
      "'\n",
      "s\n",
      "not\n",
      "a\n",
      "thing\n",
      ".\n",
      "it\n",
      "flies\n",
      ".\n",
      "it\n",
      "'\n",
      "s\n",
      "an\n",
      "airplane\n",
      ".\n",
      "it\n",
      "’\n",
      "s\n",
      "my\n",
      "airplane\n",
      ".\n",
      "”\n",
      "and\n",
      "i\n",
      "was\n",
      "proud\n",
      "to\n",
      "have\n",
      "him\n",
      "know\n",
      "that\n",
      "i\n",
      "could\n",
      "fly\n",
      ".\n",
      "then\n",
      "he\n",
      "cried\n",
      ":\n",
      "“\n",
      "what\n",
      "?\n",
      "you\n",
      "fell\n",
      "from\n",
      "the\n",
      "sky\n",
      "!\n",
      "”\n",
      "“\n",
      "yes\n",
      ",\n",
      "”\n",
      "i\n",
      "said\n",
      "modestly\n",
      ".\n",
      "“\n",
      "oh\n",
      "!\n",
      "that\n",
      "'\n",
      "s\n",
      "funny\n",
      "!\n",
      "...\n",
      "”\n",
      "and\n",
      "the\n",
      "little\n",
      "prince\n",
      "broke\n",
      "into\n",
      "a\n",
      "lovely\n",
      "peal\n",
      "of\n",
      "laughter\n",
      ",\n",
      "which\n",
      "irritated\n",
      "me\n",
      "very\n",
      "much\n",
      ".\n",
      "i\n",
      "prefer\n",
      "people\n",
      "to\n",
      "take\n",
      "my\n",
      "misfortunes\n",
      "seriously\n",
      ".\n",
      "then\n",
      "he\n",
      "added\n",
      ":\n",
      "“\n",
      "so\n",
      ",\n",
      "you\n",
      "also\n",
      "come\n",
      "from\n",
      "the\n",
      "sky\n",
      "!\n",
      "what\n",
      "planet\n",
      "are\n",
      "you\n",
      "from\n",
      "?\n",
      "”\n",
      "i\n",
      "caught\n",
      "a\n",
      "glimpse\n",
      "into\n",
      "the\n",
      "mystery\n",
      "of\n",
      "his\n",
      "presence\n",
      ",\n",
      "and\n",
      "i\n",
      "asked\n",
      "abruptly\n",
      ":\n",
      "“\n",
      "so\n",
      "you\n",
      "come\n",
      "from\n",
      "another\n",
      "planet\n",
      "then\n",
      "?\n",
      "”\n",
      "but\n",
      "he\n",
      "didn\n",
      "’\n",
      "t\n",
      "answer\n",
      ".\n",
      "he\n",
      "shook\n",
      "his\n",
      "head\n",
      "slowly\n",
      "whilst\n",
      "looking\n",
      "at\n",
      "my\n",
      "airplane\n",
      ":\n",
      "“\n",
      "it\n",
      "'\n",
      "s\n",
      "true\n",
      "that\n",
      "you\n",
      "can\n",
      "'\n",
      "t\n",
      "have\n",
      "come\n",
      "from\n",
      "far\n",
      "away\n",
      "in\n",
      "that\n",
      "thing\n",
      "...\n",
      "”\n",
      "and\n",
      "he\n",
      "drifted\n",
      "into\n",
      "a\n",
      "daydream\n",
      "which\n",
      "lasted\n",
      "a\n",
      "long\n",
      "while\n",
      ".\n",
      "then\n",
      ",\n",
      "taking\n",
      "my\n",
      "sheep\n",
      "out\n",
      "of\n",
      "his\n",
      "pocket\n",
      ",\n",
      "he\n",
      "sank\n",
      "himself\n",
      "into\n",
      "the\n",
      "contemplation\n",
      "of\n",
      "his\n",
      "treasure\n",
      ".\n",
      "you\n",
      "can\n",
      "imagine\n",
      "how\n",
      "my\n",
      "curiosity\n",
      "was\n",
      "aroused\n",
      "by\n",
      "this\n",
      "small\n",
      "disclosure\n",
      "about\n",
      "‘\n",
      "the\n",
      "other\n",
      "planets\n",
      ".\n",
      "’\n",
      "so\n",
      "i\n",
      "tried\n",
      "to\n",
      "find\n",
      "out\n",
      "more\n",
      ":\n",
      "“\n",
      "where\n",
      "are\n",
      "you\n",
      "from\n",
      "my\n",
      "little\n",
      "fellow\n",
      "?\n",
      "where\n",
      "’\n",
      "s\n",
      "this\n",
      "‘\n",
      "where\n",
      "i\n",
      "live\n",
      "’\n",
      "of\n",
      "yours\n",
      "?\n",
      "where\n",
      "do\n",
      "you\n",
      "take\n",
      "my\n",
      "sheep\n",
      "off\n",
      "to\n",
      "?\n",
      "”\n",
      "after\n",
      "a\n",
      "reflective\n",
      "silence\n",
      "he\n",
      "answered\n",
      ":\n",
      "“\n",
      "what\n",
      "'\n",
      "s\n",
      "good\n",
      "about\n",
      "the\n",
      "box\n",
      "you\n",
      "’\n",
      "ve\n",
      "given\n",
      "me\n",
      "is\n",
      "that\n",
      "at\n",
      "night\n",
      ",\n",
      "he\n",
      "can\n",
      "use\n",
      "it\n",
      "as\n",
      "a\n",
      "house\n",
      ".\n",
      "”\n",
      "“\n",
      "that\n",
      "’\n",
      "s\n",
      "right\n",
      ".\n",
      "and\n",
      "if\n",
      "you\n",
      "’\n",
      "re\n",
      "good\n",
      ",\n",
      "i\n",
      "'\n",
      "ll\n",
      "give\n",
      "you\n",
      "a\n",
      "rope\n",
      "to\n",
      "tie\n",
      "him\n",
      "up\n",
      "with\n",
      "during\n",
      "the\n",
      "day\n",
      ".\n",
      "and\n",
      "a\n",
      "stake\n",
      ".\n",
      "”\n",
      "the\n",
      "offer\n",
      "seemed\n",
      "to\n",
      "shock\n",
      "the\n",
      "little\n",
      "prince\n",
      ":\n",
      "“\n",
      "tie\n",
      "him\n",
      "up\n",
      "?\n",
      "what\n",
      "a\n",
      "funny\n",
      "idea\n",
      "!\n",
      "”\n",
      "“\n",
      "but\n",
      "if\n",
      "you\n",
      "don\n",
      "'\n",
      "t\n",
      "tie\n",
      "him\n",
      "up\n",
      ",\n",
      "he\n",
      "’\n",
      "ll\n",
      "wander\n",
      "off\n",
      ",\n",
      "and\n",
      "get\n",
      "lost\n",
      ".\n",
      "”\n",
      "my\n",
      "friend\n",
      "broke\n",
      "into\n",
      "another\n",
      "peal\n",
      "of\n",
      "laughter\n",
      ":\n",
      "“\n",
      "where\n",
      "do\n",
      "you\n",
      "think\n",
      "he\n",
      "’\n",
      "d\n",
      "go\n",
      "!\n",
      "”\n",
      "“\n",
      "anywhere\n",
      ".\n",
      "straight\n",
      "ahead\n",
      "...\n",
      "”\n",
      "then\n",
      "the\n",
      "little\n",
      "prince\n",
      "said\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gravely\n",
      ":\n",
      "“\n",
      "that\n",
      "doesn\n",
      "’\n",
      "t\n",
      "matter\n",
      ";\n",
      "where\n",
      "i\n",
      "live\n",
      ",\n",
      "everything\n",
      "is\n",
      "so\n",
      "small\n",
      "!\n",
      "”\n",
      "and\n",
      "perhaps\n",
      "with\n",
      "a\n",
      "hint\n",
      "of\n",
      "sadness\n",
      ",\n",
      "he\n",
      "added\n",
      ":\n",
      "“\n",
      "straight\n",
      "ahead\n",
      "you\n",
      "can\n",
      "'\n",
      "t\n",
      "go\n",
      "far\n",
      "...\n",
      "”\n"
     ]
    }
   ],
   "source": [
    "# activation generation shuffle\n",
    "output = []\n",
    "for index_batch, batch in enumerate(batches_shuffle):\n",
    "    batch = batch.strip() # Remove trailing character\n",
    "\n",
    "    batch = '[CLS] ' + batch + ' [SEP]'\n",
    "    tokenized_text = tokenizer.wordpiece_tokenizer.tokenize(batch)\n",
    "    inputs_ids = torch.tensor([tokenizer.convert_tokens_to_ids(tokenized_text)])\n",
    "\n",
    "    #print('input shape: ', inputs_ids.shape)\n",
    "    #print(batch)\n",
    "    #print(tokenized_text)\n",
    "    \n",
    "    mapping = utils.match_tokenized_to_untokenized(tokenized_text, batch)\n",
    "\n",
    "    #print('Mapping:')\n",
    "    #for key in mapping.keys():\n",
    "    #    print(batch.split()[key], ''.join([tokenized_text[i] for i in mapping[key]]))\n",
    "    #print('A priori Token of interest:', tokenized_text[indexes_shuffle[index_batch][0]:indexes_shuffle[index_batch][1]])\n",
    "         \n",
    "    with torch.no_grad():\n",
    "        encoded_layers = extractor_shuffle.model(inputs_ids) # last_hidden_state, pooler_output, hidden_states, attentions\n",
    "\n",
    "        hidden_states_activations_ = np.vstack(encoded_layers[2]) # retrieve all the hidden states (dimension = layer_count * len(tokenized_text) * feature_count)\n",
    "\n",
    "        #print('nb of layer:', len(encoded_layers[2]))\n",
    "        #print('output shape:', hidden_states_activations_.shape)\n",
    "        \n",
    "        new_activations = []\n",
    "        key_start = None\n",
    "        key_stop = None\n",
    "        \n",
    "        for key_, value in mapping.items(): \n",
    "            if (value[0] - 1) == (indexes_shuffle[index_batch][0]): #because we added [CLS] token at the beginning\n",
    "                key_start = key_\n",
    "        for key_, value in mapping.items(): \n",
    "            if value[-1] == (indexes_shuffle[index_batch][1]): #because we added [CLS] token at the beginning\n",
    "                key_stop = key_\n",
    "                \n",
    "        #print(key_start, key_stop)\n",
    "        #print('Extracting sentence:')\n",
    "        print(' '.join([tokenizer.decode(tokenizer.convert_tokens_to_ids([tokenized_text[word] for word in mapping[index]])) for index in range(key_start, key_stop + 1)]))\n",
    "        #print('dimension match:', len(tokenized_text)==hidden_states_activations_.shape[1])\n",
    "        output.append(' '.join([tokenizer.decode(tokenizer.convert_tokens_to_ids([tokenized_text[word] for word in mapping[index]])) for index in range(key_start, key_stop + 1)]))\n",
    "        \n",
    "        for word_index in range(key_start, key_stop + 1): # len(mapping.keys()) - 1\n",
    "            word_activation = []\n",
    "            word_activation.append([hidden_states_activations_[:,index, :] for index in mapping[word_index]])\n",
    "            word_activation = np.vstack(word_activation)\n",
    "            new_activations.append(np.mean(word_activation, axis=0).reshape(1,-1))\n",
    "        \n",
    "        #print(np.vstack(new_activations).shape)\n",
    "        #if input()!='':\n",
    "        #    break\n",
    "\n",
    "\n",
    "assert ' '.join(output) == ' '.join(iterator_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_sentence_and_context(\n",
    "    iterator, \n",
    "    past_context_size, \n",
    "    future_context_size, \n",
    "    pretrained_model,\n",
    "    transformation='shuffle',\n",
    "    vocabulary=None,\n",
    "    dictionary=None,\n",
    "    select=None,\n",
    "    seed=1111):\n",
    "    \"\"\" DEF...\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    punctuation = ['.', '!', '?', '...', '\\'', ',', ';', ':', '/', '-', '\"', '‘', '’', '(', ')', '{', '}', '[', ']', '`', '“', '”', '—']\n",
    "    if select is None:\n",
    "        words = ' '.join(iterator).split()\n",
    "    else:\n",
    "        words = iterator[select].split()\n",
    "        \n",
    "    all_words = ' '.join(iterator).split()\n",
    "    words_before = [] if select is None else ' '.join(iterator[:select]).split()\n",
    "    supp_before = [len([word for word in all_words[max(j+len(words_before)+1-past_context_size, 0):j+len(words_before)+1] if word in punctuation]) for j in range(len(words))] # we do not count punctuation in the number of words to shuffle\n",
    "    supp_after = [len([word for word in all_words[j+len(words_before)+1:min(j+len(words_before)+1+future_context_size, len(all_words))] if word in punctuation]) for j in range(len(words))] # we do not count punctuation in the number of words to shuffle\n",
    "\n",
    "    # For each word, we compute the index of the other words to transform\n",
    "    # We transform past context. Change conditions \"i<j\" and ... to something else if needed\n",
    "    index_words_list_before = [[i for i, item in enumerate(all_words) if item not in punctuation if ((i!=(j+len(words_before))) and  (i <= j+len(words_before)-past_context_size-supp_before[j]))] for j in range(len(words))] # '<=' because context_size of 1 is the current word\n",
    "    index_words_list_after = [[i for i, item in enumerate(all_words) if item not in punctuation if ((i!=(j+len(words_before))) and (i>j+len(words_before)+future_context_size+supp_after[j]))] for j in range(len(words))] # '<=' because context_size of 1 is the current word\n",
    "\n",
    "    # Create the new array of sentences with original words \n",
    "    new_words = np.tile(np.array(all_words.copy()), (len(words), 1))\n",
    "\n",
    "    for i in range(len(new_words)):\n",
    "        if len(index_words_list_before[i])>0: # if there are words to change...\n",
    "            if transformation=='shuffle':\n",
    "                # Replace words that need to be shuffled by the random sampling (except fix point and punctuation)\n",
    "                new_order = random.sample(index_words_list_before[i], len(index_words_list_before[i]))\n",
    "                if len(index_words_list_before[i])>1:\n",
    "                    while new_order==index_words_list_before[i]:\n",
    "                        new_order = random.sample(index_words_list_before[i], len(index_words_list_before[i]))\n",
    "                new_words[i, index_words_list_before[i]] = new_words[i, new_order]\n",
    "            elif transformation=='pos_replacement':\n",
    "                # Replace words that need to be replaced by words with same POS (except fix point and punctuation)\n",
    "                new_words[i, index_words_list_before[i]] = pick_pos_word(new_words[i, index_words_list_before[i]], dictionary)\n",
    "            elif transformation=='random_replacement':\n",
    "                # Replace words that need to be replaced by random words (except fix point and punctuation)\n",
    "                new_words[i, index_words_list_before[i]] = pick_random_word(new_words[i, index_words_list_before[i]], vocabulary)\n",
    "        if len(index_words_list_after[i])>0: # if there are words to change...\n",
    "            if transformation=='shuffle':\n",
    "                new_order = random.sample(index_words_list_after[i], len(index_words_list_after[i]))\n",
    "                if len(index_words_list_after[i])>1:\n",
    "                    while new_order==index_words_list_after[i]:\n",
    "                        new_order = random.sample(index_words_list_after[i], len(index_words_list_after[i]))\n",
    "                new_words[i, index_words_list_after[i]] = new_words[i, new_order]\n",
    "            elif transformation=='pos_replacement':\n",
    "                new_words[i, index_words_list_after[i]] = pick_pos_word(new_words[i, index_words_list_after[i]], dictionary)\n",
    "            elif transformation=='random_replacement':\n",
    "                new_words[i, index_words_list_after[i]] = pick_random_word(new_words[i, index_words_list_after[i]], vocabulary)\n",
    "\n",
    "    # Convert array to list\n",
    "    new_words = list(new_words)\n",
    "    new_words = [list(item) for item in new_words]\n",
    "    batch_tmp = []\n",
    "    index_tmp = []\n",
    "    tokenizer = BertTokenizer.from_pretrained(pretrained_model) # to replace with tokenizer of interest\n",
    "    # adding transformed context to each sentence\n",
    "    for i, sentence in enumerate(new_words):\n",
    "        batch_tmp.append(' '.join(sentence).strip())\n",
    "        # Determining associated indexes\n",
    "        tmp1 = ' '.join(sentence[:i+len(words_before)])\n",
    "        tmp2 = ' '.join(sentence[:i+len(words_before)+1])\n",
    "        index_tmp.append((len(tokenizer.wordpiece_tokenizer.tokenize(tmp1.strip())), \n",
    "                     len(tokenizer.wordpiece_tokenizer.tokenize(tmp2.strip()))\n",
    "                    )) # to replace with tokenizer of interest and arguments\n",
    "    print(batch_tmp)\n",
    "    return batch_tmp, index_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entering while loop...\n",
      "1\n",
      "['once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’']\n",
      "['once , i stories in years real about , was forest a the i magnificent old primeval saw book picture called life ‘ six - when a . ’', 'once , the magnificent in life i years , about old forest i saw called was when real picture a stories six ‘ a - book primeval . ’', 'once , when life saw book in i , a picture the called magnificent primeval years six old was about forest a ‘ stories - real i . ’', 'when , once i about magnificent i life , stories real in years old forest a six saw primeval a the was ‘ picture - called book . ’', 'when , i once was years a in , real old i primeval called a forest the saw picture magnificent six stories ‘ book - about life . ’', 'i , when once was six in stories , old i magnificent picture about a real forest primeval called book life saw ‘ a - years the . ’', 'i , six was when once years book , a real stories i called picture the life forest in saw old a ‘ primeval - magnificent about . ’', 'was , once six i years when old , picture the about life book in stories a saw real magnificent a i ‘ called - forest primeval . ’', 'six , was when years i once old , in magnificent life picture book a i forest real called the a stories ‘ primeval - about saw . ’', 'six , when once was i old years , i about picture life primeval in real the stories forest a saw book ‘ a - magnificent called . ’', 'six , once was when old i years , i saw picture primeval stories book in a called real forest about a ‘ life - the magnificent . ’', 'old , i i was once when years , six saw a real a magnificent in the about life primeval forest picture ‘ stories - book called . ’', 'i , saw a once six old i , years was when magnificent the about life a called book primeval in picture ‘ stories - forest real . ’', 'years , i saw old once i when , six a was magnificent picture the in a forest about real primeval life ‘ called - stories book . ’', 'years , old i six i when picture , once saw a was magnificent in stories primeval the book forest called about ‘ real - life a . ’', 'i , was a i years old six , once saw in picture magnificent when a primeval real book forest called the ‘ about - life stories . ’', 'years , magnificent i a saw a in , once i six when old picture was book forest called the stories primeval ‘ real - life about . ’', 'magnificent , old six in a once i , when i years picture was saw a book about forest called stories the ‘ life - primeval real . ’', 'when , about i in book i magnificent , six once old years saw picture was a a the stories called primeval ‘ life - forest real . ’', 'in , magnificent about once six a i , years picture when book the a i was saw old primeval stories real ‘ forest - life called . ’', 'when , old a i book a once , magnificent i the picture was six saw primeval years about in forest stories ‘ life - called real . ’', 'saw , in a when book once years , was forest about old picture primeval i magnificent i the six a called ‘ life - stories real . ’', 'six , picture the book i a once , about i saw was a in magnificent old years when forest primeval called ‘ real - stories life . ’', 'the , a picture forest called once years , in saw six was about i i book when primeval magnificent old a ‘ real - stories life . ’', 'picture , when saw old magnificent years once , was six in forest the a primeval called book about i a i ‘ real - stories life . ’', 'saw , magnificent six when about called book , a picture i once forest old in years a primeval i was real ‘ the - life stories . ’', 'life , primeval picture old was when magnificent , once a about forest a six in years real the i i saw ‘ book - called stories . ’', 'saw , six forest old picture once about , life was a real book primeval in the a when i called i ‘ magnificent - years stories . ’', 'picture , a magnificent about years i six , i primeval old in called once was saw life when stories book the ‘ a - forest real . ’']\n",
      "0\n",
      "\n",
      "2\n",
      "['once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’', 'it showed a boa constrictor swallowing a wild animal .']\n",
      "['old , stories picture six real book i , years when a about magnificent forest primeval i the in called a saw ‘ once - life was . ’ it swallowing boa wild a animal a constrictor showed .', 'a , was about called six once book , a i in i life stories saw forest the it old real when ‘ picture - years magnificent . ’ primeval showed a animal wild boa constrictor a swallowing .', 'six , about book stories a called life , i saw was old picture it i in a forest showed primeval when ‘ years - the once . ’ real magnificent a wild animal swallowing a boa constrictor .', 'magnificent , years picture the about forest was , when showed saw stories i called a life a book in six i ‘ old - once real . ’ a it primeval boa animal a swallowing constrictor wild .', 'i , boa when six picture a real , saw was stories in called forest years a old life showed about it ‘ i - primeval a . ’ book once the magnificent constrictor swallowing wild a animal .', 'it , about i saw stories was in , picture primeval constrictor showed boa forest a once magnificent the a a called ‘ i - old book . ’ years real life when six swallowing animal wild a .', 'a , forest it stories real a showed , life magnificent called six years old i constrictor about i once swallowing was ‘ saw - picture the . ’ book boa primeval a in when a animal wild .', 'a , about old i called a boa , primeval book stories i the once showed saw magnificent constrictor six real a ‘ a - when swallowing . ’ it life in years was picture forest wild animal .', 'picture , a a in boa saw magnificent , old was it constrictor years a a when i six stories swallowing life ‘ showed - primeval once . ’ i forest about wild book real called the animal .', 'called , swallowing i constrictor years primeval boa , once forest when picture i stories showed saw real six book magnificent wild ‘ about - a old . ’ in it life the was a a a animal .']\n",
      "1\n",
      "p\n"
     ]
    }
   ],
   "source": [
    "iterator= iterator_list[0]\n",
    "number_of_sentence=config['number_of_sentence']\n",
    "number_sentence_before=config['number_of_sentence_before']\n",
    "number_sentence_after=config['number_of_sentence_after']\n",
    "pretrained_model='bert-base-uncased'\n",
    "past_context_size=config['attention_length_before']\n",
    "future_context_size=config['attention_length_after']\n",
    "transformation='shuffle'\n",
    "vocabulary=None\n",
    "dictionary=None\n",
    "seed=1111\n",
    "max_length=512\n",
    "\n",
    "\n",
    "iterator = [item.strip() for item in iterator]\n",
    "max_length -= 2 # for special tokens\n",
    "assert number_of_sentence > 0\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model) # to replace with tokenizer of interest\n",
    "\n",
    "batch = []\n",
    "indexes = []\n",
    "sentence_count = 0\n",
    "n = len(iterator)\n",
    "\n",
    "\n",
    "print('entering while loop...')\n",
    "# rest of the iterator + context \n",
    "while sentence_count < n:\n",
    "    start = max(sentence_count - number_sentence_before, 0)\n",
    "    stop = min(sentence_count + number_of_sentence, n)\n",
    "    stop_post_context = min(stop + number_sentence_after, n)\n",
    "    token_count = len(tokenizer.wordpiece_tokenizer.tokenize(' '.join(iterator[start:stop_post_context]))) # to replace with tokenizer of interest and arguments\n",
    "    if token_count > max_length:\n",
    "        raise ValueError('Cannot fit context with additional sentence. You should reduce context length.')\n",
    "    # computing batch and indexes\n",
    "    print(len(iterator[start:stop_post_context]))\n",
    "    print(iterator[start:stop_post_context])\n",
    "    \n",
    "    batch_tmp, index_tmp = transform_sentence_and_context(\n",
    "        iterator[start:stop_post_context], \n",
    "        past_context_size=past_context_size,\n",
    "        future_context_size=future_context_size, \n",
    "        pretrained_model=pretrained_model,\n",
    "        transformation=transformation,\n",
    "        vocabulary=vocabulary,\n",
    "        dictionary=dictionary,\n",
    "        select=stop-start-1,\n",
    "        seed=seed\n",
    "    )        \n",
    "    batch += batch_tmp\n",
    "    indexes += index_tmp\n",
    "    sentence_count = stop\n",
    "    print(stop-start-1)\n",
    "    if input()!='':\n",
    "        break\n",
    "\n",
    "#for b in batch:\n",
    "#    print(b)\n",
    "#print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-cd6c0dddeb38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mresult_dep_relations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0mresult_dep_relations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dep_relations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dependence'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0msave_yaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dep_relations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-cd6c0dddeb38>\u001b[0m in \u001b[0;36mmerge_dict\u001b[0;34m(list_of_dict, merge_type)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist_of_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_of_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mnew_list_of_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_two_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdict1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mnew_list_of_dicts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import os, yaml\n",
    "import tqdm\n",
    "import glob\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "import random\n",
    "from collections import Counter\n",
    "import glob\n",
    "\n",
    "def save_yaml(data, yaml_path):\n",
    "    \"\"\"Open and write safely in a yaml file.\n",
    "    Arguments:\n",
    "        - data: list/dict/str/int/float\n",
    "        -yaml_path: str\n",
    "    \"\"\"\n",
    "    with open(yaml_path, 'w') as outfile:\n",
    "        yaml.dump(data, outfile, default_flow_style=False)\n",
    "\n",
    "def merge_two_dicts(dict1, dict2, merge_type='dependence'):\n",
    "    \"\"\"Need to iterate over dict1.keys() because 'merge_two_dicts_key' return updated dict2.\n",
    "    \"\"\"\n",
    "    if merge_type=='dependence':\n",
    "        dict2 = {k: list(set(dict2.get(k) if dict2.get(k) is not None else []).union(set(dict1.get(k) if dict1.get(k) is not None else []))) for k in set(dict2) | set(dict1)}\n",
    "    #else:\n",
    "    #    for key in dict1.keys():\n",
    "    #        dict2 = merge_two_dicts_key(dict1, dict2, key)\n",
    "    return dict2\n",
    "\n",
    "\n",
    "def merge_dict(list_of_dict, merge_type='dependence'):\n",
    "    \"\"\"Merge a list of dict\n",
    "    \"\"\"\n",
    "    if len(list_of_dict)==0:\n",
    "        print('input is empty...')\n",
    "    elif len(list_of_dict)==1:\n",
    "        return list_of_dict[0]\n",
    "    else:\n",
    "        pairs = [[list_of_dict[2*i], list_of_dict[2*i+1]] for i in range(len(list_of_dict)//2)]\n",
    "        new_list_of_dicts = Parallel(n_jobs=-1)(delayed(merge_two_dicts)(dict1, dict2, merge_type=merge_type) for dict1, dict2 in tqdm(pairs))\n",
    "        if len(list_of_dict)%2==1:\n",
    "            new_list_of_dicts.append(list_of_dict[-1])\n",
    "        return merge_dict(new_list_of_dicts, merge_type=merge_type)\n",
    "    \n",
    "def uniform(values):\n",
    "    \"\"\" Pick randomly following uniform distribution\n",
    "    \"\"\"\n",
    "    n = len(values)\n",
    "    return values[random.randint(0, n-1)]\n",
    "saving_path = '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing'\n",
    "\n",
    "def tmp(path):\n",
    "    with open(path, 'r') as stream:\n",
    "        params = yaml.safe_load(stream)\n",
    "    return params\n",
    "\n",
    "files = [\n",
    "    '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-950_to-1000.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-900_to-950.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-850_to-900.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-800_to-850.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-750_to-800.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-700_to-750.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-650_to-700.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-600_to-650.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-550_to-600.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-50_to-100.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-500_to-550.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-450_to-500.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-400_to-450.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-350_to-400.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-300_to-350.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-250_to-300.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-200_to-250.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-150_to-200.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-100_to-150.yml',\n",
    "'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-0_to-50.yml',\n",
    "\n",
    "]\n",
    "\n",
    "saving_path = '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing'\n",
    "name = 'dependency_relations_from-0_to-1000.yml'\n",
    "\n",
    "\n",
    "result_dep_relations = Parallel(n_jobs=-1)(delayed(tmp)(item) for item in files)\n",
    "result_dep_relations = merge_dict(result_dep_relations, merge_type='dependence')\n",
    "\n",
    "save_yaml(result_dep_relations, os.path.join(saving_path, name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.merge_dict(list_of_dict, merge_type='dependence')>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'function'> "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-d59c2af6ce72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult_dep_relations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dep_relations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dependence'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-65-2de8e49bec90>\u001b[0m in \u001b[0;36mmerge_dict\u001b[0;34m(list_of_dict, merge_type)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist_of_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_of_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_two_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mnew_list_of_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_two_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdict1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result_dep_relations = merge_dict(result_dep_relations, merge_type='dependence')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "import random\n",
    "from collections import Counter\n",
    "import glob\n",
    "import spacy\n",
    "\n",
    "def merge_two_dicts_key(dict1, dict2, key):\n",
    "    \"\"\"Merge 2 dicts values for a given key into 1.\n",
    "    We return dict2, because we assume that we iterate in dict1.keys() in the parent function.\n",
    "    \"\"\"\n",
    "    if dict1[key]['text'] in dict2.keys():\n",
    "        # POS\n",
    "        dict2[key]['POS'] = {k: dict2[key]['POS'].get(k, 0) +  dict1[key]['POS'].get(k, 0) for k in set(dict2[key]['POS']) | set(dict1[key]['POS'])}\n",
    "        # TAG\n",
    "        dict2[key]['tag'] = {k: dict2[key]['tag'].get(k, 0) +  dict1[key]['tag'].get(k, 0) for k in set(dict2[key]['tag']) | set(dict1[key]['tag'])}\n",
    "        # Dependecy parsing\n",
    "        dict2[key]['dependency_parsing'] = {k: dict2[key]['dependency_parsing'].get(k, 0) +  dict1[key]['dependency_parsing'].get(k, 0) for k in set(dict2[key]['dependency_parsing']) | set(dict1[key]['dependency_parsing'])}\n",
    "        # head\n",
    "        x = dict(Counter(dict2[key]['head']))\n",
    "        y = dict(Counter(dict1[key]['head']))\n",
    "        dict2[key]['head'] = {k: x.get(k, 0) + y.get(k, 0) for k in set(x) | set(y)}\n",
    "        # head_pos\n",
    "        x = dict(Counter(dict2[key]['head_pos']))\n",
    "        y = dict(Counter(dict1[key]['head_pos']))\n",
    "        dict2[key]['head_pos'] = {k: x.get(k, 0) + y.get(k, 0) for k in set(x) | set(y)}\n",
    "        # morphology\n",
    "        x = dict(Counter(dict2[key]['morphology']))\n",
    "        y = dict(Counter(dict1[key]['morphology']))\n",
    "        dict2[key]['morphology'] = {k: x.get(k, 0) + y.get(k, 0) for k in set(x) | set(y)}\n",
    "        # entity_IOB\n",
    "        dict2[key]['entity_IOB'] = {k: dict2[key]['entity_IOB'].get(k, 0) +  dict1[key]['entity_IOB'].get(k, 0) for k in set(dict2[key]['entity_IOB']) | set(dict1[key]['entity_IOB'])}\n",
    "        # entity_type\n",
    "        dict2[key]['entity_type'] = {k: dict2[key]['entity_type'].get(k, 0) +  dict1[key]['entity_type'].get(k, 0) for k in set(dict2[key]['entity_type']) | set(dict1[key]['entity_type'])}\n",
    "        # entity\n",
    "        dict2[key]['entity'] = {k: dict2[key]['entity'].get(k, 0) +  dict1[key]['entity'].get(k, 0) for k in set(dict2[key]['entity']) | set(dict1[key]['entity'])}\n",
    "\n",
    "    else:\n",
    "        dict2[key] = dict1[key].copy()\n",
    "    return dict2\n",
    "\n",
    "def merge_two_dicts(dict1, dict2, merge_type='dependence'):\n",
    "    \"\"\"Need to iterate over dict1.keys() because 'merge_two_dicts_key' return updated dict2.\n",
    "    \"\"\"\n",
    "    if merge_type=='dependence':\n",
    "        dict2 = {k: list(set(dict2.get(k) if dict2.get(k) is not None else []).union(set(dict1.get(k) if dict1.get(k) is not None else []))) for k in set(dict2) | set(dict1)}\n",
    "    else:\n",
    "        for key in dict1.keys():\n",
    "            dict2 = merge_two_dicts_key(dict1, dict2, key)\n",
    "    return dict2\n",
    "\n",
    "\n",
    "def merge_dict(list_of_dict, merge_type='dependence'):\n",
    "    \"\"\"Merge a list of dict\n",
    "    \"\"\"\n",
    "    if len(list_of_dict)==0:\n",
    "        print('input is empty...')\n",
    "    elif len(list_of_dict)==1:\n",
    "        return list_of_dict[0]\n",
    "    else:\n",
    "        pairs = [[list_of_dict[2*i], list_of_dict[2*i+1]] for i in range(len(list_of_dict)//2)]\n",
    "        print(type(merge_two_dicts), pairs)\n",
    "        new_list_of_dicts = Parallel(n_jobs=-1)(delayed(merge_two_dicts)(dict1, dict2, merge_type=merge_type) for dict1, dict2 in tqdm(pairs))\n",
    "        if len(list_of_dict)%2==1:\n",
    "            new_list_of_dicts.append(list_of_dict[-1])\n",
    "        return merge_dict(new_list_of_dicts, merge_type=merge_type)\n",
    "    \n",
    "def uniform(values):\n",
    "    \"\"\" Pick randomly following uniform distribution\n",
    "    \"\"\"\n",
    "    n = len(values)\n",
    "    return values[random.randint(0, n-1)]\n",
    "\n",
    "def generate_pos_freq_sample(nlp, sentence, dep_relations_dict, n_samples=50, limit_iterations=3000, information_type='tag', use_morph=True, same_freq=True, word_freq=None, skip_punctuation=True):\n",
    "    \"\"\"Generate sentence with same POS, dependecy parsing and syntaxic tree.\n",
    "    freq_dict is the log frequency dictionary whose keys are vocabulary words.\n",
    "    \"\"\"\n",
    "    punctuation = ['\\'', ',', ';', ':', '/', '-', '\"', '‘', '’', '(', ')', '{', '}', '[', ']', '`', '“', '”', '—', '.', '!', '?', '...']\n",
    "    doc = nlp(sentence)\n",
    "    root = [token for token in doc if token.head == token][0]\n",
    "    ref_tree_representation = doc_to_tree(doc, root)\n",
    "    # Iterating to generate samples\n",
    "    i=0\n",
    "    count=0\n",
    "    new_samples = []\n",
    "    while (i < n_samples) and (count < limit_iterations):\n",
    "        sample = []\n",
    "        for token in doc:\n",
    "            if (token.text.lower() in punctuation) and skip_punctuation:\n",
    "                sample.append(token.text.lower())\n",
    "            else:\n",
    "                # Computing dependency relationships with head and children\n",
    "                keys = []\n",
    "                if information_type=='tag':\n",
    "                    all_children = [token.tag_]\n",
    "                elif information_type=='pos':\n",
    "                    all_children = [token.pos_]\n",
    "                elif information_type=='dep':\n",
    "                    all_children = [token.dep_]\n",
    "                for child in token.children:\n",
    "                    if information_type=='tag':\n",
    "                        keys.append(str([token.tag_, child.tag_]))\n",
    "                        all_children.append(child.tag_)\n",
    "                    elif information_type=='pos':\n",
    "                        keys.append(str([token.pos_, child.pos_]))\n",
    "                        all_children.append(child.pos_)\n",
    "                    elif information_type=='dep':\n",
    "                        keys.append(str([token.dep_, child.dep_]))\n",
    "                        all_children.append(child.dep_)\n",
    "                keys.append(str(all_children))\n",
    "                if use_morph:\n",
    "                    for index in range(len(keys)):\n",
    "                        keys[index] += str(token.morph)\n",
    "                # Retrieving possible words to replace 'token'\n",
    "                for index, key in enumerate(keys):\n",
    "                    keys[index] = str(uuid.uuid3(uuid.NAMESPACE_DNS, str(key)).hex)\n",
    "                index = len(keys)-1\n",
    "                while (keys[index] not in dep_relations_dict.keys()) and (index>=0):\n",
    "                    index -= 1\n",
    "                if index<0:\n",
    "                    raise KeyError\n",
    "                possible_words = dep_relations_dict[keys[index]]\n",
    "                if same_freq:\n",
    "                    possible_words = filter_list(possible_words, word_freq, word_freq[token.text.lower()])\n",
    "                print(token.text, possible_words)\n",
    "                sample.append(uniform(possible_words))\n",
    "        new_sentence = ' '.join(sample)\n",
    "        doc_sample = nlp(' '.join(sample))\n",
    "        root = [token for token in doc_sample if token.head == token][0]\n",
    "        tree_representation = doc_to_tree(doc_sample, root)\n",
    "        if tree_representation==ref_tree_representation:\n",
    "            i+=1\n",
    "            new_samples.append(new_sentence)\n",
    "        count+=1\n",
    "    print('done in ', count, ' iterations.')\n",
    "    return new_samples\n",
    "\n",
    "\n",
    "def batchify(train_data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    train = train_data.replace('<eos>', '').replace('<unk>', '').split('\\n')\n",
    "    batches = [' '.join(train[i*5000:(i+1)*5000]) for i in range(len(train)//5000)]\n",
    "    return batches\n",
    "\n",
    "def doc_to_tree(doc, root, tree_type='pos'):\n",
    "    \"\"\"Create linear tree structure to represent dependency parsing.\n",
    "    \"\"\"\n",
    "    representation = [root.pos_ if tree_type=='pos' else root.tag_]\n",
    "    tmp = []\n",
    "    for descendant in root.children:\n",
    "        tmp.append(doc_to_tree(doc, descendant))\n",
    "    representation += tmp\n",
    "    return representation\n",
    "\n",
    "\n",
    "def get_sentence_tree_dict(tree_data, tree_type='pos'):\n",
    "    \"\"\"Train data should have been prepared with :\n",
    "    ''' tree_data = train_data.replace('<eos>', '').replace('<unk>', '').split('\\n') '''\n",
    "    tree_data should be a list of sentences.\n",
    "    \"\"\"\n",
    "    tree_dict = {}\n",
    "    for sentence in tqdm(tree_data):\n",
    "        doc = nlp(sentence)\n",
    "        root = [token for token in doc if token.head == token][0]\n",
    "        tree_representation = doc_to_tree(doc, root, tree_type=tree_type)\n",
    "        order = [token.dep_ for token in doc]\n",
    "        if str(tree_representation) in tree_dict.keys():\n",
    "            if str(order) in tree_dict[str(tree_representation)].keys():\n",
    "                for index_token, token in enumerate(doc):\n",
    "                    if token.text.lower() not in tree_dict[str(tree_representation)][str(order)][index_token]:\n",
    "                        tree_dict[str(tree_representation)][str(order)][index_token].append(token.text.lower())\n",
    "            else:\n",
    "                tree_dict[str(tree_representation)][str(order)] = [[token.text.lower()] for token in doc]\n",
    "        else:\n",
    "            tree_dict[str(tree_representation)] = {}\n",
    "            tree_dict[str(tree_representation)][str(order)] = [[token.text.lower()] for token in doc]\n",
    "    return tree_dict\n",
    "\n",
    "\n",
    "def update_dependency_dict(token, dep_relations={}, key_type='dep', use_children=True):\n",
    "    \"\"\"Update a dictionary where keys are dependency relationships.\n",
    "    And values are list of possible words.\n",
    "    \"\"\"\n",
    "    word = token.text.lower()\n",
    "    # determining type of key\n",
    "    # DEP\n",
    "    if key_type=='dep':\n",
    "        if use_children:\n",
    "            keys = []\n",
    "            all_children = [token.dep_]\n",
    "            for child in token.children:\n",
    "                keys.append(str([token.dep_, child.dep_]))\n",
    "                all_children.append(child.dep_)\n",
    "            keys.append(str(all_children))\n",
    "        else:\n",
    "            keys = [str(token.dep_)]\n",
    "    # POS\n",
    "    elif key_type=='pos':\n",
    "        if use_children:\n",
    "            keys = []\n",
    "            all_children = [token.head.pos_, token.pos_]\n",
    "            for child in token.children:\n",
    "                keys.append(str([token.head.pos_, token.pos_, child.pos_]))\n",
    "                all_children.append(child.pos_)\n",
    "            keys.append(str(all_children))\n",
    "        else:\n",
    "            keys = [str([token.head.pos_, token.pos_])]\n",
    "    # TAG\n",
    "    elif key_type=='tag':\n",
    "        if use_children:\n",
    "            keys = []\n",
    "            all_children = [token.head.tag_, token.tag_]\n",
    "            for child in token.children:\n",
    "                keys.append(str([token.head.tag_, token.tag_, child.tag_]))\n",
    "                all_children.append(child.tag_)\n",
    "            keys.append(str(all_children))\n",
    "        else:\n",
    "            keys = [str([token.head.tag_, token.tag_])]\n",
    "    final_keys = []\n",
    "    for key in keys:\n",
    "        final_keys.append(key + str(token.morph))\n",
    "    for index, key in enumerate(final_keys):\n",
    "        final_keys[index] = uuid.uuid3(uuid.NAMESPACE_DNS, str(key)).hex\n",
    "    # updating the dictionary\n",
    "    for key in final_keys:\n",
    "        if key in dep_relations.keys():\n",
    "            if word not in dep_relations[key]:\n",
    "                dep_relations[key].append(word)\n",
    "        else:\n",
    "            dep_relations[key] = [word]\n",
    "        \n",
    "def update_parsing_dict(token, data_dict={}):\n",
    "    \"\"\"Update a dictionary with all general relationships in language.\n",
    "    \"\"\"\n",
    "    word = token.text.lower()\n",
    "    if word not in data_dict.keys():\n",
    "        data_dict[word] = {\n",
    "            'text': word,\n",
    "            'lemma': token.lemma_,\n",
    "            'POS': {token.pos_: 1},\n",
    "            'tag': {token.tag_: 1},\n",
    "            'dependency_parsing': {token.dep_: 1},\n",
    "            'head': [token.head.text.lower()],\n",
    "            'head_pos': [token.head.pos_],\n",
    "            'shape': token.shape_,\n",
    "            #'is_alpha': [token.is_alpha],\n",
    "            #'is_stop': [token.is_stop],\n",
    "            'morphology': [str(token.morph)],\n",
    "            'entity_IOB': {token.ent_iob_: 1},\n",
    "            'entity_type': {token.ent_type_: 1},\n",
    "            'entity': {token.ent_kb_id_: 1},\n",
    "        }\n",
    "    else:\n",
    "        # POS\n",
    "        if token.pos_ in data_dict[word]['POS'].keys():\n",
    "            data_dict[word]['POS'][token.pos_] +=1\n",
    "        else:\n",
    "            data_dict[word]['POS'][token.pos_] =1\n",
    "        # TAG\n",
    "        if token.tag_ in data_dict[word]['tag'].keys():\n",
    "            data_dict[word]['tag'][token.tag_] +=1\n",
    "        else:\n",
    "            data_dict[word]['tag'][token.tag_] =1\n",
    "        # Dependecy parsing\n",
    "        if token.dep_ in data_dict[word]['dependency_parsing'].keys():\n",
    "            data_dict[word]['dependency_parsing'][token.dep_] += 1\n",
    "        else:\n",
    "            data_dict[word]['dependency_parsing'][token.dep_] = 1\n",
    "        # head\n",
    "        data_dict[word]['head'].append(token.head.text.lower())\n",
    "        # head_pos\n",
    "        data_dict[word]['head_pos'].append(token.head.pos_)\n",
    "        # is_alpha\n",
    "        #data_dict[word]['is_alpha'].append(token.is_alpha)\n",
    "        # is_stop\n",
    "        #data_dict[word]['is_stop'].append(token.is_stop)\n",
    "        # morphology\n",
    "        data_dict[word]['morphology'].append(str(token.morph))\n",
    "        # entity_IOB\n",
    "        if token.ent_iob_ in data_dict[word]['entity_IOB'].keys():\n",
    "            data_dict[word]['entity_IOB'][token.ent_iob_] += 1\n",
    "        else:\n",
    "            data_dict[word]['entity_IOB'][token.ent_iob_] = 1\n",
    "        # entity_type\n",
    "        if token.ent_type_ in data_dict[word]['entity_type'].keys():\n",
    "            data_dict[word]['entity_type'][token.ent_type_] += 1\n",
    "        else:\n",
    "            data_dict[word]['entity_type'][token.ent_type_] = 1\n",
    "        # entity\n",
    "        if token.ent_type_ in data_dict[word]['entity'].keys():\n",
    "            data_dict[word]['entity'][token.ent_kb_id_] += 1\n",
    "        else:\n",
    "            data_dict[word]['entity'][token.ent_kb_id_] = 1\n",
    "            \n",
    "def get_dep_and_parsing_dicts(train, index, saving_path):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    doc = nlp(train)\n",
    "    #data_dict = {}\n",
    "    dep_relations = {}\n",
    "    for index, token in tqdm(enumerate(doc)):\n",
    "        try:\n",
    "            update_dependency_dict(token, dep_relations=dep_relations, key_type='dep')\n",
    "            update_dependency_dict(token, dep_relations=dep_relations, key_type='pos')\n",
    "            update_dependency_dict(token, dep_relations=dep_relations, key_type='tag')\n",
    "            #update_parsing_dict(token, data_dict=data_dict)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return dep_relations\n",
    "    #save_yaml(dep_relations, os.path.join(saving_path, 'dep_relations-{}.yml'.format(index)))\n",
    "    #tree_data = train_data.replace('<eos>', '').replace('<unk>', '').split('\\n')\n",
    "    #tree_dict = get_sentence_tree_dict(tree_data)\n",
    "    #return data_dict, dep_relations\n",
    "\n",
    "\n",
    "def read_yaml(yaml_path):\n",
    "    \"\"\"Open and read safely a yaml file.\"\"\"\n",
    "    with open(yaml_path, 'r') as stream:\n",
    "        try:\n",
    "            parameters = yaml.safe_load(stream)\n",
    "        except :\n",
    "            print(\"Couldn't load yaml file: {}.\".format(yaml_path))\n",
    "            quit()\n",
    "    return parameters\n",
    "\n",
    "def save_yaml(data, yaml_path):\n",
    "    \"\"\"Open and write safely in a yaml file.\n",
    "    Arguments:\n",
    "        - data: list/dict/str/int/float\n",
    "        -yaml_path: str\n",
    "    \"\"\"\n",
    "    with open(yaml_path, 'w') as outfile:\n",
    "        yaml.dump(data, outfile, default_flow_style=False)\n",
    "    \n",
    "def write(path, text, end='\\n'):\n",
    "    \"\"\"Write in the specified text file.\"\"\"\n",
    "    with open(path, 'a+') as f:\n",
    "        f.write(text)\n",
    "        f.write(end)\n",
    "\n",
    "def check_folder(path):\n",
    "    \"\"\"Create adequate folders if necessary.\"\"\"\n",
    "    try:\n",
    "        if not os.path.isdir(path):\n",
    "            check_folder(os.path.dirname(path))\n",
    "            os.mkdir(path)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform(values):\n",
    "    \"\"\" Pick randomly following uniform distribution\n",
    "    \"\"\"\n",
    "    n = len(values)\n",
    "    return values[random.randint(0, n-1)]\n",
    "\n",
    "# Filter a list based on criteria\n",
    "def filter_list(list_to_filter, values, reference):\n",
    "    \"\"\" Filter a list based on criteria\n",
    "    \"\"\"\n",
    "    def keep(word):\n",
    "        if np.abs(values[word] - reference) <= 1:\n",
    "            return word\n",
    "    new_list = map(keep, list_to_filter)\n",
    "    # we remove None values\n",
    "    new_list = list(filter(None, new_list))\n",
    "    return new_list\n",
    "\n",
    "def generate_freq_sample(sentence, n_samples, word_list, word_freq, skip_punctuation=True, limit_iterations=1000):\n",
    "    \"\"\"Generate sentence with same frequency.\n",
    "    freq_dict is the log frequency dictionary whose keys are vocabulary words.\n",
    "    \"\"\"\n",
    "    punctuation = ['\\'', ',', ';', ':', '/', '-', '\"', '‘', '’', '(', ')', '{', '}', '[', ']', '`', '“', '”', '—', '.', '!', '?', '...']\n",
    "    def sample_sentence():\n",
    "        sample = []\n",
    "        for word in sentence.split():\n",
    "            if skip_punctuation and (word in punctuation):\n",
    "                sample.append(word)\n",
    "            else:\n",
    "                possible_words = filter_list(word_list, word_freq, word_freq[word])\n",
    "                sample.append(uniform(possible_words))\n",
    "        new_sentence = ' '.join(sample)\n",
    "        return new_sentence\n",
    "    new_samples = Parallel(n_jobs=-1)(delayed(sample_sentence)() for _ in range(n_samples))\n",
    "\n",
    "    return new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_relations_dict_1 = read_yaml('/Volumes/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/dependency_relations_from-0_to-1000.yml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’\n",
      "['promised , boys it must row hand they , in dollars going complex true t want forgot was get matzoth sponge since ‘ beach - gonna yo . ’', 'science , em me guys relationship america fly , for leaves was rich twins all get sally pretty got infuriate busted ones ‘ got - probably prep . ’', 'forgive , young they i explain jimmy husband , t type right indians recommend way what special uh up commitments outstanding wasn ‘ upset - name jersey . ’', 'starting , anyway no they ma hands major , don movies ll sahara former is i video sure was baedeker stuffed force ‘ cost - coming sometime . ’', 'honor , left like lot orange joke being , are animal going clicks uniform very about space fuck re procuring embarrass david ‘ showed - ma nicky . ’', 'bank , will right home plain pick ln , don idea on hag woman what not rich hello your cufflink licking said ‘ bus - might lounge . ’', 'keys , hands not give grandfather close michael , just whoa she metro known okay good stranger things like jackman swamp police ‘ spirit - who shaking . ’', 'mother , man it at busted questions tv , here never me casualties shock good re closet men a supe competitors staying ‘ left - questions argue . ’', 'doctor , chance was about pleased during police , in middle let volcano ward got if students night now epithelium brent anybody ‘ ah - drink unacceptable . ’', 'horse , trouble be night meal inside mike , m nobody how loch base re come starts son all zanders snatch yep ‘ none - colonel congress . ’']\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8d649c307f24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_freq_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_punctuation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_pos_freq_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdep_relations_dict_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minformation_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_morph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msame_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_punctuation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2de8e49bec90>\u001b[0m in \u001b[0;36mgenerate_pos_freq_sample\u001b[0;34m(nlp, sentence, dep_relations_dict, n_samples, limit_iterations, information_type, use_morph, same_freq, word_freq, skip_punctuation)\u001b[0m\n\u001b[1;32m    119\u001b[0m                     \u001b[0mindex\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0mpossible_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdep_relations_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msame_freq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#from get_dependency_parsing import generate_pos_freq_sample, generate_freq_sample, filter_list\n",
    "\n",
    "english_words_data = pd.read_csv('/Volumes/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/text/english/lexique_database.tsv', delimiter='\\t')\n",
    "# Creating dict with freq information\n",
    "word_list = english_words_data['Word'].apply(lambda x: str(x).lower()).values\n",
    "freq_list = english_words_data['Lg10WF'].values\n",
    "zip_freq = zip(word_list, freq_list)\n",
    "word_freq = dict(zip_freq)\n",
    "\n",
    "\n",
    "for sentence in iterator_list[0][:2]:\n",
    "    print(sentence)\n",
    "    print(generate_freq_sample(sentence, 10, word_list, word_freq, skip_punctuation=True))\n",
    "    print()\n",
    "    print(generate_pos_freq_sample(nlp, sentence, dep_relations_dict_1, n_samples=1, limit_iterations=3000, information_type='tag', use_morph=True, same_freq=True, word_freq=word_freq, skip_punctuation=True))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection of two lists\n",
    "def intersect(list1, list2):\n",
    "    \"\"\" Intersects two lists\n",
    "    \"\"\"\n",
    "    tmp = set(list2)\n",
    "    list3 = [value for value in list1 if value in tmp]\n",
    "    return list3\n",
    "\n",
    "list1 = pd.read_csv('/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/text/english/lexique_database.tsv', delimiter='\\t')\n",
    "\n",
    "list1 = list1[['Word', 'Lg10WF']]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy Parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.remove_pipe(\"ner\")\n",
    "nlp.max_length = np.inf\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on LPP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>tag</th>\n",
       "      <th>dependency parsing</th>\n",
       "      <th>head</th>\n",
       "      <th>head_pos</th>\n",
       "      <th>shape</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>morphology</th>\n",
       "      <th>entity_IOB</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>once</td>\n",
       "      <td>once</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>advmod</td>\n",
       "      <td>saw</td>\n",
       "      <td>VERB</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>saw</td>\n",
       "      <td>VERB</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(PunctType=Comm)</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when</td>\n",
       "      <td>when</td>\n",
       "      <td>ADV</td>\n",
       "      <td>WRB</td>\n",
       "      <td>advmod</td>\n",
       "      <td>was</td>\n",
       "      <td>VERB</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>()</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>was</td>\n",
       "      <td>VERB</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>(Case=Nom, Number=Sing, Person=1, PronType=Prs)</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>was</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBD</td>\n",
       "      <td>advcl</td>\n",
       "      <td>saw</td>\n",
       "      <td>VERB</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>(Mood=Ind, Number=Sing, Person=3, Tense=Past, ...</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>go</td>\n",
       "      <td>VERB</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>(Number=Sing)</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>go</td>\n",
       "      <td>go</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VB</td>\n",
       "      <td>ccomp</td>\n",
       "      <td>added</td>\n",
       "      <td>VERB</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>(VerbForm=Inf)</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>far</td>\n",
       "      <td>far</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>advmod</td>\n",
       "      <td>go</td>\n",
       "      <td>VERB</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>()</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>NFP</td>\n",
       "      <td>punct</td>\n",
       "      <td>added</td>\n",
       "      <td>VERB</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>()</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>”</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>''</td>\n",
       "      <td>punct</td>\n",
       "      <td>added</td>\n",
       "      <td>VERB</td>\n",
       "      <td>”</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(PunctSide=Fin, PunctType=Quot)</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1895 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text lemma    POS  tag dependency parsing   head head_pos shape  \\\n",
       "0     once  once    ADV   RB             advmod    saw     VERB  xxxx   \n",
       "1        ,     ,  PUNCT    ,              punct    saw     VERB     ,   \n",
       "2     when  when    ADV  WRB             advmod    was     VERB  xxxx   \n",
       "3        i     I   PRON  PRP              nsubj    was     VERB     x   \n",
       "4      was    be   VERB  VBD              advcl    saw     VERB   xxx   \n",
       "...    ...   ...    ...  ...                ...    ...      ...   ...   \n",
       "1890     t     t   NOUN   NN              nsubj     go     VERB     x   \n",
       "1891    go    go   VERB   VB              ccomp  added     VERB    xx   \n",
       "1892   far   far    ADV   RB             advmod     go     VERB   xxx   \n",
       "1893   ...   ...  PUNCT  NFP              punct  added     VERB   ...   \n",
       "1894     ”     \"  PUNCT   ''              punct  added     VERB     ”   \n",
       "\n",
       "      is_alpha  is_stop                                         morphology  \\\n",
       "0         True     True                                                 ()   \n",
       "1        False    False                                   (PunctType=Comm)   \n",
       "2         True     True                                                 ()   \n",
       "3         True     True    (Case=Nom, Number=Sing, Person=1, PronType=Prs)   \n",
       "4         True     True  (Mood=Ind, Number=Sing, Person=3, Tense=Past, ...   \n",
       "...        ...      ...                                                ...   \n",
       "1890      True    False                                      (Number=Sing)   \n",
       "1891      True     True                                     (VerbForm=Inf)   \n",
       "1892      True    False                                                 ()   \n",
       "1893     False    False                                                 ()   \n",
       "1894     False    False                    (PunctSide=Fin, PunctType=Quot)   \n",
       "\n",
       "     entity_IOB entity_type entity  \n",
       "0             O                     \n",
       "1             O                     \n",
       "2             O                     \n",
       "3             O                     \n",
       "4             O                     \n",
       "...         ...         ...    ...  \n",
       "1890          O                     \n",
       "1891          O                     \n",
       "1892          O                     \n",
       "1893          O                     \n",
       "1894          O                     \n",
       "\n",
       "[1895 rows x 14 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "doc = nlp(' '.join(iterator_list[0]))\n",
    "data = []\n",
    "for index, token in enumerate(doc):\n",
    "    data.append([token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.head.text, token.head.pos_,\n",
    "            token.shape_, token.is_alpha, token.is_stop, token.morph, token.ent_iob_, token.ent_type_, token.ent_kb_id_])\n",
    "    #print(ref[index], token.text)\n",
    "df = pd.DataFrame(data, columns=['text', 'lemma', 'POS', 'tag', 'dependency parsing', 'head', 'head_pos', 'shape', \n",
    "                                 'is_alpha', 'is_stop', 'morphology', 'entity_IOB', 'entity_type', 'entity'\n",
    "                                ])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on Wikipedia\n",
    "train_data = open('/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/text/english/lstm_training/train.txt', 'r').read()\n",
    "train = train_data.replace('<eos>', '').replace('\\n', '').replace('<unk>', '')\n",
    "\n",
    "train_batch = batchify(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on Project Gutenberg\n",
    "train_batch = sorted(glob.glob('/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/text/english/Gutenberg/txt/*'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(train, index, saving_path, preprocess=False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if preprocess:\n",
    "        train = open(train, 'r').read()\n",
    "        train = train.replace('\\n', ' ').replace(\"\\'\", ' ').replace('_', ' ')\n",
    "        train = ' '.join(train.split())\n",
    "    get_dep_and_parsing_dicts(train, index, saving_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "saving_path = '/home/ap263679/tmp/dependency_parsing'\n",
    "merge_every = 200\n",
    "result_dep_relations = []\n",
    "result_data_dict = []\n",
    "\n",
    "for index, train in tqdm(enumerate(train_batch)):\n",
    "    f(train, index=index, saving_path=saving_path, preprocess=True)\n",
    "\n",
    "\n",
    "for i in range(0, len(train_batch)//merge_every):\n",
    "    gc.collect()\n",
    "    results = Parallel(n_jobs=-2)(delayed(f)(train, index=index, saving_path=saving_path, preprocess=True) for train in tqdm(train_batch[i*merge_every:(i+1)*merge_every]))\n",
    "    res = list(zip(*results))\n",
    "    #result_data_dict += res[0]\n",
    "    result_dep_relations += res[1]\n",
    "    result_dep_relations = merge_dict(result_dep_relations, merge_type='dependence')\n",
    "    #result_data_dict = merge_dict(result_data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 85.12it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 6016.42it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 2427.66it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 981.28it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 904.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 396.40it/s]\n",
      "/home/ap263679/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "saving_path = '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing'\n",
    "\n",
    "def tmp(path):\n",
    "    with open(path, 'r') as stream:\n",
    "        params = yaml.safe_load(stream)\n",
    "    return params\n",
    "\n",
    "result_dep_relations = Parallel(n_jobs=-1)(delayed(tmp)(item) for item in tqdm(sorted(glob.glob(f'/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-*_to-*.yml'))))\n",
    "result_dep_relations = merge_dict(result_dep_relations, merge_type='dependence')\n",
    "\n",
    "save_yaml(result_dep_relations, os.path.join(saving_path, 'dependency_relations.yml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"37b19ac4c3e849c6bc5d714fff8eabbe-0\" class=\"displacy\" width=\"1450\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">it</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">showed</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">boa</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">constrictor</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">digesting</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">an</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">elephant .</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-37b19ac4c3e849c6bc5d714fff8eabbe-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-37b19ac4c3e849c6bc5d714fff8eabbe-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-37b19ac4c3e849c6bc5d714fff8eabbe-0-1\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-37b19ac4c3e849c6bc5d714fff8eabbe-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-37b19ac4c3e849c6bc5d714fff8eabbe-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-37b19ac4c3e849c6bc5d714fff8eabbe-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-37b19ac4c3e849c6bc5d714fff8eabbe-0-3\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 750.0,2.0 750.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-37b19ac4c3e849c6bc5d714fff8eabbe-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,266.5 L758.0,254.5 742.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-37b19ac4c3e849c6bc5d714fff8eabbe-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-37b19ac4c3e849c6bc5d714fff8eabbe-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-37b19ac4c3e849c6bc5d714fff8eabbe-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-37b19ac4c3e849c6bc5d714fff8eabbe-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-37b19ac4c3e849c6bc5d714fff8eabbe-0-6\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-37b19ac4c3e849c6bc5d714fff8eabbe-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "once , when i was six years old , i saw a magnificent picture in a book about the primeval forest called ‘ real - life stories . ’\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-54ca2d78ce79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_pos_freq_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdep_relations_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minformation_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_morph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msame_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_punctuation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dep'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-effe2df1d428>\u001b[0m in \u001b[0;36mgenerate_pos_freq_sample\u001b[0;34m(nlp, sentence, dep_relations_dict, n_samples, limit_iterations, information_type, use_morph, same_freq, word_freq, skip_punctuation)\u001b[0m\n\u001b[1;32m    118\u001b[0m                     \u001b[0mindex\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                 \u001b[0mpossible_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdep_relations_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msame_freq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sentence = iterator_list[0][10]\n",
    "#sentence = 'This habit of uselessly wasting time, is the whole difficulty; and it is vastly important to you, and still more so to your children, that you should break this habit.'\n",
    "#print(sentence)\n",
    "#dep_relations_0 = read_yaml('/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/from-0_to-50.yml')\n",
    "#from-0_to-100.yml')\n",
    "spacy.displacy.render(nlp(sentence), style='dep')\n",
    "for sentence in iterator_list[0]:\n",
    "    print(sentence)\n",
    "    samples = generate_pos_freq_sample(nlp, sentence, dep_relations_0, n_samples=5, limit_iterations=3000, information_type='pos', use_morph=False, same_freq=False, word_freq=None, skip_punctuation=True)\n",
    "    spacy.displacy.render(nlp(samples[0]), style='dep')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outside\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('the dog runs outside')\n",
    "print(doc[3].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2883\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2887\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2892\n",
      "2893\n",
      "2894\n",
      "2895\n",
      "2896\n",
      "2897\n",
      "2898\n",
      "2899\n",
      "2900\n",
      "2901\n",
      "2902\n",
      "2903\n",
      "2904\n",
      "2905\n",
      "2906\n",
      "2907\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2911\n",
      "2912\n",
      "2913\n",
      "2914\n",
      "2915\n",
      "2916\n",
      "2917\n",
      "2918\n",
      "2919\n",
      "2920\n",
      "2921\n",
      "2922\n",
      "2923\n",
      "2924\n",
      "2925\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "2933\n",
      "2934\n",
      "2935\n",
      "2936\n",
      "2937\n",
      "2938\n",
      "2939\n",
      "2940\n",
      "2941\n",
      "2942\n",
      "2943\n",
      "2944\n",
      "2945\n",
      "2946\n",
      "2947\n",
      "2948\n",
      "2949\n",
      "2950\n",
      "2951\n",
      "2952\n",
      "2953\n",
      "2954\n",
      "2955\n",
      "2956\n",
      "2957\n",
      "2958\n",
      "2959\n",
      "2960\n",
      "2961\n",
      "2962\n",
      "2963\n",
      "2964\n",
      "2965\n",
      "2966\n",
      "2967\n",
      "2968\n",
      "2969\n",
      "2970\n",
      "2971\n",
      "2972\n",
      "2973\n",
      "2974\n",
      "2975\n",
      "2976\n",
      "2977\n",
      "2978\n",
      "2979\n",
      "2980\n",
      "2981\n",
      "2982\n",
      "2983\n",
      "2984\n",
      "2985\n",
      "2986\n",
      "2987\n",
      "2988\n",
      "2989\n",
      "2990\n",
      "2991\n",
      "2992\n",
      "2993\n",
      "2994\n",
      "2995\n",
      "2996\n",
      "2997\n",
      "2998\n",
      "2999\n",
      "3000\n",
      "3001\n",
      "3002\n",
      "3003\n",
      "3004\n",
      "3005\n",
      "3006\n",
      "3007\n",
      "3008\n",
      "3009\n",
      "3010\n",
      "3011\n",
      "3012\n",
      "3013\n",
      "3014\n",
      "3015\n",
      "3016\n",
      "3017\n",
      "3018\n",
      "3019\n",
      "3020\n",
      "3021\n",
      "3022\n",
      "3023\n",
      "3024\n",
      "3025\n",
      "3026\n",
      "3027\n",
      "3028\n",
      "3029\n",
      "3030\n",
      "3031\n",
      "3032\n",
      "3033\n",
      "3034\n",
      "3035\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "for i in range(len(train_batch)):\n",
    "    print(i)\n",
    "    train = train_batch[i]\n",
    "    train = open(train, 'r', encoding=\"utf8\", errors='ignore').read()\n",
    "    train = train.replace('\\n', ' ').replace(\"\\'\", ' ').replace('_', ' ').replace('--', ' - ').replace('. . .', '...')\n",
    "    train = ' '.join(train.split())\n",
    "\n",
    "#re.sub('\\[[^\\[]*\\]', '', train)\n",
    "#dep_relations_0 = get_dep_and_parsing_dicts(train, 0, '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/oldstuff/dependency_parsing/test.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lull',\n",
       " 'personate',\n",
       " 'head',\n",
       " 'warn',\n",
       " 'misreport',\n",
       " 'pierce',\n",
       " 'rend',\n",
       " 'pe',\n",
       " 'delay',\n",
       " 'accumulate',\n",
       " 'employ',\n",
       " 'bust',\n",
       " 'compensate',\n",
       " 'fondle',\n",
       " 'enact',\n",
       " 'tire',\n",
       " 'transplant',\n",
       " 'read',\n",
       " 'intimidate',\n",
       " 'house',\n",
       " 'retrench',\n",
       " 'channel',\n",
       " 'relax',\n",
       " 'join',\n",
       " 'do',\n",
       " 'assert',\n",
       " 'amass',\n",
       " 'send',\n",
       " 'withhold',\n",
       " 'develop',\n",
       " 'evacuate',\n",
       " 'stash',\n",
       " 'repel',\n",
       " 'part',\n",
       " 'cramp',\n",
       " 'distract',\n",
       " 'cancel',\n",
       " 'dishonor',\n",
       " 'refuse',\n",
       " 'truss',\n",
       " 'open',\n",
       " 'scold',\n",
       " 'live',\n",
       " 'exasperate',\n",
       " 'palliate',\n",
       " 'envenom',\n",
       " 'stifle',\n",
       " 'hit',\n",
       " 'consume',\n",
       " 'gladden',\n",
       " 'coal',\n",
       " 'adjudge',\n",
       " 'ensure',\n",
       " 'crash',\n",
       " 'cross',\n",
       " 'retain',\n",
       " 'divorce',\n",
       " 'unlock',\n",
       " 'rout',\n",
       " 'extenuate',\n",
       " 'transact',\n",
       " 'gasp',\n",
       " 'reintroduce',\n",
       " 'flavour',\n",
       " 'compare',\n",
       " 'harden',\n",
       " 'prosper',\n",
       " 'excuse',\n",
       " 'anger',\n",
       " 'swap',\n",
       " 'protrude',\n",
       " 'prefer',\n",
       " 'brace',\n",
       " 'abandon',\n",
       " 'exorcise',\n",
       " 'purge',\n",
       " 'push',\n",
       " 'object',\n",
       " 'befall',\n",
       " 'vent',\n",
       " 'haunt',\n",
       " 'forbid',\n",
       " 'beliebe',\n",
       " 'bird',\n",
       " 'preach',\n",
       " 'hand',\n",
       " 'embank',\n",
       " 'share',\n",
       " 'trip',\n",
       " 'clip',\n",
       " 'buff',\n",
       " 'smoke',\n",
       " 'savour',\n",
       " 'disengage',\n",
       " 'boss',\n",
       " 'fire',\n",
       " 'plaze',\n",
       " 'controvert',\n",
       " 'yonder',\n",
       " 'thrill',\n",
       " 'frame',\n",
       " 'dim',\n",
       " 'sod',\n",
       " 'heap',\n",
       " 'scent',\n",
       " 'colour',\n",
       " 'chase',\n",
       " 'inquire',\n",
       " 'strike',\n",
       " 'affront',\n",
       " 'shield',\n",
       " 'embalm',\n",
       " 'tack',\n",
       " 'grace',\n",
       " 'reflect',\n",
       " 'milk',\n",
       " 'movie',\n",
       " 'rue',\n",
       " 'pervert',\n",
       " 'fee',\n",
       " 'line',\n",
       " 'awe',\n",
       " 'debauch',\n",
       " 'snap',\n",
       " 'tinker',\n",
       " 'humanise',\n",
       " 'please',\n",
       " 'credit',\n",
       " 'arrange',\n",
       " 'repent',\n",
       " 'succeed',\n",
       " 'cure',\n",
       " 'weld',\n",
       " 'charge',\n",
       " 'rent',\n",
       " 'chloroform',\n",
       " 'embitter',\n",
       " 'stigmatise',\n",
       " 'estrange',\n",
       " 'unlace',\n",
       " 'grasp',\n",
       " 'corrode',\n",
       " 'plead',\n",
       " 'depict',\n",
       " 'fetch',\n",
       " 'blame',\n",
       " 'mystify',\n",
       " 'taste',\n",
       " 'impersonate',\n",
       " 'accelerate',\n",
       " 'decline',\n",
       " 'benefit',\n",
       " 'shoot',\n",
       " 'transmute',\n",
       " 'disgrace',\n",
       " 'identify',\n",
       " 'cheat',\n",
       " 'perfume',\n",
       " 'stain',\n",
       " 'induce',\n",
       " 'unpack',\n",
       " 'suspend',\n",
       " 'shadow',\n",
       " 'misunderstand',\n",
       " 'enlarge',\n",
       " 'animate',\n",
       " 'shout',\n",
       " 'criticise',\n",
       " 'revisit',\n",
       " 'refute',\n",
       " 'sear',\n",
       " 'undo',\n",
       " 'pound',\n",
       " 'link',\n",
       " 'swallow',\n",
       " 'reprehend',\n",
       " 'melt',\n",
       " 'starve',\n",
       " 'destroy',\n",
       " 'selfish',\n",
       " 'frisk',\n",
       " 'introduis',\n",
       " 'mitigate',\n",
       " 'scalp',\n",
       " 'post',\n",
       " 'uplift',\n",
       " 'vanquish',\n",
       " 'tie',\n",
       " 'draw',\n",
       " 'respect',\n",
       " 'desert',\n",
       " 'mate',\n",
       " 'echo',\n",
       " 'authorize',\n",
       " 'picture',\n",
       " 'telephone',\n",
       " 'bide',\n",
       " 'mature',\n",
       " 'paunch',\n",
       " 'skip',\n",
       " 'bathe',\n",
       " 'humiliate',\n",
       " 'terrorize',\n",
       " 'affect',\n",
       " 'sheath',\n",
       " 'alleviate',\n",
       " 'conquest',\n",
       " 'roast',\n",
       " 'shade',\n",
       " 'know',\n",
       " 'numb',\n",
       " 'capture',\n",
       " 'harm',\n",
       " 'murder',\n",
       " 'stem',\n",
       " 'scribble',\n",
       " 'await',\n",
       " 'remark',\n",
       " 'qualify',\n",
       " 'harvest',\n",
       " 'recognise',\n",
       " 'reform',\n",
       " 'complicate',\n",
       " 'move',\n",
       " 'defraud',\n",
       " 'breast',\n",
       " 'actuate',\n",
       " 'educate',\n",
       " 'blast',\n",
       " 'medicine',\n",
       " 'appoint',\n",
       " 'embellish',\n",
       " 'rock',\n",
       " 'squench',\n",
       " 'batter',\n",
       " 'shun',\n",
       " 'decide',\n",
       " 'expose',\n",
       " 'plot',\n",
       " 'remove',\n",
       " 'rally',\n",
       " 'withstand',\n",
       " 'care',\n",
       " 'oblige',\n",
       " 'corrupt',\n",
       " 'outstep',\n",
       " 'spread',\n",
       " 'hold',\n",
       " 'measure',\n",
       " 'hallow',\n",
       " 'receive',\n",
       " 'avoid',\n",
       " 'allure',\n",
       " 'clasp',\n",
       " 'snatch',\n",
       " 'incapacitate',\n",
       " 'concentrate',\n",
       " 'coach',\n",
       " 'absorb',\n",
       " 'lack',\n",
       " 'dominate',\n",
       " 'engage',\n",
       " 'overcome',\n",
       " 'cock',\n",
       " 'scandalise',\n",
       " 'mention',\n",
       " 'love',\n",
       " 'adjust',\n",
       " 'perplex',\n",
       " 'persuade',\n",
       " 'liberate',\n",
       " 'cope',\n",
       " 'butcher',\n",
       " 'order',\n",
       " 'bombard',\n",
       " 'serve',\n",
       " 'thwart',\n",
       " 'entangle',\n",
       " 'dip',\n",
       " 'disqualify',\n",
       " 'condone',\n",
       " 'disregard',\n",
       " 'like',\n",
       " 'possess',\n",
       " 'reproduce',\n",
       " 'blaze',\n",
       " 'travel',\n",
       " 'appal',\n",
       " 'announce',\n",
       " 'impede',\n",
       " 'cut',\n",
       " 'warp',\n",
       " 'kind',\n",
       " 'adorn',\n",
       " 'print',\n",
       " 'drain',\n",
       " 'hurry',\n",
       " 'betray',\n",
       " 'perform',\n",
       " 'illustrate',\n",
       " 'fright',\n",
       " 'design',\n",
       " 'ascribe',\n",
       " 'pinion',\n",
       " 'stress',\n",
       " 'merit',\n",
       " 'recommence',\n",
       " 'beg',\n",
       " 'pleasure',\n",
       " 'rivet',\n",
       " 'explode',\n",
       " 'marshal',\n",
       " 'administer',\n",
       " 'relish',\n",
       " 'import',\n",
       " 'sling',\n",
       " 'baptize',\n",
       " 'disclose',\n",
       " 'grant',\n",
       " 'wreck',\n",
       " 'substitute',\n",
       " 'precede',\n",
       " 'balance',\n",
       " 'frustrate',\n",
       " 'redress',\n",
       " 'put',\n",
       " 'interweave',\n",
       " 'come',\n",
       " 'dissect',\n",
       " 'dirty',\n",
       " 'port',\n",
       " 'bepraise',\n",
       " 'film',\n",
       " 'undertake',\n",
       " 'prophesy',\n",
       " 'astound',\n",
       " 'soften',\n",
       " 'meditate',\n",
       " 'scatter',\n",
       " 'snare',\n",
       " 'circumvent',\n",
       " 'wive',\n",
       " 'balk',\n",
       " 'rake',\n",
       " 'bewail',\n",
       " 'foe',\n",
       " 'prop',\n",
       " 'befog',\n",
       " 'ransack',\n",
       " 'take',\n",
       " 'inspect',\n",
       " 'sober',\n",
       " 'rub',\n",
       " 'inspire',\n",
       " 'swamp',\n",
       " 'hinder',\n",
       " 'blur',\n",
       " 'proffer',\n",
       " 'eject',\n",
       " 'partake',\n",
       " 'square',\n",
       " 'perpetuate',\n",
       " 'wire',\n",
       " 'insult',\n",
       " 'enquire',\n",
       " 'improve',\n",
       " 'jostle',\n",
       " 'humor',\n",
       " 'carve',\n",
       " 'prove',\n",
       " 'sign',\n",
       " 'verify',\n",
       " 'recoup',\n",
       " 'repair',\n",
       " 'bound',\n",
       " 'dance',\n",
       " 'confer',\n",
       " 'array',\n",
       " 'interpret',\n",
       " 'excel',\n",
       " 'resemble',\n",
       " 'monie',\n",
       " 'skim',\n",
       " 'contest',\n",
       " 'brook',\n",
       " 'further',\n",
       " 'steady',\n",
       " 'visit',\n",
       " 'require',\n",
       " 'suck',\n",
       " 'procrastinate',\n",
       " 'reduce',\n",
       " 'trap',\n",
       " 'macedon.--celebrates',\n",
       " 'lette',\n",
       " 'circle',\n",
       " 'form',\n",
       " 'contrive',\n",
       " 'reinstall',\n",
       " 'wean',\n",
       " 'aid',\n",
       " 'swell',\n",
       " 'revolutionise',\n",
       " 'figure',\n",
       " 'mean',\n",
       " 'render',\n",
       " 'tease',\n",
       " 'devise',\n",
       " 'thread',\n",
       " 'accomplish',\n",
       " 'elect',\n",
       " 'ensnare',\n",
       " 'discourage',\n",
       " 'hasten',\n",
       " 'rumple',\n",
       " 'womankind',\n",
       " 'hoist',\n",
       " 'disturb',\n",
       " 'tepid',\n",
       " 'forgo',\n",
       " 'launch',\n",
       " 'interpose',\n",
       " 'quell',\n",
       " 'rekindle',\n",
       " 'subsist',\n",
       " 'eschew',\n",
       " 'salt',\n",
       " 'soothe',\n",
       " 'besmirch',\n",
       " 'bully',\n",
       " 'foreshadow',\n",
       " 'discern',\n",
       " 'grandeur',\n",
       " 'discharge',\n",
       " 'distribute',\n",
       " 'dazzle',\n",
       " 'consign',\n",
       " 'evince',\n",
       " 'bridle',\n",
       " 'boil',\n",
       " 'repeople',\n",
       " 'rouse',\n",
       " 'digest',\n",
       " 'reassert',\n",
       " 'parallel',\n",
       " 'tempt',\n",
       " 'frighten',\n",
       " 'strain',\n",
       " 'ring',\n",
       " 'unarm',\n",
       " 'shatter',\n",
       " 'row',\n",
       " 'peruse',\n",
       " 'avow',\n",
       " 'retire',\n",
       " 'translate',\n",
       " 'snub',\n",
       " 'subvert',\n",
       " 'pacify',\n",
       " 'maraud',\n",
       " 'startle',\n",
       " 'learne',\n",
       " 'reinstate',\n",
       " 'whet',\n",
       " 'transmit',\n",
       " 'outdistance',\n",
       " 'regard',\n",
       " 'quench',\n",
       " 'happen',\n",
       " 'submit',\n",
       " 'pawn',\n",
       " 'prize',\n",
       " 'brazen',\n",
       " 'admit',\n",
       " 'screw',\n",
       " 'breathe',\n",
       " 'call',\n",
       " 'bemoan',\n",
       " 'affirm',\n",
       " 'choke',\n",
       " 'court',\n",
       " 'thin',\n",
       " 'rebuke',\n",
       " 'expiate',\n",
       " 'damage',\n",
       " 'advertise',\n",
       " 'limit',\n",
       " 'replace',\n",
       " 'separate',\n",
       " 'disenchant',\n",
       " 'town',\n",
       " 'slit',\n",
       " 'get',\n",
       " 'stretch',\n",
       " 'condense',\n",
       " 'tapestry',\n",
       " 'scripture',\n",
       " 'usurp',\n",
       " 'herd',\n",
       " 'fear',\n",
       " 'breed',\n",
       " 'elude',\n",
       " 'expel',\n",
       " 'fight',\n",
       " 'cook',\n",
       " 'obstruct',\n",
       " 'forego',\n",
       " 'shirk',\n",
       " 'lubricate',\n",
       " 'afford',\n",
       " 'forge',\n",
       " 'impel',\n",
       " 'endow',\n",
       " 'chuse',\n",
       " 'wipe',\n",
       " 'cover',\n",
       " 'surmount',\n",
       " 'strip',\n",
       " 'wake',\n",
       " 'outrage',\n",
       " 'offend',\n",
       " 'flesh',\n",
       " 'soak',\n",
       " 'seat',\n",
       " 'bake',\n",
       " 'dispute',\n",
       " 'justify',\n",
       " 'envy',\n",
       " 'sec',\n",
       " 'override',\n",
       " 'clean',\n",
       " 'jeopardize',\n",
       " 'soil',\n",
       " 'pardon',\n",
       " 'pet',\n",
       " 'familiarize',\n",
       " 'jerk',\n",
       " 'string',\n",
       " 'anoint',\n",
       " 'oppress',\n",
       " 'prescribe',\n",
       " 'arm',\n",
       " 'scrub',\n",
       " 'produce',\n",
       " 'answer',\n",
       " 'penetrate',\n",
       " 'exercise',\n",
       " 'christen',\n",
       " 'work',\n",
       " 'thrust',\n",
       " 'smell',\n",
       " 'ask',\n",
       " 'occasion',\n",
       " 'disperse',\n",
       " 'undergo',\n",
       " 'blow',\n",
       " 'revise',\n",
       " 'conclude',\n",
       " 'accuse',\n",
       " 'honor',\n",
       " 'surprise',\n",
       " 'forget',\n",
       " 'allay',\n",
       " 'unclose',\n",
       " 'chance',\n",
       " 'lessen',\n",
       " 'second',\n",
       " 'sheer',\n",
       " 'uphold',\n",
       " 'train',\n",
       " 'ravish',\n",
       " 'ride',\n",
       " 'complete',\n",
       " 'rescind',\n",
       " 'befriend',\n",
       " 'inculcate',\n",
       " 'torment',\n",
       " 'revolutionize',\n",
       " 'release',\n",
       " 'hev',\n",
       " 'repulse',\n",
       " 'doubt',\n",
       " 'report',\n",
       " 'risk',\n",
       " 'signalize',\n",
       " 'persecute',\n",
       " 'concoct',\n",
       " 'mix',\n",
       " 'husband',\n",
       " 'forecast',\n",
       " 'promotion',\n",
       " 'enlighten',\n",
       " 'damp',\n",
       " 'deny',\n",
       " 'shake',\n",
       " 'shock',\n",
       " 'temptation',\n",
       " 'seize',\n",
       " 'inhabit',\n",
       " 'elp',\n",
       " 'test',\n",
       " 'imitate',\n",
       " 'relate',\n",
       " 'kick',\n",
       " 'blink',\n",
       " 'reason',\n",
       " 'calm',\n",
       " 'fracture',\n",
       " 'continue',\n",
       " 'undeceive',\n",
       " 'invade',\n",
       " 'govern',\n",
       " 'act',\n",
       " 'guess',\n",
       " 'poison',\n",
       " 'interfere',\n",
       " 'misapply',\n",
       " 'embarrass',\n",
       " 'reenter',\n",
       " 'squire',\n",
       " 'repurchase',\n",
       " 'ameliorate',\n",
       " 'extinguish',\n",
       " 'lecture',\n",
       " 'overthrow',\n",
       " 'blockade',\n",
       " 'estimate',\n",
       " 'cleave',\n",
       " 'horsewhip',\n",
       " 'indemnify',\n",
       " 'cement',\n",
       " 'marry',\n",
       " 'summon',\n",
       " 'hope',\n",
       " 'favour',\n",
       " 'steer',\n",
       " 'enchant',\n",
       " 'surprize',\n",
       " 'toss',\n",
       " 'sprain',\n",
       " 'fend',\n",
       " 'frescoe',\n",
       " 'unnerve',\n",
       " 'chill',\n",
       " 'edify',\n",
       " 'discuss',\n",
       " 'compose',\n",
       " 'overhaul',\n",
       " 'necessitate',\n",
       " 'pronounce',\n",
       " 'absolve',\n",
       " 'explore',\n",
       " 'look',\n",
       " 'grip',\n",
       " 'say',\n",
       " 'abhor',\n",
       " 'tickle',\n",
       " 'organize',\n",
       " 'expiscate',\n",
       " 'quiet',\n",
       " 'elevate',\n",
       " 'dis',\n",
       " 'identity',\n",
       " 'touch',\n",
       " 'jam',\n",
       " 'hoold',\n",
       " 'die',\n",
       " 'express',\n",
       " 'suit',\n",
       " 'embark',\n",
       " 'oust',\n",
       " 'spite',\n",
       " 'lub',\n",
       " 'annihilate',\n",
       " 'ornament',\n",
       " 'retract',\n",
       " 'maintain',\n",
       " 'curb',\n",
       " 'hem',\n",
       " 'unmask',\n",
       " 'gall',\n",
       " 'score',\n",
       " 'dare',\n",
       " 'augment',\n",
       " 'acquit',\n",
       " 'advocate',\n",
       " 'pattern',\n",
       " 'don',\n",
       " 'intimate',\n",
       " 'exert',\n",
       " 'belie',\n",
       " 'disgust',\n",
       " 'vary',\n",
       " 'encircle',\n",
       " 'cow',\n",
       " 'seek',\n",
       " 'reconcile',\n",
       " 'restrict',\n",
       " 'bell',\n",
       " 'fall',\n",
       " 'stir',\n",
       " 'captivate',\n",
       " 'dissatisfy',\n",
       " 'cheer',\n",
       " 'encourage',\n",
       " 'traverse',\n",
       " 'arrest',\n",
       " 'ransom',\n",
       " 'forgit',\n",
       " 'scale',\n",
       " 'stroke',\n",
       " 'sentence',\n",
       " 'uproot',\n",
       " 'pay',\n",
       " 'scuttle',\n",
       " 'entice',\n",
       " 'patronise',\n",
       " 'tell',\n",
       " 'resist',\n",
       " 'pole',\n",
       " 'undermine',\n",
       " 'acquire',\n",
       " 'forestall',\n",
       " 'degrade',\n",
       " 'abridge',\n",
       " 'beach',\n",
       " 'uncover',\n",
       " 'bridge',\n",
       " 'gar',\n",
       " 'knock',\n",
       " 'inspan',\n",
       " 'spear',\n",
       " 'exceed',\n",
       " 'recruit',\n",
       " 'awaken',\n",
       " 'understand',\n",
       " 'deter',\n",
       " 'fix',\n",
       " 'consecrate',\n",
       " 'tow',\n",
       " 'redeem',\n",
       " 'delude',\n",
       " 'brighten',\n",
       " 'scour',\n",
       " 'budge',\n",
       " 'intoxicate',\n",
       " 'straighten',\n",
       " 'pervade',\n",
       " 'remedy',\n",
       " 'endorse',\n",
       " 'welcome',\n",
       " 'exclude',\n",
       " 'dodge',\n",
       " 'perpetrate',\n",
       " 'convulse',\n",
       " 'mire',\n",
       " 'collect',\n",
       " 'prejudice',\n",
       " 'quit',\n",
       " 'boom',\n",
       " 'rupture',\n",
       " 'fatigue',\n",
       " 'explicate',\n",
       " 'repress',\n",
       " 'convict',\n",
       " 'discountenance',\n",
       " 'emulate',\n",
       " 'solve',\n",
       " 'subsidise',\n",
       " 'dissociate',\n",
       " 'preclude',\n",
       " 'debar',\n",
       " 'denote',\n",
       " 'control',\n",
       " 'go',\n",
       " 'hire',\n",
       " 'fatten',\n",
       " 'efface',\n",
       " 'dam',\n",
       " 'comprehend',\n",
       " 'escape',\n",
       " 'stop',\n",
       " 'repay',\n",
       " 'attract',\n",
       " 'tap',\n",
       " 'unravel',\n",
       " 'pen',\n",
       " 'encompass',\n",
       " 'kindle',\n",
       " 'discard',\n",
       " 'clinch',\n",
       " 'present',\n",
       " 'establish',\n",
       " 'sound',\n",
       " 'incipient',\n",
       " 'exculpate',\n",
       " 'face',\n",
       " 'mourn',\n",
       " 'spin',\n",
       " 'practise',\n",
       " 'imperil',\n",
       " 'attach',\n",
       " 'lie',\n",
       " 'brave',\n",
       " 'encumber',\n",
       " 'reveal',\n",
       " 'bag',\n",
       " 'embody',\n",
       " 'rustle',\n",
       " 'introduce',\n",
       " 'cheapen',\n",
       " 'provoke',\n",
       " 'walk',\n",
       " 'insure',\n",
       " 'devote',\n",
       " 'convene',\n",
       " 'salve',\n",
       " 'swear',\n",
       " 'sobriety',\n",
       " 'shell',\n",
       " 'alienate',\n",
       " 'smash',\n",
       " 'hearten',\n",
       " 'record',\n",
       " 'concern',\n",
       " 'irrigate',\n",
       " 'ground',\n",
       " 'button',\n",
       " 'intensify',\n",
       " 'subscribe',\n",
       " 'weaken',\n",
       " 'connote',\n",
       " 'fish',\n",
       " 'ford',\n",
       " 'distress',\n",
       " 'hate',\n",
       " 'notice',\n",
       " 'challenge',\n",
       " 'infect',\n",
       " 'detain',\n",
       " 'counterbalance',\n",
       " 'impart',\n",
       " 'cause',\n",
       " 'quieten',\n",
       " 'pinch',\n",
       " 'disguise',\n",
       " 'board',\n",
       " 'puff',\n",
       " 'console',\n",
       " 'relapse',\n",
       " 'loosen',\n",
       " 'dirge',\n",
       " 'stock',\n",
       " 'comb',\n",
       " 'unveil',\n",
       " 'aunt',\n",
       " 'spot',\n",
       " 'hender',\n",
       " 'tear',\n",
       " 'undervalue',\n",
       " 'sarve',\n",
       " 'pull',\n",
       " 'neutralize',\n",
       " 'reconnoiter',\n",
       " 'slay',\n",
       " 'reap',\n",
       " 'weary',\n",
       " 'construct',\n",
       " 'enable',\n",
       " 'execute',\n",
       " 'omit',\n",
       " 'ascertain',\n",
       " 'clear',\n",
       " 'bias',\n",
       " 'slug',\n",
       " 'guard',\n",
       " 'issue',\n",
       " 'reassure',\n",
       " 'catch',\n",
       " 'color',\n",
       " 'shroud',\n",
       " 'pump',\n",
       " 'untangle',\n",
       " 'warrant',\n",
       " 'feed',\n",
       " 'obviate',\n",
       " 'shut',\n",
       " 'foresee',\n",
       " 'paint',\n",
       " 'dissolve',\n",
       " 'reverse',\n",
       " 'sell',\n",
       " 'fortify',\n",
       " 'conceive',\n",
       " 'mend',\n",
       " 'foul',\n",
       " 'propound',\n",
       " 'shoulder',\n",
       " 'base',\n",
       " 'parade',\n",
       " 'impute',\n",
       " 'cap',\n",
       " 'prod',\n",
       " 'pitch',\n",
       " 'censure',\n",
       " 'tame',\n",
       " 'break',\n",
       " 'throw',\n",
       " 'offset',\n",
       " 'advance',\n",
       " 'winter',\n",
       " 'reckon',\n",
       " 'adore',\n",
       " 'empty',\n",
       " 'reprobate',\n",
       " 'recall',\n",
       " 'rewrite',\n",
       " 'seal',\n",
       " 'demonstrate',\n",
       " 'damn',\n",
       " 'spell',\n",
       " 'weather',\n",
       " 'sustain',\n",
       " 'obscure',\n",
       " 'behold',\n",
       " 'divide',\n",
       " 'deduce',\n",
       " 'assemble',\n",
       " 'infer',\n",
       " 'average',\n",
       " 'facilitate',\n",
       " 'overawe',\n",
       " 'furl',\n",
       " 'defray',\n",
       " 'forgive',\n",
       " 'grow',\n",
       " 'belabour',\n",
       " 'replenish',\n",
       " 'tranquillize',\n",
       " 'humble',\n",
       " 'collar',\n",
       " 'pamper',\n",
       " 'combat',\n",
       " 'bestow',\n",
       " 'better',\n",
       " 'shew',\n",
       " 'woo',\n",
       " 'perfect',\n",
       " 'chaperon',\n",
       " 'refill',\n",
       " 'suffer',\n",
       " 'water',\n",
       " 'range',\n",
       " 'close',\n",
       " 'fry',\n",
       " 'perturb',\n",
       " 'float',\n",
       " 'besiege',\n",
       " 'inculpate',\n",
       " 'climb',\n",
       " 'transport',\n",
       " 'allow',\n",
       " 'presume',\n",
       " 'exhibit',\n",
       " 'tender',\n",
       " 'connect',\n",
       " 'mistake',\n",
       " 'quicken',\n",
       " 'equal',\n",
       " 'despise',\n",
       " 'entreat',\n",
       " 'state',\n",
       " 'hamper',\n",
       " 'nominate',\n",
       " 'follow',\n",
       " 'attend',\n",
       " 'brief',\n",
       " 'assign',\n",
       " 'equalize',\n",
       " 'decoy',\n",
       " 'devour',\n",
       " 'debate',\n",
       " 'propagate',\n",
       " 'cry',\n",
       " 'reorganise',\n",
       " 'consider',\n",
       " 'shed',\n",
       " 'confiscate',\n",
       " 'hoard',\n",
       " 'swindle',\n",
       " 'convince',\n",
       " 'retrieve',\n",
       " 'wear',\n",
       " 'bless',\n",
       " 'secrete',\n",
       " 'esteem',\n",
       " 'attain',\n",
       " 'elaborate',\n",
       " 'eradicate',\n",
       " 'top',\n",
       " ...]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dep_relations['56b9484a739b3239839c49aba132b8e8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(nlp, sentence, dep_relations_dict, n_samples=50, limit_iterations=3000, key_type='tag', use_morph=True, use_children=True):\n",
    "    \"\"\"Generate sentence with same POS, dependecy parsing and syntaxic tree.\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    root = [token for token in doc if token.head == token][0]\n",
    "    ref_tree_representation = doc_to_tree(doc, root)\n",
    "    # Iterating to generate samples\n",
    "    i=0\n",
    "    count=0\n",
    "    new_samples = []\n",
    "    while (i < n_samples) and (count < limit_iterations):\n",
    "        sample = []\n",
    "        for token in doc:\n",
    "            if key_type=='dep':\n",
    "                if use_children:\n",
    "                    keys = []\n",
    "                    all_children = [token.dep_]\n",
    "                    for child in token.children:\n",
    "                        keys.append(str([token.dep_, child.dep_]))\n",
    "                        all_children.append(child.dep_)\n",
    "                    keys.append(str(all_children))\n",
    "                else:\n",
    "                    keys = [str(token.dep_)]\n",
    "            # POS\n",
    "            elif key_type=='pos':\n",
    "                if use_children:\n",
    "                    keys = []\n",
    "                    all_children = [token.head.pos_, token.pos_]\n",
    "                    for child in token.children:\n",
    "                        keys.append(str([token.head.pos_, token.pos_, child.pos_]))\n",
    "                        all_children.append(child.pos_)\n",
    "                    keys.append(str(all_children))\n",
    "                else:\n",
    "                    keys = [str([token.head.pos_, token.pos_])]\n",
    "            # TAG\n",
    "            elif key_type=='tag':\n",
    "                if use_children:\n",
    "                    keys = []\n",
    "                    all_children = [token.head.tag_, token.tag_]\n",
    "                    for child in token.children:\n",
    "                        keys.append(str([token.head.tag_, token.tag_, child.tag_]))\n",
    "                        all_children.append(child.tag_)\n",
    "                    keys.append(str(all_children))\n",
    "                else:\n",
    "                    keys = [str([token.head.tag_, token.tag_])]\n",
    "            final_keys = []\n",
    "            for key in keys:\n",
    "                final_keys.append(key + str(token.morph))\n",
    "            for index, key in enumerate(final_keys):\n",
    "                final_keys[index] = str(uuid.uuid3(uuid.NAMESPACE_DNS, str(key)).hex)\n",
    "            index = len(final_keys)-1\n",
    "            while (final_keys[index] not in dep_relations_dict.keys()) and (index>=0):\n",
    "                index -= 1\n",
    "            if index<0:\n",
    "                raise KeyError\n",
    "            possible_words = dep_relations_dict[final_keys[index]]\n",
    "            tmp = uniform(possible_words)\n",
    "            print(token.text, len(possible_words), tmp)\n",
    "            sample.append(tmp)\n",
    "        new_sentence = ' '.join(sample)\n",
    "        doc_sample = nlp(' '.join(sample))\n",
    "        root = [token for token in doc_sample if token.head == token][0]\n",
    "        tree_representation = doc_to_tree(doc_sample, root)\n",
    "        if tree_representation==ref_tree_representation:\n",
    "            i+=1\n",
    "            new_samples.append(new_sentence)\n",
    "        count+=1\n",
    "    print('done in ', count, ' iterations.')\n",
    "    return new_samples\n",
    "\n",
    "\n",
    "def update_dependency_dict(token, dep_relations={}, key_type='dep', use_children=True):\n",
    "    \"\"\"Update a dictionary where keys are dependency relationships.\n",
    "    And values are list of possible words.\n",
    "    \"\"\"\n",
    "    word = token.text.lower()\n",
    "    # determining type of key\n",
    "    # DEP\n",
    "    if key_type=='dep':\n",
    "        if use_children:\n",
    "            keys = []\n",
    "            all_children = [token.dep_]\n",
    "            for child in token.children:\n",
    "                keys.append(str([token.dep_, child.dep_]))\n",
    "                all_children.append(child.dep_)\n",
    "            keys.append(str(all_children))\n",
    "        else:\n",
    "            keys = [str(token.dep_)]\n",
    "    # POS\n",
    "    elif key_type=='pos':\n",
    "        if use_children:\n",
    "            keys = []\n",
    "            all_children = [token.head.pos_, token.pos_]\n",
    "            for child in token.children:\n",
    "                keys.append(str([token.head.pos_, token.pos_, child.pos_]))\n",
    "                all_children.append(child.pos_)\n",
    "            keys.append(str(all_children))\n",
    "        else:\n",
    "            keys = [str([token.head.pos_, token.pos_])]\n",
    "    # TAG\n",
    "    elif key_type=='tag':\n",
    "        if use_children:\n",
    "            keys = []\n",
    "            all_children = [token.head.tag_, token.tag_]\n",
    "            for child in token.children:\n",
    "                keys.append(str([token.head.tag_, token.tag_, child.tag_]))\n",
    "                all_children.append(child.tag_)\n",
    "            keys.append(str(all_children))\n",
    "        else:\n",
    "            keys = [str([token.head.tag_, token.tag_])]\n",
    "    final_keys = []\n",
    "    for key in keys:\n",
    "        final_keys.append(key + str(token.morph))\n",
    "    for index, key in enumerate(final_keys):\n",
    "        final_keys[index] = str(uuid.uuid3(uuid.NAMESPACE_DNS, str(key)).hex)\n",
    "    # updating the dictionary\n",
    "    for key in final_keys:\n",
    "        if key in dep_relations.keys():\n",
    "            if word not in dep_relations[key]:\n",
    "                dep_relations[key].append(word)\n",
    "        else:\n",
    "            dep_relations[key] = [word]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Number=Sing|PronType=Dem det DT DET []   \n",
      "habit Number=Sing nsubj NN NOUN ['DT', 'IN']   \n",
      "of  prep IN ADP ['VBG']   \n",
      "uselessly  advmod RB ADV []   \n",
      "wasting Aspect=Prog|Tense=Pres|VerbForm=Part pcomp VBG VERB ['RB', 'NN']   \n",
      "time Number=Sing dobj NN NOUN []   \n",
      ", PunctType=Comm punct , PUNCT []   \n",
      "is Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin ROOT VBZ AUX ['NN', ',', 'NN', ':', 'CC', 'VBZ']   \n",
      "the Definite=Def|PronType=Art det DT DET []   \n",
      "whole Degree=Pos amod JJ ADJ []   \n",
      "difficulty Number=Sing attr NN NOUN ['DT', 'JJ']   \n",
      ";  punct : PUNCT []   \n",
      "and ConjType=Cmp cc CC CCONJ []   \n",
      "it Case=Nom|Gender=Neut|Number=Sing|Person=3|PronType=Prs nsubj PRP PRON []   \n",
      "is Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin conj VBZ VERB ['PRP', 'JJ', ',', 'CC', 'IN', ',', 'VB', '.']   \n",
      "vastly  advmod RB ADV []   \n",
      "important Degree=Pos acomp JJ ADJ ['RB', 'IN']   \n",
      "to  prep IN ADP ['PRP']   \n",
      "you Case=Acc|Person=2|PronType=Prs pobj PRP PRON []   \n",
      ", PunctType=Comm punct , PUNCT []   \n",
      "and ConjType=Cmp cc CC CCONJ []   \n",
      "still  advmod RB ADV []   \n",
      "more Degree=Cmp advmod RBR ADV []   \n",
      "so  advmod RB ADV ['RB', 'RBR']   \n",
      "to  prep IN ADP ['RB', 'NNS']   \n",
      "your Person=2|Poss=Yes|PronType=Prs poss PRP$ PRON []   \n",
      "children Number=Plur pobj NNS NOUN ['PRP$']   \n",
      ", PunctType=Comm punct , PUNCT []   \n",
      "that  mark IN SCONJ []   \n",
      "you Case=Nom|Person=2|PronType=Prs nsubj PRP PRON []   \n",
      "should VerbForm=Fin aux MD AUX []   \n",
      "break VerbForm=Inf ccomp VB VERB ['IN', 'PRP', 'MD', 'NN']   \n",
      "this Number=Sing|PronType=Dem det DT DET []   \n",
      "habit Number=Sing dobj NN NOUN ['DT']   \n",
      ". PunctType=Peri punct . PUNCT []   \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"cab4bc935a08475988727a4fe5c27f2f-0\" class=\"displacy\" width=\"5300\" height=\"837.0\" direction=\"ltr\" style=\"max-width: none; height: 837.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">habit</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">uselessly</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">wasting</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">time,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">whole</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">difficulty;</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">it</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">vastly</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">important</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">you,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">still</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">more</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">so</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">your</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">children,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\">that</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4425\">you</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4425\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4600\">should</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4600\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4775\">break</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4775\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4950\">this</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4950\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"747.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5125\">habit.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5125\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-0\" stroke-width=\"2px\" d=\"M70,702.0 C70,614.5 190.0,614.5 190.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,704.0 L62,692.0 78,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-1\" stroke-width=\"2px\" d=\"M245,702.0 C245,264.5 1085.0,264.5 1085.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,704.0 L237,692.0 253,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-2\" stroke-width=\"2px\" d=\"M245,702.0 C245,614.5 365.0,614.5 365.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M365.0,704.0 L373.0,692.0 357.0,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-3\" stroke-width=\"2px\" d=\"M595,702.0 C595,614.5 715.0,614.5 715.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,704.0 L587,692.0 603,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-4\" stroke-width=\"2px\" d=\"M420,702.0 C420,527.0 720.0,527.0 720.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M720.0,704.0 L728.0,692.0 712.0,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-5\" stroke-width=\"2px\" d=\"M770,702.0 C770,614.5 890.0,614.5 890.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M890.0,704.0 L898.0,692.0 882.0,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-6\" stroke-width=\"2px\" d=\"M1295,702.0 C1295,527.0 1595.0,527.0 1595.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,704.0 L1287,692.0 1303,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-7\" stroke-width=\"2px\" d=\"M1470,702.0 C1470,614.5 1590.0,614.5 1590.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,704.0 L1462,692.0 1478,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-8\" stroke-width=\"2px\" d=\"M1120,702.0 C1120,439.5 1600.0,439.5 1600.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1600.0,704.0 L1608.0,692.0 1592.0,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-9\" stroke-width=\"2px\" d=\"M1120,702.0 C1120,352.0 1780.0,352.0 1780.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1780.0,704.0 L1788.0,692.0 1772.0,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-10\" stroke-width=\"2px\" d=\"M1995,702.0 C1995,614.5 2115.0,614.5 2115.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1995,704.0 L1987,692.0 2003,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-11\" stroke-width=\"2px\" d=\"M1120,702.0 C1120,177.0 2140.0,177.0 2140.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2140.0,704.0 L2148.0,692.0 2132.0,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-12\" stroke-width=\"2px\" d=\"M2345,702.0 C2345,614.5 2465.0,614.5 2465.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2345,704.0 L2337,692.0 2353,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-13\" stroke-width=\"2px\" d=\"M2170,702.0 C2170,527.0 2470.0,527.0 2470.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2470.0,704.0 L2478.0,692.0 2462.0,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-14\" stroke-width=\"2px\" d=\"M2520,702.0 C2520,614.5 2640.0,614.5 2640.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2640.0,704.0 L2648.0,692.0 2632.0,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-15\" stroke-width=\"2px\" d=\"M2695,702.0 C2695,614.5 2815.0,614.5 2815.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2815.0,704.0 L2823.0,692.0 2807.0,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-16\" stroke-width=\"2px\" d=\"M2170,702.0 C2170,264.5 3010.0,264.5 3010.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3010.0,704.0 L3018.0,692.0 3002.0,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-17\" stroke-width=\"2px\" d=\"M3220,702.0 C3220,527.0 3520.0,527.0 3520.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3220,704.0 L3212,692.0 3228,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-18\" stroke-width=\"2px\" d=\"M3395,702.0 C3395,614.5 3515.0,614.5 3515.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3395,704.0 L3387,692.0 3403,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-19\" stroke-width=\"2px\" d=\"M3570,702.0 C3570,614.5 3690.0,614.5 3690.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3570,704.0 L3562,692.0 3578,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-20\" stroke-width=\"2px\" d=\"M2170,702.0 C2170,89.5 3720.0,89.5 3720.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3720.0,704.0 L3728.0,692.0 3712.0,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-21\" stroke-width=\"2px\" d=\"M3920,702.0 C3920,614.5 4040.0,614.5 4040.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3920,704.0 L3912,692.0 3928,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-22\" stroke-width=\"2px\" d=\"M3745,702.0 C3745,527.0 4045.0,527.0 4045.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4045.0,704.0 L4053.0,692.0 4037.0,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-23\" stroke-width=\"2px\" d=\"M4270,702.0 C4270,439.5 4750.0,439.5 4750.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4270,704.0 L4262,692.0 4278,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-24\" stroke-width=\"2px\" d=\"M4445,702.0 C4445,527.0 4745.0,527.0 4745.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4445,704.0 L4437,692.0 4453,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-25\" stroke-width=\"2px\" d=\"M4620,702.0 C4620,614.5 4740.0,614.5 4740.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-25\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4620,704.0 L4612,692.0 4628,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-26\" stroke-width=\"2px\" d=\"M2170,702.0 C2170,2.0 4775.0,2.0 4775.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-26\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4775.0,704.0 L4783.0,692.0 4767.0,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-27\" stroke-width=\"2px\" d=\"M4970,702.0 C4970,614.5 5090.0,614.5 5090.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-27\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4970,704.0 L4962,692.0 4978,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cab4bc935a08475988727a4fe5c27f2f-0-28\" stroke-width=\"2px\" d=\"M4795,702.0 C4795,527.0 5095.0,527.0 5095.0,702.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cab4bc935a08475988727a4fe5c27f2f-0-28\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5095.0,704.0 L5103.0,692.0 5087.0,692.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(sentence)\n",
    "for token in doc:\n",
    "    print(token.text, token.morph, token.dep_, token.tag_, token.pos_, [item.tag_ for item in token.children], token.ent_iob_, token.ent_type_, token.ent_kb_id_, )\n",
    "spacy.displacy.render(doc, style='dep')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - ['VBN', 'VBN', 'RB', ',', 'NNPS', 'VBD', 'NNS', '.']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "1 - ['VBZ', 'NN', 'DT', 'VBZ', 'VBP']-Number=Sing\n",
      "\n",
      "2 - ['VBN', 'NNP', 'DT', 'IN', 'IN', ',', 'IN', 'NN']-NounType=Prop|Number=Sing\n",
      "\n",
      "3 - ['ADJ', 'VERB', 'PART', 'PUNCT', 'SPACE', 'PUNCT', 'ADP', 'PUNCT']-VerbForm=Inf\n",
      "\n",
      "4 - ['VERB', 'VERB', 'SCONJ', 'PROPN', 'ADJ', 'PUNCT', 'ADP', 'PUNCT', 'VERB']-Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\n",
      "\n",
      "5 - ['VERB', 'VERB', 'ADP', 'PUNCT', 'ADP', 'PUNCT', 'NOUN', 'ADP', 'ADV', 'CCONJ', 'VERB']-Number=Sing|Person=Three|Tense=Pres|VerbForm=Fin\n",
      "\n",
      "6 - ['aux', 'punct', 'cc', 'conj']-VerbType=Mod\n",
      "\n",
      "7 - ['advcl', 'prep', 'nsubj', 'aux', 'advmod', 'cc', 'conj', 'punct']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "8 - ['NN', 'VB', 'IN', 'NNS', 'MD', 'IN', 'VBZ']-VerbForm=Inf\n",
      "\n",
      "9 - ['VERB', 'VERB', 'ADP', 'PUNCT', 'NOUN', 'AUX', 'ADP', 'ADP', 'CCONJ', 'VERB', 'VERB']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "10 - ['VBD', 'VBD', 'IN', 'DT', 'RB', 'JJ', ',', 'VBG']-Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\n",
      "\n",
      "11 - ['VBN', 'DT', 'IN', ',', 'JJS', 'IN', 'RB', '-RRB-', 'IN']-\n",
      "\n",
      "12 - ['VBZ', 'NN', 'DT', 'NN', 'VBN', 'NN', 'IN']-Number=Sing\n",
      "\n",
      "13 - ['VBN', 'VBN', 'WRB', 'RB', 'IN']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "14 - ['VBZ', 'NNP', 'DT', 'JJ', 'HYPH', 'NNP']-NounType=Prop|Number=Sing\n",
      "\n",
      "15 - ['AUX', 'AUX', 'PROPN', 'PROPN', 'ADP', 'ADP', 'ADP', 'PUNCT']-Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\n",
      "\n",
      "16 - ['NN', 'NNS', 'CD', 'NN', 'NN', 'IN']-Number=Plur\n",
      "\n",
      "17 - ['NN', 'VBZ', 'WDT', ':', 'VBZ']-Number=Sing|Person=Three|Tense=Pres|VerbForm=Fin\n",
      "\n",
      "18 - ['ADP', 'NOUN', 'DET', 'ADJ', 'ADP', 'AUX']-Number=Plur\n",
      "\n",
      "19 - ['nmod', 'punct', 'nmod', 'punct', 'nmod']-NounType=Prop|Number=Plur\n",
      "\n",
      "20 - ['AUX', 'PROPN', 'SPACE', 'PUNCT', 'VERB', 'PUNCT', 'ADP', 'PUNCT']-NounType=Prop|Number=Sing\n",
      "\n",
      "21 - ['ccomp', 'mark', 'nsubj', 'prep', 'cc', 'conj']-Number=Sing|Person=Three|Tense=Pres|VerbForm=Fin\n",
      "\n",
      "22 - ['ROOT', 'nsubjpass', 'advmod', 'punct', 'nsubjpass', 'auxpass', 'xcomp', 'punct', 'cc', 'conj']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "23 - ['VERB', 'VERB', 'PRON', 'SCONJ', 'ADP']-Aspect=Prog|Tense=Pres|VerbForm=Part\n",
      "\n",
      "24 - ['IN', 'NN', 'DT', 'IN', 'CC', 'NN', 'VB']-Number=Sing\n",
      "\n",
      "25 - ['pobj', 'poss', 'det', 'amod', 'relcl']-Number=Plur\n",
      "\n",
      "26 - ['IN', 'VBD', 'JJR', \"''\", 'CC', 'NNS']-Tense=Past|VerbForm=Fin\n",
      "\n",
      "27 - ['VBD', 'VBD', 'IN', 'JJ', 'PRP', 'VB']-Tense=Past|VerbForm=Fin\n",
      "\n",
      "28 - ['IN', 'NNS', 'CD', 'DT', 'CD']-Number=Plur\n",
      "\n",
      "29 - ['VBN', 'VBN', 'IN', 'PRP', 'VBD', 'NNP', 'IN', 'VBN', '.']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "30 - ['IN', 'IN', 'NN', ',', 'IN', ',', 'SYM']-\n",
      "\n",
      "31 - ['NNS', 'IN', '``', 'NN', \"''\", 'NNS']-\n",
      "\n",
      "32 - ['VBN', 'VBN', 'VBD', 'IN', ',', 'NN', ',', ',', 'VBD', 'NN', ',', 'IN', '.']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "33 - ['advcl', 'prep', 'nsubj', 'cc', 'conj', 'prep', 'punct', 'advcl', 'punct']-Tense=Pres|VerbForm=Fin\n",
      "\n",
      "34 - ['IN', 'NN', 'DT', 'JJS', ',', 'CC', '_SP', 'CC', '_SP']-Number=Sing\n",
      "\n",
      "35 - ['ADJ', 'ADJ', 'SPACE', 'AUX', 'NOUN', 'PUNCT']-Degree=Pos\n",
      "\n",
      "36 - ['ADP', 'PROPN', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PUNCT', 'ADP', 'PUNCT']-NounType=Prop|Number=Sing\n",
      "\n",
      "37 - ['VBN', 'VBN', 'VBG', ',', 'NNP', 'VBD', 'VB', 'VBN', '.']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "38 - ['VERB', 'VERB', 'PRON', 'AUX', 'ADV', 'AUX', 'CCONJ', 'VERB', 'PUNCT', 'ADP', 'PUNCT', 'CCONJ', 'VERB', 'PUNCT']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "39 - ['VBD', 'VBP', 'EX', 'NNS', '-RRB-', '.']-Mood=Ind|Tense=Pres|VerbForm=Fin\n",
      "\n",
      "40 - ['VERB', 'NOUN', 'DET', 'ADJ', 'ADV', 'VERB']-Number=Plur\n",
      "\n",
      "41 - ['VERB', 'VERB', 'AUX', 'PUNCT', 'PROPN', 'PUNCT', 'ADV', 'NOUN', 'ADP', 'PUNCT', 'ADP', 'PUNCT', 'VERB']-Tense=Past|VerbForm=Fin\n",
      "\n",
      "42 - ['ROOT', 'prep', 'punct', 'punct', 'nsubj', 'punct', 'dobj', 'punct', 'prep', 'punct', 'ccomp', 'punct']-Tense=Past|VerbForm=Fin\n",
      "\n",
      "43 - ['nmod', 'nmod', 'compound', 'appos']-Number=Plur\n",
      "\n",
      "44 - ['NOUN', 'VERB', 'DET', 'ADV', 'NOUN', 'NOUN', 'ADP', 'PUNCT', 'VERB']-Tense=Past|VerbForm=Fin\n",
      "\n",
      "45 - ['advcl', 'mark', 'nsubj', 'acomp', 'prep', 'conj']-Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "\n",
      "46 - ['VERB', 'VERB', 'NOUN', 'AUX', 'ADV', 'ADP', 'PROPN', 'PUNCT', 'NOUN', 'PUNCT', 'VERB', 'PUNCT']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "47 - ['VB', 'NN', 'DT', 'JJ', 'JJ', ',', 'JJ', 'NN']-Number=Sing\n",
      "\n",
      "48 - ['advcl', 'cc', 'conj', 'advcl', 'advcl', 'prep']-Aspect=Prog|Tense=Pres|VerbForm=Part\n",
      "\n",
      "49 - ['ROOT', 'ccomp', 'punct', 'nsubj', 'acomp', 'xcomp', 'cc', 'conj']-Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "\n",
      "50 - ['_SP', 'NN', 'DT', 'JJ', 'IN', 'IN', 'IN', ',', 'VBN']-Number=Sing\n",
      "\n",
      "51 - ['pobj', 'appos', 'nummod', 'cc', 'conj']-NounType=Prop|Number=Sing\n",
      "\n",
      "52 - ['VBG', 'VBD', 'RP', 'NN', ',', 'VBG']-Tense=Past|VerbForm=Fin\n",
      "\n",
      "53 - ['VBN', 'VBN', 'PRP', 'VBD', 'IN', ',', 'CC', 'VBD', 'VBN', '.']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "54 - ['ROOT', 'advcl', 'punct', 'punct', 'aux', 'neg', 'dobj', 'punct', 'punct', 'punct']-VerbForm=Inf\n",
      "\n",
      "55 - ['conj', 'advmod', 'acomp', 'punct', 'npadvmod']-Tense=Past|VerbForm=Fin\n",
      "\n",
      "56 - ['VBZ', 'NN', 'DT', '``', 'CD', 'IN']-Number=Sing\n",
      "\n",
      "57 - ['relcl', 'advmod', 'nsubj', 'advcl']-Number=Sing|Person=Three|Tense=Pres|VerbForm=Fin\n",
      "\n",
      "58 - ['VBN', 'VBN', 'NN', 'VBZ', 'NN', ',', 'VBD', '.']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "59 - ['ROOT', 'nsubj', 'aux', 'acomp', 'xcomp', 'cc', 'conj']-Tense=Past|VerbForm=Part\n",
      "\n",
      "60 - ['VBZ', 'VBP', 'RB', 'IN', 'PRP', 'VBZ']-Tense=Pres|VerbForm=Fin\n",
      "\n",
      "61 - ['appos', 'det', 'prep', 'punct']-VerbForm=Inf\n",
      "\n",
      "62 - ['IN', '_SP', 'NNP', 'NN', '-RRB-']-NounType=Prop|Number=Sing\n",
      "\n",
      "63 - ['IN', 'NN', '-RRB-', ',', 'VBZ']-Number=Sing\n",
      "\n",
      "64 - ['VBP', 'NNP', '_SP', 'IN', '-LRB-', 'NNP', '-RRB-', 'CC', 'NN']-NounType=Prop|Number=Sing\n",
      "\n",
      "65 - ['VBN', 'VBN', '_SP', 'NN', 'VBP', 'CC', 'VB', '.']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "66 - ['VERB', 'VERB', 'ADP', 'PUNCT', 'ADV', 'PUNCT', 'PRON', 'AUX', 'NOUN', 'PUNCT', 'SPACE', 'PUNCT', 'ADP', 'PUNCT']-VerbForm=Inf\n",
      "\n",
      "67 - ['VBD', 'NN', 'PDT', 'DT', 'IN', 'IN', 'VBN']-Number=Sing\n",
      "\n",
      "68 - ['VERB', 'NOUN', 'ADV', 'NUM', 'ADJ', 'ADP', 'CCONJ', 'NOUN']-Number=Plur\n",
      "\n",
      "69 - ['ccomp', 'nsubj', 'prep', 'advmod', 'cc', 'conj']-Aspect=Prog|Tense=Pres|VerbForm=Part\n",
      "\n",
      "70 - ['VBN', 'VBG', 'NN', 'IN', ',', 'IN', ',', 'CC', 'VBG']-Aspect=Prog|Tense=Pres|VerbForm=Part\n",
      "\n",
      "71 - ['ROOT', 'advcl', 'punct', 'nsubjpass', 'auxpass', 'dobj', 'cc', 'conj', 'punct', 'cc', 'conj']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "72 - ['VBZ', 'VBP', 'PRP', 'RB', 'NN', '.']-Mood=Ind|Tense=Pres|VerbForm=Fin\n",
      "\n",
      "73 - ['VERB', 'VERB', 'AUX', 'PUNCT', 'ADP', 'PUNCT', 'PRON', 'AUX', 'PUNCT', 'PUNCT']-Tense=Past|VerbForm=Fin\n",
      "\n",
      "74 - ['SPACE', 'PROPN', 'ADP', 'PUNCT', 'PROPN', 'PUNCT', 'NOUN', 'PUNCT']-NounType=Prop|Number=Sing\n",
      "\n",
      "75 - ['VBP', 'VBP', 'WRB', 'NNS', 'JJR']-Mood=Ind|Tense=Pres|VerbForm=Fin\n",
      "\n",
      "76 - ['VBP', 'VBP', 'IN', 'CD', 'NN', 'CC', 'VB', '.']-Tense=Pres|VerbForm=Fin\n",
      "\n",
      "77 - ['VBG', 'NN', 'NN', 'NN', '-RRB-']-Number=Sing\n",
      "\n",
      "78 - ['oprd', 'punct', 'det']-Degree=Pos\n",
      "\n",
      "79 - ['conj', 'det', 'amod', 'appos', 'punct', 'punct', 'acl', 'punct', 'conj']-NounType=Prop|Number=Sing\n",
      "\n",
      "80 - ['ADP', 'PROPN', 'DET', 'VERB', 'PROPN', 'PUNCT', 'VERB', 'PUNCT', 'NOUN', 'PUNCT']-NounType=Prop|Number=Sing\n",
      "\n",
      "81 - ['VERB', 'VERB', 'VERB', 'ADP', 'PUNCT', 'NOUN', 'PROPN', 'ADP', 'ADP', 'PUNCT']-Tense=Past|VerbForm=Fin\n",
      "\n",
      "82 - ['ROOT', 'advcl', 'punct', 'auxpass', 'npadvmod', 'ccomp']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "83 - ['IN', 'NNP', 'DT', 'JJ', 'NNP', 'POS', 'VBN', 'NNP']-NounType=Prop|Number=Sing\n",
      "\n",
      "84 - ['NN', 'VBP', '-LRB-', 'RB', '``', 'WRB', 'NNS']-Mood=Ind|Tense=Pres|VerbForm=Fin\n",
      "\n",
      "85 - ['dobj', 'prep', 'punct', 'prep', 'punct', 'punct', 'appos', 'punct', 'prep', 'prep', 'punct']-NumType=Card\n",
      "\n",
      "86 - ['ccomp', 'punct', 'advmod', 'nsubj', 'aux', 'dobj', 'punct', 'cc', 'conj']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "87 - ['VBN', 'VBN', 'VB', ',', 'NN', 'VBD', 'RB', 'VB', 'VBN', '.']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "88 - ['ADP', 'AUX', 'ADP', 'PRON', 'ADV']-VerbForm=Fin\n",
      "\n",
      "89 - ['VBZ', 'VBN', '_SP', 'TO', 'VB', 'IN', 'JJ']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "90 - ['IN', 'NNS', 'DT', 'CD', 'VBN', 'NN', '``']-Number=Plur\n",
      "\n",
      "91 - ['VBZ', 'VBZ', 'IN', ',', 'NN', 'VB', ',', 'VBZ', '.']-Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "\n",
      "92 - ['VBD', 'VBD', 'IN', 'NNP', 'IN', 'VB', 'VBD', '.']-Tense=Past|VerbForm=Fin\n",
      "\n",
      "93 - ['VBZ', 'VBZ', '_SP', 'NN', 'RB', 'CD', ',', 'VBG', '.']-Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "\n",
      "94 - ['CD', 'NN', 'IN', 'DT', 'NNP', 'NN', 'IN']-Number=Sing\n",
      "\n",
      "95 - ['VBZ', 'VBZ', 'VBN', ',', 'NN', 'NN', ',', '.']-Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "\n",
      "96 - ['VBD', 'VBN', 'IN', ',', 'VBD', 'NN', ',', 'VBN', '.']-Aspect=Perf|Tense=Past|VerbForm=Part\n",
      "\n",
      "97 - ['NNPS', 'JJ', 'NN', ',', 'NNS']-Degree=Pos\n",
      "\n",
      "98 - ['VERB', 'VERB', 'VERB', 'PUNCT', 'NOUN', 'NOUN', 'PROPN', 'PUNCT']-Tense=Past|VerbForm=Fin\n",
      "\n",
      "99 - ['ADP', 'NOUN', 'PRON', 'NUM', 'ADJ', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ']-Number=Plur\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(list(dep_relations.keys())[:100]):\n",
    "    print(i, '-', j)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"'JJ'\" in \"['VB', 'NN', 'DT', 'JJ', 'JJ', ',', 'JJ', 'NN']-Number=Sing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VERB', ['NOUN', ['ADJ']], ['NOUN', ['NOUN']], ['ADP', ['NOUN']], ['PUNCT']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a4153aa7aa324b53b0fef5352206732d-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Autonomous</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">cars</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">shift</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">insurance</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">liability</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">toward</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">manufacturers .</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a4153aa7aa324b53b0fef5352206732d-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a4153aa7aa324b53b0fef5352206732d-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a4153aa7aa324b53b0fef5352206732d-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a4153aa7aa324b53b0fef5352206732d-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a4153aa7aa324b53b0fef5352206732d-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a4153aa7aa324b53b0fef5352206732d-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a4153aa7aa324b53b0fef5352206732d-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a4153aa7aa324b53b0fef5352206732d-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,266.5 L753.0,254.5 737.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a4153aa7aa324b53b0fef5352206732d-0-4\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a4153aa7aa324b53b0fef5352206732d-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,266.5 L933.0,254.5 917.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a4153aa7aa324b53b0fef5352206732d-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a4153aa7aa324b53b0fef5352206732d-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1090.0,266.5 L1098.0,254.5 1082.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "\"['ADJ']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-249-b36da154ed74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_children\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Retrieving possible words to replace 'token'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpossible_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mnew_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['ADJ']\""
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "sentence = \"Autonomous cars shift insurance liability toward manufacturers .\"\n",
    "\n",
    "doc = nlp(sentence)\n",
    "#print(sentence)\n",
    "root = [token for token in doc if token.head == token][0]\n",
    "ref_tree_representation = doc_to_tree(doc, root)\n",
    "print(ref_tree_representation)\n",
    "spacy.displacy.render(doc, style='dep')\n",
    "#\n",
    "#dep = result_dep_relations[0]\n",
    "#\n",
    "i=0\n",
    "count=0\n",
    "while (i < 5) and (count < 1000):\n",
    "    sample = []\n",
    "    for token in doc:\n",
    "        # Computing dependency relationships with head and children\n",
    "        keys = []\n",
    "        all_children = [token.pos_]\n",
    "        for child in token.children:\n",
    "            keys.append(str([token.pos_, child.pos_]))\n",
    "            all_children.append(child.pos_)\n",
    "        keys.append(str(all_children))\n",
    "        # Retrieving possible words to replace 'token'\n",
    "        possible_words = dep[keys[-1]]\n",
    "        sample.append(uniform(possible_words))\n",
    "    new_sentence = ' '.join(sample)\n",
    "    doc_sample = nlp(' '.join(sample))\n",
    "    root = [token for token in doc_sample if token.head == token][0]\n",
    "    tree_representation = doc_to_tree(doc_sample, root)\n",
    "    if tree_representation!=ref_tree_representation:\n",
    "        i+=1\n",
    "        print(new_sentence)\n",
    "        print(tree_representation)\n",
    "        spacy.displacy.render(doc_sample, style='dep')\n",
    "    count+=1\n",
    "print('done in ', count, ' iterations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>morph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>once</td>\n",
       "      <td>RB</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>(PunctType=Comm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when</td>\n",
       "      <td>WRB</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i</td>\n",
       "      <td>PRP</td>\n",
       "      <td>(Case=Nom, Number=Sing, Person=1, PronType=Prs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>was</td>\n",
       "      <td>VBD</td>\n",
       "      <td>(Mood=Ind, Number=Sing, Person=3, Tense=Past, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>not</td>\n",
       "      <td>RB</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>a</td>\n",
       "      <td>DT</td>\n",
       "      <td>(Definite=Ind, PronType=Art)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>hat</td>\n",
       "      <td>NN</td>\n",
       "      <td>(Number=Sing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>(PunctType=Peri)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  tag                                              morph\n",
       "0    once   RB                                                 ()\n",
       "1       ,    ,                                   (PunctType=Comm)\n",
       "2    when  WRB                                                 ()\n",
       "3       i  PRP    (Case=Nom, Number=Sing, Person=1, PronType=Prs)\n",
       "4     was  VBD  (Mood=Ind, Number=Sing, Person=3, Tense=Past, ...\n",
       "..    ...  ...                                                ...\n",
       "160   not   RB                                                 ()\n",
       "161    of   IN                                                 ()\n",
       "162     a   DT                       (Definite=Ind, PronType=Art)\n",
       "163   hat   NN                                      (Number=Sing)\n",
       "164     .    .                                   (PunctType=Peri)\n",
       "\n",
       "[165 rows x 3 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(' '.join(iterator_list[0][:10]))\n",
    "d = []\n",
    "for token in doc:\n",
    "    d.append([token.text, token.tag_, token.morph])\n",
    "    #print(token.text, token.dep_, token.head.text, token.head.pos_, \n",
    "    #        [(child.pos_, child.dep_) for child in token.children])\n",
    "pd.DataFrame(d, columns=['word', 'tag', 'morph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [04:45<00:00, 35.07it/s] \n"
     ]
    }
   ],
   "source": [
    "tree_data = train_data.replace('<eos>', '').replace('<unk>', '').split('\\n')[:10000]\n",
    "tree_dict = get_sentence_tree_dict(tree_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['ROOT', 'advmod', 'punct', 'advcl', 'punct', 'nsubj', 'dobj', 'punct', 'punct']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-240-81dc1eb83616>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-238-3c08a131528a>\u001b[0m in \u001b[0;36mgenerate_sample\u001b[0;34m(sentence, n_samples, limit_iterations)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_children\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m# Retrieving possible words to replace 'token'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mpossible_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mnew_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['ROOT', 'advmod', 'punct', 'advcl', 'punct', 'nsubj', 'dobj', 'punct', 'punct']\""
     ]
    }
   ],
   "source": [
    "generate_sample(iterator_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import benepar\n",
    "#benepar.download('benepar_en3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.6'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'T5Tokenizer' object has no attribute 'is_fast'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5c9d731d6e0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbenepar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeneparComponent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"benepar_en3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The time for action is now. It is never too late to do something.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/benepar/integrations/spacy_plugin.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, subbatch_max_tokens, disable_tagger, batch_size)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeprecated\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mignored\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0muse\u001b[0m \u001b[0msubbatch_max_tokens\u001b[0m \u001b[0minstead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \"\"\"\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_trained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/benepar/integrations/downloader.py\u001b[0m in \u001b[0;36mload_trained_model\u001b[0;34m(model_name_or_path)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_chart\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChartParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChartParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_trained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/benepar/parse_chart.py\u001b[0m in \u001b[0;36mfrom_trained\u001b[0;34m(cls, model_path)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hparams\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnkutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/benepar/parse_chart.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tag_vocab, label_vocab, char_vocab, hparams, pretrained_model_path)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 )\n\u001b[1;32m     69\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 self.retokenizer = retokenization.Retokenizer(\n\u001b[0m\u001b[1;32m     71\u001b[0m                     \u001b[0mpretrained_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_start_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/benepar/retokenization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pretrained_model_name_or_path, retain_start_stop)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         )\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fast\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             raise NotImplementedError(\n\u001b[1;32m     95\u001b[0m                 \u001b[0;34m\"Converting from treebank tokenization to tokenization used by a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'T5Tokenizer' object has no attribute 'is_fast'"
     ]
    }
   ],
   "source": [
    "from benepar import BeneparComponent\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.remove_pipe(\"ner\")\n",
    "nlp.max_length = np.inf\n",
    "print(nlp.pipe_names)\n",
    "#nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})\n",
    "nlp.add_pipe(benepar.BeneparComponent(\"benepar_en3\"))\n",
    "doc = nlp('The time for action is now. It is never too late to do something.')\n",
    "sent = list(doc.sents)[0]\n",
    "print(sent._.parse_string)\n",
    "# (S (NP (NP (DT The) (NN time)) (PP (IN for) (NP (NN action)))) (VP (VBZ is) (ADVP (RB now))) (. .))\n",
    "print(sent._.labels)\n",
    "# ('S',)\n",
    "print(list(sent._.children)[0])\n",
    "# The time for action\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading benepar_en: Package 'benepar_en' not found\n",
      "[nltk_data]     in index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import benepar\n",
    "benepar.download('benepar_en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
