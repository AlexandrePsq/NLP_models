{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to evaluate model entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, GPT2Tokenizer,  GPT2LMHeadModel, GPT2Tokenizer, BertForMaskedLM\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPT2.tokenizer import tokenize\n",
    "from LSTM.tokenizer import unk_transform\n",
    "#from LSTM.model import LSTMExtractor\n",
    "from LSTM.data import Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(pk):\n",
    "    pk = pk.numpy()\n",
    "    entropy = -np.sum(pk * np.log2(pk), axis=0)\n",
    "    return entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_output(out): \n",
    "    result = np.sum([entropy(scipy.special.softmax(out[0].detach().squeeze(0)[ax])) for ax in range(out[0].detach().squeeze(0).shape[0])]) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model instanciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "t_base = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_medium = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n",
    "t_medium = GPT2Tokenizer.from_pretrained('gpt2-medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bert = BertForMaskedLM.from_pretrained('bert-base-cased')\n",
    "t_bert = BertTokenizer.from_pretrained('bert-base-cased') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = LSTMExtractor(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/stimuli-representations/english/LSTM_embedding-size_600_nhid_300_nlayers_1_dropout_02_wiki_kristina_english/activations_run1.csv')\n",
    "lstm_result = data['entropy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#template = '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/text/english/text_english_run*.txt' # path to text input  \n",
    "template = '/USers/alexpsq/Code/Parietal/data/text_english_run*.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob.glob(template))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:00<00:00, 464123.80it/s]\n",
      "100%|██████████| 135/135 [00:00<00:00, 865796.70it/s]\n",
      "100%|██████████| 176/176 [00:00<00:00, 951285.44it/s]\n",
      "100%|██████████| 173/173 [00:00<00:00, 836925.71it/s]\n",
      "100%|██████████| 177/177 [00:00<00:00, 618659.84it/s]\n",
      "100%|██████████| 216/216 [00:00<00:00, 710007.57it/s]\n",
      "100%|██████████| 196/196 [00:00<00:00, 556967.20it/s]\n",
      "100%|██████████| 145/145 [00:00<00:00, 259459.93it/s]\n",
      "100%|██████████| 207/207 [00:00<00:00, 497547.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "Preprocessing...\n",
      "Preprocessed.\n",
      "Tokenized.\n",
      "Tokenizing...\n",
      "Preprocessing...\n",
      "Preprocessed.\n",
      "Tokenized.\n",
      "Tokenizing...\n",
      "Preprocessing...\n",
      "Preprocessed.\n",
      "Tokenized.\n",
      "Tokenizing...\n",
      "Preprocessing...\n",
      "Preprocessed.\n",
      "Tokenized.\n",
      "Tokenizing...\n",
      "Preprocessing...\n",
      "Preprocessed.\n",
      "Tokenized.\n",
      "Tokenizing...\n",
      "Preprocessing...\n",
      "Preprocessed.\n",
      "Tokenized.\n",
      "Tokenizing...\n",
      "Preprocessing...\n",
      "Preprocessed.\n",
      "Tokenized.\n",
      "Tokenizing...\n",
      "Preprocessing...\n",
      "Preprocessed.\n",
      "Tokenized.\n",
      "Tokenizing...\n",
      "Preprocessing...\n",
      "Preprocessed.\n",
      "Tokenized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "iterator_list = [tokenize(path, language, train=False) for path in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n"
     ]
    }
   ],
   "source": [
    "res = ' '.join(iterator_list[0])\n",
    "res = res.split(' ')\n",
    "print(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_path = '/neurospin/unicog/protocols/IRMf/LePetitPrince_Pallier_2018/LePetitPrince/data/text/english/lstm_training'\n",
    "#vocab_path = '/Users/alexpsq/Code/data/'\n",
    "vocab = Dictionary(vocab_path, language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator_list_lstm = [[unk_transform(word, vocab) for item in iterator_ for word in item.strip().split(' ')] for iterator_ in iterator_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchity(iterator, context_length, pretrained_bert, max_length=512):\n",
    "    \"\"\"Batchify iterator sentence, to get minimum context length \n",
    "    when possible.\n",
    "    Arguments:\n",
    "        - iterator: sentence iterator\n",
    "        - context_length: int\n",
    "    Returns:\n",
    "        - batch: sequence iterator\n",
    "        - indexes: tuple of int\n",
    "    \"\"\"\n",
    "    iterator = [item.strip() for item in iterator]\n",
    "    max_length -= 2 # for special tokens\n",
    "    tokenizer = BertTokenizer.from_pretrained(pretrained_bert)\n",
    "    \n",
    "    batch = []\n",
    "    indexes = []\n",
    "    sentence_count = 0\n",
    "    n = len(iterator)\n",
    "    \n",
    "    assert context_length < max_length\n",
    "    token_count = 0\n",
    "    while sentence_count < n and token_count < max_length:\n",
    "        token_count += len(tokenizer.wordpiece_tokenizer.tokenize(iterator[sentence_count]))\n",
    "        if token_count < max_length:\n",
    "            sentence_count += 1\n",
    "    batch.append(' '.join(iterator[:sentence_count]))\n",
    "    indexes.append((0, len(tokenizer.wordpiece_tokenizer.tokenize(batch[-1]))))\n",
    "    \n",
    "    while sentence_count < n:\n",
    "        token_count = 0\n",
    "        sentence_index = sentence_count - 1\n",
    "        tmp = sentence_count\n",
    "        while token_count < context_length:\n",
    "            token_count += len(tokenizer.wordpiece_tokenizer.tokenize(iterator[sentence_index]))\n",
    "            sentence_index -= 1\n",
    "        while sentence_count < n and token_count < max_length:\n",
    "            token_count += len(tokenizer.wordpiece_tokenizer.tokenize(iterator[sentence_count]))\n",
    "            if token_count < max_length:\n",
    "                sentence_count += 1\n",
    "        batch.append(' '.join(iterator[sentence_index+1:sentence_count]))\n",
    "        indexes.append((len(tokenizer.wordpiece_tokenizer.tokenize(' '.join(iterator[sentence_index+1:tmp]))), len(tokenizer.wordpiece_tokenizer.tokenize(batch[-1]))))\n",
    "    return batch, indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once , when I was six years old , I saw a magnificent picture in a book about the primeval forest called ‘ Real - life Stories . ’  It showed a boa constrictor swallowing a wild animal .  Here is a copy of the drawing . It said in the book : “ Boa constrictors swallow their prey whole , without chewing .  Then they are not able to move , and they sleep for the six months it takes for digestion . ”\n",
      "['Once', ',', 'when', 'I', 'was', 'six', 'years', 'old', ',', 'I', 'saw', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'primeval', 'forest', 'called', '‘', 'Real', '-', 'life', 'Stories', '.', '’', '', 'It', 'showed', 'a', 'boa', 'constrictor', 'swallowing', 'a', 'wild', 'animal', '.', '', 'Here', 'is', 'a', 'copy', 'of', 'the', 'drawing', '.', 'It', 'said', 'in', 'the', 'book', ':', '“', 'Boa', 'constrictors', 'swallow', 'their', 'prey', 'whole', ',', 'without', 'chewing', '.', '', 'Then', 'they', 'are', 'not', 'able', 'to', 'move', ',', 'and', 'they', 'sleep', 'for', 'the', 'six', 'months', 'it', 'takes', 'for', 'digestion', '.', '”']\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(iterator_list[0][0:5]))\n",
    "print([item for l in [iterator_list[0][index] for index in range(5)] for item in l.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Once , when I was six years old , I saw a magnificent picture in a book about the primeval forest called ‘ Real - life Stories . ’',\n",
       " ' It showed a boa constrictor swallowing a wild animal .',\n",
       " ' Here is a copy of the drawing .',\n",
       " 'It said in the book : “ Boa constrictors swallow their prey whole , without chewing .',\n",
       " ' Then they are not able to move , and they sleep for the six months it takes for digestion . ”',\n",
       " ' So I thought a lot about the adventures of the jungle and , in turn , I managed , with a coloured pencil , to make my first drawing .',\n",
       " ' My Drawing Number one .',\n",
       " ' It looked like this : I showed my masterpiece to the grownups and I asked them if my drawing frightened them .',\n",
       " 'They answered me : “ Why would anyone be frightened by a hat ? ”',\n",
       " ' My drawing was not of a hat .',\n",
       " ' It showed a boa constrictor digesting an elephant .',\n",
       " ' I then drew the inside of the boa constrictor , so that the grownups could understand .',\n",
       " ' They always need to have things explained .',\n",
       " ' My Drawing Number two looked like this : The grownups advised me to leave aside drawings of boa constrictors , open or closed , and to apply myself instead to geography , history , arithmetic and grammar .',\n",
       " ' Thus I abandoned , at the age of six , a magnificent career as a painter .',\n",
       " ' I was discouraged by the failure of my Drawing Number one and of my Drawing Number two .',\n",
       " ' Grownups never understand anything by themselves , and it ’ s tiresome for children to always explain things for them again and again .',\n",
       " 'So I had to choose another profession , and I learned to fly airplanes .',\n",
       " ' I flew a little in many places around the world .',\n",
       " \" And geography , it ' s true , has served me well .\",\n",
       " ' I could recognize , at first glance , China from Arizona .',\n",
       " ' It ’ s very useful if you get lost at night .',\n",
       " 'I have had , during my life , a lot of contact with many persons of consequence .',\n",
       " ' I have lived a lot amongst the grownups .',\n",
       " ' I have seen them from close up .',\n",
       " ' It hasnt much improved my opinion of them .',\n",
       " \"Whenever I met one of them that seemed a bit more clear - sighted , I tried the experiment of showing them my Drawing Number one , that I ' ve always kept .\",\n",
       " ' I wanted to know if they were really a person of true understanding .',\n",
       " \" But they always responded : “ It ' s a hat . ”\",\n",
       " ' So I would never speak to them of boa constrictors , nor of primeval forests , nor of the stars .',\n",
       " ' I put myself at their level .',\n",
       " ' I talked to them about bridge , golf , politics and neckties .',\n",
       " ' And the grownup was glad to know such a sensible man .',\n",
       " 'So I lived alone , without anyone I could really talk to , until a breakdown in the Sahara desert , six years ago .',\n",
       " ' Something had broken in my engine .',\n",
       " ' And as I had with me neither a mechanic nor any passengers , I readied myself to try and carry out , all alone , the difficult repairs .',\n",
       " ' For me it was a matter of life or death .',\n",
       " ' I had hardly enough water to drink for a week .',\n",
       " 'The first night I went to sleep on the sand , a thousand miles from any human habitation .',\n",
       " ' I was more isolated than a shipwrecked sailor on a raft in the middle of the ocean .',\n",
       " ' So you can imagine my surprise when at daybreak , a funny little voice woke me up .',\n",
       " ' It said : “ Please ...',\n",
       " ' draw me a sheep ! ”',\n",
       " ' “ What ? ”',\n",
       " ' “ Draw me a sheep ! ”',\n",
       " ' I jumped to my feet as if I ’ d been struck by lightning .',\n",
       " ' I rubbed my eyes .',\n",
       " ' I took a good look around me .',\n",
       " ' And I saw a quite extraordinary little man , who was examining me seriously .',\n",
       " ' Here is the best portrait that , later , I managed to do of him .',\n",
       " ' But my drawing , of course , is much less charming than its model .',\n",
       " \" It ' s not my fault .\",\n",
       " \" I was discouraged in my career as a painter by the grownups , at the age of six , and I hadn ' t learned to draw anything except boa constrictors , closed and open .\",\n",
       " 'I stared at this sudden apparition wide eyed with astonishment .',\n",
       " ' Remember that I was a thousand miles from any inhabited region .',\n",
       " ' And yet this little fellow seemed neither lost , nor half - dead with fatigue , nor starved or dying of thirst or fear .',\n",
       " ' He looked nothing like a child lost in the middle of the desert , a thousand miles from any inhabited region .',\n",
       " ' When I finally managed to speak , I said : “ But — what are you doing here ? ”',\n",
       " ' And he repeated , very slowly , as if it was something very serious : “ Please ...',\n",
       " ' draw me a sheep ... ”',\n",
       " ' When a mystery is too overpowering , one dare not disobey .',\n",
       " ' Absurd as it seemed to me a thousand miles from any human habitation and in danger of death , I took out of my pocket a sheet of paper and a pen .',\n",
       " ' But then I remembered that I had mainly studied geography , history , arithmetic and grammar , and I told the little fellow ( a little crossly ) that I didn ’ t know how to draw .',\n",
       " \" He replied : “ It doesn ' t matter .\",\n",
       " ' Draw me a sheep . ”',\n",
       " ' As I ’ d never drawn a sheep , I redrew for him one of the only two drawings that I was capable of .',\n",
       " ' The one of the closed boa constrictor .',\n",
       " ' And I was astounded to hear the little fellow respond : “ No !',\n",
       " ' No !',\n",
       " ' I don ’ t want an elephant inside a boa constrictor .',\n",
       " ' A boa constrictor is very dangerous , and an elephant is very cumbersome .',\n",
       " ' Where I live everything is very small .',\n",
       " ' I need a sheep .',\n",
       " ' Draw me a sheep . ”',\n",
       " ' So I drew .',\n",
       " 'He looked carefully , then said : “ No !',\n",
       " ' This one ’ s already very sick .',\n",
       " ' Make another one . ”',\n",
       " ' I drew again : My friend smiled gently and indulgently : “ You can see yourself ...',\n",
       " \" this isn ’ t a sheep , it ' s a ram .\",\n",
       " ' It has horns ...',\n",
       " ' “ So once again I redid my drawing : But it was rejected , like the previous ones : “ This one ’ s too old .',\n",
       " ' I want a sheep that will live a long time . ”',\n",
       " ' So , getting impatient , as I was eager to start dismantling my engine , I hastily sketched this drawing : And I snapped : “ This here is the box .',\n",
       " ' The sheep you want is inside . ”',\n",
       " \" But I was very surprised to see the face of my young judge light up : “ It ' s exactly the way I wanted !\",\n",
       " ' Do you think this sheep needs a lot of grass ? ”',\n",
       " ' “ Why ? ”',\n",
       " \" “ Because where I ' m from everything is very small ... ”\",\n",
       " ' “ There will certainly be enough .',\n",
       " ' I gave you a very small sheep . ”',\n",
       " ' He leaned his head towards the drawing : “ Not that small ...',\n",
       " ' Look !',\n",
       " \" He ' s fallen asleep ... ”\",\n",
       " \" And that ' s how I met the little prince .\",\n",
       " 'It took me a long time to find out where he came from .',\n",
       " ' The little prince , who asked me many questions , never seemed to hear my own .',\n",
       " ' It was the words spoken by chance that , little by little , revealed everything to me .',\n",
       " \" So , when he saw my airplane for the first time ( I won ’ t draw my airplane , it would be a drawing far too complicated for me ) , he asked me : “ What ' s that thing there ? ”\",\n",
       " \" “ It ' s not a thing .\",\n",
       " ' It flies .',\n",
       " \" It ' s an airplane .\",\n",
       " 'It ’ s my airplane . ”',\n",
       " ' And I was proud to have him know that I could fly .',\n",
       " ' Then he cried : “ What ?',\n",
       " ' You fell from the sky ! ”',\n",
       " ' “ Yes , ” I said modestly .',\n",
       " ' “ Oh !',\n",
       " \" That ' s funny !\",\n",
       " ' ... ”',\n",
       " ' And the little prince broke into a lovely peal of laughter , which irritated me very much .',\n",
       " ' I prefer people to take my misfortunes seriously .',\n",
       " ' Then he added : “ So , you also come from the sky !',\n",
       " 'What planet are you from ? ”',\n",
       " ' I caught a glimpse into the mystery of his presence , and I asked abruptly : “ So you come from another planet then ? ”',\n",
       " ' But he didn ’ t answer .',\n",
       " \" He shook his head slowly whilst looking at my airplane : “ It ' s true that you can ' t have come from far away in that thing ... ”\",\n",
       " ' And he drifted into a daydream which lasted a long while .',\n",
       " ' Then , taking my sheep out of his pocket , he sank himself into the contemplation of his treasure .',\n",
       " 'You can imagine how my curiosity was aroused by this small disclosure about ‘ the other planets . ’',\n",
       " ' So I tried to find out more : “ Where are you from my little fellow ?',\n",
       " ' Where ’ s this ‘ where I live ’ of yours ?',\n",
       " ' Where do you take my sheep off to ? ”',\n",
       " \" After a reflective silence he answered : “ What ' s good about the box you ’ ve given me is that at night , he can use it as a house . ”\",\n",
       " ' “ That ’ s right .',\n",
       " \" And if you ’ re good , I ' ll give you a rope to tie him up with during the day .\",\n",
       " ' And a stake . ”',\n",
       " ' The offer seemed to shock the little prince : “ Tie him up ?',\n",
       " ' What a funny idea ! ”',\n",
       " \" “ But if you don ' t tie him up , he ’ ll wander off , and get lost . ”\",\n",
       " ' My friend broke into another peal of laughter : “ Where do you think he ’ d go ! ”',\n",
       " ' “ Anywhere .',\n",
       " ' Straight ahead ... ”',\n",
       " ' Then the little prince said gravely : “ That doesn ’ t matter ; where I live , everything is so small ! ”',\n",
       " \" And perhaps with a hint of sadness , he added : “ Straight ahead you can ' t go far ... ”\"]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iterator_list[0][16:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['the']\n",
      "2\n",
      "['the', 'dog']\n",
      "3\n",
      "['the', 'dog', 'runs']\n",
      "4\n",
      "['the', 'dog', 'runs', '.']\n"
     ]
    }
   ],
   "source": [
    "for index in range(1, len('the dog runs . '.split()) +1):\n",
    "    print(index)\n",
    "    print('the dog runs . '.split()[:index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġthe', 'Ġdog', 'Ġruns', 'Ġ.']"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_base.tokenize('the dog runs . ', add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 499), (217, 504), (202, 489), (211, 508), (204, 487), (203, 502), (221, 268)]\n",
      "\n",
      "[(0, 499), (217, 504), (202, 489), (211, 508), (204, 487), (203, 502), (221, 268)]\n",
      "\n",
      "[(0, 499), (217, 504), (202, 489), (211, 508), (204, 487), (203, 502), (221, 268)]\n",
      "\n",
      "[(0, 499), (217, 504), (202, 489), (211, 508), (204, 487), (203, 502), (221, 268)]\n",
      "\n",
      "[(0, 499), (217, 504), (202, 489), (211, 508), (204, 487), (203, 502), (221, 268)]\n",
      "\n",
      "[(0, 499), (217, 504), (202, 489), (211, 508), (204, 487), (203, 502), (221, 268)]\n",
      "\n",
      "[(0, 499), (217, 504), (202, 489), (211, 508), (204, 487), (203, 502), (221, 268)]\n",
      "\n",
      "[(0, 499), (217, 504), (202, 489), (211, 508), (204, 487), (203, 502), (221, 268)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    batch, indexes = batchity(iterator_list[0], 200, 'bert-base-cased', max_length=512)\n",
    "    print(indexes)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I thus learned a second very important thing : that his home planet was barely bigger than a house ! It didn ' t surprise me much .  I knew that , apart from the large planets like the Earth , Jupiter , Mars , and Venus , which have been given names , there are hundreds of others that are sometimes so small that one has great difficulty in spotting them through the telescope .  When an astronomer discovers one of these , he gives it a number for a name .  He might call it for example “ asteroid three hundred and twenty - five . ”  I have serious reason to believe that the planet from where the little prince came is the asteroid B - six hundred and twelve .  This asteroid has only been seen through a telescope once , in one thousand , nine hundred and nine , by a Turkish astronomer . He had then given a big presentation on his discovery at an international astronomy conference . But nobody had believed him because of his outfit .  Grownups are like that . Fortunately for the reputation of Asteroid B - six hundred and twelve , a Turkish dictator imposed on his people , on pain of death , to dress themselves in the European fashion .  The astronomer gave his presentation again in one thousand , nine hundred and twenty , dressed very stylishly .  And this time everybody believed him . If I have told you these details about the asteroid B - six hundred and twelve , and revealed to you its number , it ’ s because of the grownups .  Grownups love numbers .  When you talk to them about a new friend , they never ask you about any of the important things .  They never ask you : “ How does his voice sound ?  What games does he like best ?  Does he collect butterflies ? ”  They ask : “ How old is he ?  How many brothers does he have ?  How much does he weigh ?  How much money does his father make ? ”  Only then do they think they know him .  If you said to the grownups : “ I saw a beautiful red brick house with geraniums by the windows and doves on the roof ...  , ” they wouldn ’ t be able to picture this house in their minds .  You ’ d have to tell them : “ I saw a hundred thousand franc house . ”  And they ’ d cry : “ How pretty ! ”  So if you were to say to them : “ The proof that the little prince existed is that he was charming , he laughed , and he wanted a sheep .\n",
      "\n",
      "\n",
      " Grownups love numbers .  When you talk to them about a new friend , they never ask you about any of the important things .  They never ask you : “ How does his voice sound ?  What games does he like best ?  Does he collect butterflies ? ”  They ask : “ How old is he ?  How many brothers does he have ?  How much does he weigh ?  How much money does his father make ? ”  Only then do they think they know him .  If you said to the grownups : “ I saw a beautiful red brick house with geraniums by the windows and doves on the roof ...  , ” they wouldn ’ t be able to picture this house in their minds .  You ’ d have to tell them : “ I saw a hundred thousand franc house . ”  And they ’ d cry : “ How pretty ! ”  So if you were to say to them : “ The proof that the little prince existed is that he was charming , he laughed , and he wanted a sheep .  If someone wants a sheep , that proves they exist , ” they ’ d shrug their shoulders and treat you like a child .  But if you were to say : “ The planet he came from is the Asteroid B - six hundred and twelve ” , they ’ d be convinced , and leave you in peace and spare you their questions .  They ’ re like that .  Don ’ t blame them .  Children should be forgiving towards the grownups . But , of course , those of us who understand life , we don ' t much care for numbers !  I ’ d have liked to begin this story in the same way as a fairy tale .  I ’ d have liked to say : “ Once upon a time , there was a little prince who lived on a planet not much bigger than himself , and who needed a friend ... ”  For those who understand life , it would have seemed much more natural . For I don ’ t want my book to be read lightly .  I feel so much sadness in recounting these memories .  It ' s already been six years since my friend left with his sheep .  If I try to describe him here , it ’ s so as not to forget him .  It ’ s sad to forget a friend .  Not everyone has had a friend .  And if I forgot him , I could become like the grownups who are only interested in numbers .  So that ’ s why I have again bought a box of paints and some pencils .\n",
      "\n",
      "\n",
      "But , of course , those of us who understand life , we don ' t much care for numbers !  I ’ d have liked to begin this story in the same way as a fairy tale .  I ’ d have liked to say : “ Once upon a time , there was a little prince who lived on a planet not much bigger than himself , and who needed a friend ... ”  For those who understand life , it would have seemed much more natural . For I don ’ t want my book to be read lightly .  I feel so much sadness in recounting these memories .  It ' s already been six years since my friend left with his sheep .  If I try to describe him here , it ’ s so as not to forget him .  It ’ s sad to forget a friend .  Not everyone has had a friend .  And if I forgot him , I could become like the grownups who are only interested in numbers .  So that ’ s why I have again bought a box of paints and some pencils .  It ' s hard to take up drawing again at my age , when I have only ever attempted to draw a boa constrictor , closed and open , at the age of six !  I ' ll try , of course , to make my portraits as lifelike as possible .  But I ’ m not quite sure I ' ll succeed .  Some drawings go alright ; others don ’ t look like their subjects .  I also get the size a bit wrong .  Here the little prince is too big .  There he ’ s too small .  I ’ m also not sure about the colour of his outfit .  So I fumble along somehow , as best I can .  I will make mistakes on certain important points too .  But you ’ ll have to forgive me that .  My friend never gave explanations .  Perhaps he thought I was just like himself .  But I , unfortunately , don ' t know how to see sheep through boxes .  Perhaps I ’ m a bit like the grownups .  I must have got older . Every day I ’ d learn something about his planet , the departure , and the trip .  The information came slowly , as his thoughts wandered .  It was in this way that , on the third day , I came to know of the tragedy of the baobabs . This time again it was thanks to the sheep , because the little prince asked me abruptly , as if seized by a grave doubt : “ It ’ s true , isn ’ t it , that sheep eat shrubs ? ”  “ Yes .  It ' s true . ”\n",
      "\n",
      "\n",
      " There he ’ s too small .  I ’ m also not sure about the colour of his outfit .  So I fumble along somehow , as best I can .  I will make mistakes on certain important points too .  But you ’ ll have to forgive me that .  My friend never gave explanations .  Perhaps he thought I was just like himself .  But I , unfortunately , don ' t know how to see sheep through boxes .  Perhaps I ’ m a bit like the grownups .  I must have got older . Every day I ’ d learn something about his planet , the departure , and the trip .  The information came slowly , as his thoughts wandered .  It was in this way that , on the third day , I came to know of the tragedy of the baobabs . This time again it was thanks to the sheep , because the little prince asked me abruptly , as if seized by a grave doubt : “ It ’ s true , isn ’ t it , that sheep eat shrubs ? ”  “ Yes .  It ' s true . ”  “ Oh !  I am glad ! ”  I didn ’ t understand why it was so important that sheep eat shrubs . But the little prince added : “ Then it follows they also eat baobabs ? ”  I pointed out to the little prince that baobabs were not shrubs , but trees as big as churches , and that even if he took with him a whole herd of elephants , the herd wouldn ' t manage to eat up one single baobab . The idea of the herd of elephants made the little prince laugh : “ They ’ d have to be piled up on top of each other ... ”  But he remarked wisely : “ The baobab trees , before they grow up , start off small . ”  “ That ' s right !  But why do you want the sheep to eat the little baobabs ? ”  He replied : “ Oh , come on ! ”  as if it were obvious .  And it took me a great mental effort to understand this problem on my own , without any help . And indeed , on the planet of the little prince there were , like on all planets , both good plants and bad plants .  And therefore , both good seeds from good plants and bad seeds from bad plants .  But seeds are invisible .  They sleep secretly deep in the earth until , on a whim , one of them decides to wake up .  Then it elongates and grows , timidly at first , toward the sun : a charming little harmless sprig .\n",
      "\n",
      "\n",
      "The idea of the herd of elephants made the little prince laugh : “ They ’ d have to be piled up on top of each other ... ”  But he remarked wisely : “ The baobab trees , before they grow up , start off small . ”  “ That ' s right !  But why do you want the sheep to eat the little baobabs ? ”  He replied : “ Oh , come on ! ”  as if it were obvious .  And it took me a great mental effort to understand this problem on my own , without any help . And indeed , on the planet of the little prince there were , like on all planets , both good plants and bad plants .  And therefore , both good seeds from good plants and bad seeds from bad plants .  But seeds are invisible .  They sleep secretly deep in the earth until , on a whim , one of them decides to wake up .  Then it elongates and grows , timidly at first , toward the sun : a charming little harmless sprig .  If it ’ s a sprig of radish or rose bush , you can let it grow as it likes .  But if it ’ s a bad plant , one must pull the plant out straight away , as soon as it can be recognised .  Now there were some terrible seeds on the planet of the little prince ...  there were the seeds of baobab trees .  The soil of the planet was infested with them .  A baobab , if you get to it too late , can never be got rid of .  It takes over the entire planet .  It pierces it with its roots .  And if the planet is too small , and if there are too many baobabs , they shatter it to pieces .  “ It ' s a matter of discipline , ” the little prince told me later .  “ After grooming oneself in the morning , the planet must be carefully groomed .  You must see to it that you regularly pull out the baobabs as soon as they can be told apart from the rose bushes , to which they look very similar when they ’ re very young .  It ' s a very boring job , but very easy . ”  And one day he suggested that I apply myself to making a beautiful drawing , so that the children from where I come from would understand all this .  “ If one day they travel , ” he said to me , “ it could come in useful .\n",
      "\n",
      "\n",
      " A baobab , if you get to it too late , can never be got rid of .  It takes over the entire planet .  It pierces it with its roots .  And if the planet is too small , and if there are too many baobabs , they shatter it to pieces .  “ It ' s a matter of discipline , ” the little prince told me later .  “ After grooming oneself in the morning , the planet must be carefully groomed .  You must see to it that you regularly pull out the baobabs as soon as they can be told apart from the rose bushes , to which they look very similar when they ’ re very young .  It ' s a very boring job , but very easy . ”  And one day he suggested that I apply myself to making a beautiful drawing , so that the children from where I come from would understand all this .  “ If one day they travel , ” he said to me , “ it could come in useful .  Sometimes there ’ s no harm in postponing one ' s work .  But in the case of baobabs , that always leads to a catastrophe .  I used to know a planet inhabited by a lazy man .  He had neglected three little bushes ... ”  And based on what the little prince told me , I drew this planet .  I don ’ t like to sound like a moralist .  But the danger of the baobabs is so little understood , and the risks run by anyone who might get lost on an asteroid are so large that , for once , I am breaking my normal reserve .  I say : “ Children !  Beware of baobabs ! ”  It ’ s to warn my friends of the danger they ' ve long been skirting , like myself , without knowing it , that I have worked so hard on this drawing .  The lesson which I pass on by this means was worth the effort .  You might be wondering : Why is it that in this book there aren ' t any other drawings as impressive as the drawing of the baobabs ?  The answer is simple : I tried but I couldn ’ t succeed .  When I drew the baobabs I was spurred on by a sense of urgency . Oh !  Little prince , I came to understand , gradually , in this way , your sad life .  For a long time your only entertainment was the softness of the sunsets .\n",
      "\n",
      "\n",
      " But the danger of the baobabs is so little understood , and the risks run by anyone who might get lost on an asteroid are so large that , for once , I am breaking my normal reserve .  I say : “ Children !  Beware of baobabs ! ”  It ’ s to warn my friends of the danger they ' ve long been skirting , like myself , without knowing it , that I have worked so hard on this drawing .  The lesson which I pass on by this means was worth the effort .  You might be wondering : Why is it that in this book there aren ' t any other drawings as impressive as the drawing of the baobabs ?  The answer is simple : I tried but I couldn ’ t succeed .  When I drew the baobabs I was spurred on by a sense of urgency . Oh !  Little prince , I came to understand , gradually , in this way , your sad life .  For a long time your only entertainment was the softness of the sunsets .  I learned this new detail on the fourth day , in the morning , when you said to me : “ I ’ m very fond of sunsets .  Let ’ s go and see a sunset now ... ”  “ But we have to wait ... ”  “ Wait for what ? ”  “ Wait until the sun goes down . ”  You seemed surprised at first , and then you chuckled at yourself .  And you said : “ I think myself at home still ! ”  Indeed .  When it ’ s noon in the United States , the sun , everybody knows , is setting over France .  It would suffice to be able to go to France in one minute to be able to see a sunset .  Unfortunately , France is much too far away .  But on your tiny planet , all you needed was to move your chair a few steps .  And you watched the twilight falling whenever you liked ... One day I saw the sunset forty - four times ! And a little later you added : “ You know ...  you love the sunset , when you ’ re really sad ... ”  “ The day you saw it forty - four times , were you were really that sad then ? ”  But the little prince made no reply .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in batch:\n",
    "    print(i)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('bert',\n",
       "               BertModel(\n",
       "                 (embeddings): BertEmbeddings(\n",
       "                   (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "                   (position_embeddings): Embedding(512, 768)\n",
       "                   (token_type_embeddings): Embedding(2, 768)\n",
       "                   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                   (dropout): Dropout(p=0.1, inplace=False)\n",
       "                 )\n",
       "                 (encoder): BertEncoder(\n",
       "                   (layer): ModuleList(\n",
       "                     (0): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (1): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (2): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (3): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (4): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (5): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (6): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (7): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (8): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (9): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (10): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (11): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                   )\n",
       "                 )\n",
       "                 (pooler): BertPooler(\n",
       "                   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                   (activation): Tanh()\n",
       "                 )\n",
       "               )),\n",
       "              ('cls',\n",
       "               BertOnlyMLMHead(\n",
       "                 (predictions): BertLMPredictionHead(\n",
       "                   (transform): BertPredictionHeadTransform(\n",
       "                     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                   )\n",
       "                   (decoder): Linear(in_features=768, out_features=28996, bias=True)\n",
       "                 )\n",
       "               ))]),\n",
       " 'config': BertConfig {\n",
       "   \"_num_labels\": 2,\n",
       "   \"architectures\": [\n",
       "     \"BertForMaskedLM\"\n",
       "   ],\n",
       "   \"attention_probs_dropout_prob\": 0.1,\n",
       "   \"bad_words_ids\": null,\n",
       "   \"bos_token_id\": null,\n",
       "   \"decoder_start_token_id\": null,\n",
       "   \"do_sample\": false,\n",
       "   \"early_stopping\": false,\n",
       "   \"eos_token_id\": null,\n",
       "   \"finetuning_task\": null,\n",
       "   \"hidden_act\": \"gelu\",\n",
       "   \"hidden_dropout_prob\": 0.1,\n",
       "   \"hidden_size\": 768,\n",
       "   \"id2label\": {\n",
       "     \"0\": \"LABEL_0\",\n",
       "     \"1\": \"LABEL_1\"\n",
       "   },\n",
       "   \"initializer_range\": 0.02,\n",
       "   \"intermediate_size\": 3072,\n",
       "   \"is_decoder\": false,\n",
       "   \"is_encoder_decoder\": false,\n",
       "   \"label2id\": {\n",
       "     \"LABEL_0\": 0,\n",
       "     \"LABEL_1\": 1\n",
       "   },\n",
       "   \"layer_norm_eps\": 1e-12,\n",
       "   \"length_penalty\": 1.0,\n",
       "   \"max_length\": 20,\n",
       "   \"max_position_embeddings\": 512,\n",
       "   \"min_length\": 0,\n",
       "   \"model_type\": \"bert\",\n",
       "   \"no_repeat_ngram_size\": 0,\n",
       "   \"num_attention_heads\": 12,\n",
       "   \"num_beams\": 1,\n",
       "   \"num_hidden_layers\": 12,\n",
       "   \"num_return_sequences\": 1,\n",
       "   \"output_attentions\": false,\n",
       "   \"output_hidden_states\": false,\n",
       "   \"pad_token_id\": 0,\n",
       "   \"prefix\": null,\n",
       "   \"pruned_heads\": {},\n",
       "   \"repetition_penalty\": 1.0,\n",
       "   \"task_specific_params\": null,\n",
       "   \"temperature\": 1.0,\n",
       "   \"top_k\": 50,\n",
       "   \"top_p\": 1.0,\n",
       "   \"torchscript\": false,\n",
       "   \"type_vocab_size\": 2,\n",
       "   \"use_bfloat16\": false,\n",
       "   \"use_cache\": true,\n",
       "   \"vocab_size\": 28996,\n",
       "   \"xla_device\": null\n",
       " }}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(model_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Once', ',', 'when', 'I', 'was', 'six', 'years', 'old', ',', 'I', 'saw', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'Real', '-', 'life', 'Stories', '.', '’', 'It', 'showed', 'a', 'b', '##oa', 'con', '##st', '##ric', '##tor', 'swallowing', 'a', 'wild', 'animal', '.', 'Here', 'is', 'a', 'copy', 'of', 'the', 'drawing', '.', 'It', 'said', 'in', 'the', 'book', ':', '“', 'Bo', '##a', 'con', '##st', '##ric', '##tors', 'swallow', 'their', 'prey', 'whole', ',', 'without', 'chewing', '.', 'Then', 'they', 'are', 'not', 'able', 'to', 'move', ',', 'and', 'they', 'sleep', 'for', 'the', 'six', 'months', 'it', 'takes', 'for', 'dig', '##est', '##ion', '.', '”', 'So', 'I', 'thought', 'a', 'lot', 'about', 'the', 'adventures', 'of', 'the', 'jungle', 'and', ',', 'in', 'turn', ',', 'I', 'managed', ',', 'with', 'a', 'coloured', 'pencil', ',', 'to', 'make', 'my', 'first', 'drawing', '.', 'My', 'Drawing', 'Number', 'one', '.', 'It', 'looked', 'like', 'this', ':', 'I', 'showed', 'my', 'masterpiece', 'to', 'the', 'grown', '##ups', 'and', 'I', 'asked', 'them', 'if', 'my', 'drawing', 'frightened', 'them', '.', 'They', 'answered', 'me', ':', '“', 'Why', 'would', 'anyone', 'be', 'frightened', 'by', 'a', 'hat', '?', '”', 'My', 'drawing', 'was', 'not', 'of', 'a', 'hat', '.', 'It', 'showed', 'a', 'b', '##oa', 'con', '##st', '##ric', '##tor', 'dig', '##est', '##ing', 'an', 'elephant', '.', 'I', 'then', 'drew', 'the', 'inside', 'of', 'the', 'b', '##oa', 'con', '##st', '##ric', '##tor', ',', 'so', 'that', 'the', 'grown', '##ups', 'could', 'understand', '.', 'They', 'always', 'need', 'to', 'have', 'things', 'explained', '.', 'My', 'Drawing', 'Number', 'two', 'looked', 'like', 'this', ':', 'The', 'grown', '##ups', 'advised', 'me', 'to', 'leave', 'aside', 'drawings', 'of', 'b', '##oa', 'con', '##st', '##ric', '##tors', ',', 'open', 'or', 'closed', ',', 'and', 'to', 'apply', 'myself', 'instead', 'to', 'geography', ',', 'history', ',', 'arithmetic', 'and', 'grammar', '.', 'Thus', 'I', 'abandoned', ',', 'at', 'the', 'age', 'of', 'six', ',', 'a', 'magnificent', 'career', 'as', 'a', 'painter', '.', 'I', 'was', 'discouraged', 'by', 'the', 'failure', 'of', 'my', 'Drawing', 'Number', 'one', 'and', 'of', 'my', 'Drawing', 'Number', 'two', '.', 'G', '##row', '##nu', '##ps', 'never', 'understand', 'anything', 'by', 'themselves', ',', 'and', 'it', '’', 's', 'tires', '##ome', 'for', 'children', 'to', 'always', 'explain', 'things', 'for', 'them', 'again', 'and', 'again', '.', 'So', 'I', 'had', 'to', 'choose', 'another', 'profession', ',', 'and', 'I', 'learned', 'to', 'fly', 'airplane', '##s', '.', 'I', 'flew', 'a', 'little', 'in', 'many', 'places', 'around', 'the', 'world', '.', 'And', 'geography', ',', 'it', \"'\", 's', 'true', ',', 'has', 'served', 'me', 'well', '.', 'I', 'could', 'recognize', ',', 'at', 'first', 'glance', ',', 'China', 'from', 'Arizona', '.', 'It', '’', 's', 'very', 'useful', 'if', 'you', 'get', 'lost', 'at', 'night', '.', 'I', 'have', 'had', ',', 'during', 'my', 'life', ',', 'a', 'lot', 'of', 'contact', 'with', 'many', 'persons', 'of', 'consequence', '.', 'I', 'have', 'lived', 'a', 'lot', 'amongst', 'the', 'grown', '##ups', '.', 'I', 'have', 'seen', 'them', 'from', 'close', 'up', '.', 'It', 'hasn', '##t', 'much', 'improved', 'my', 'opinion', 'of', 'them', '.', 'Whenever', 'I', 'met', 'one', 'of', 'them', 'that', 'seemed', 'a', 'bit', 'more', 'clear', '-', 'sighted', ',', 'I', 'tried', 'the', 'experiment', 'of', 'showing', 'them', 'my', 'Drawing', 'Number', 'one', ',', 'that', 'I', \"'\", 've', 'always', 'kept', '.', 'I', 'wanted', 'to', 'know', 'if', 'they', 'were', 'really', 'a', 'person', 'of', 'true', 'understanding', '.', 'But', 'they', 'always', 'responded', ':', '“', 'It', \"'\", 's', 'a', 'hat', '.', '”']\n",
      "\n",
      "499\n",
      "['Once', ',', 'when', 'I', 'was', 'six', 'years', 'old', ',', 'I', 'saw', 'a', 'magnificent', 'picture', 'in', 'a', 'book', 'about', 'the', 'prime', '##val', 'forest', 'called', '‘', 'Real', '-', 'life', 'Stories', '.', '’', 'It', 'showed', 'a', 'b', '##oa', 'con', '##st', '##ric', '##tor', 'swallowing', 'a', 'wild', 'animal', '.', 'Here', 'is', 'a', 'copy', 'of', 'the', 'drawing', '.', 'It', 'said', 'in', 'the', 'book', ':', '“', 'Bo', '##a', 'con', '##st', '##ric', '##tors', 'swallow', 'their', 'prey', 'whole', ',', 'without', 'chewing', '.', 'Then', 'they', 'are', 'not', 'able', 'to', 'move', ',', 'and', 'they', 'sleep', 'for', 'the', 'six', 'months', 'it', 'takes', 'for', 'dig', '##est', '##ion', '.', '”', 'So', 'I', 'thought', 'a', 'lot', 'about', 'the', 'adventures', 'of', 'the', 'jungle', 'and', ',', 'in', 'turn', ',', 'I', 'managed', ',', 'with', 'a', 'coloured', 'pencil', ',', 'to', 'make', 'my', 'first', 'drawing', '.', 'My', 'Drawing', 'Number', 'one', '.', 'It', 'looked', 'like', 'this', ':', 'I', 'showed', 'my', 'masterpiece', 'to', 'the', 'grown', '##ups', 'and', 'I', 'asked', 'them', 'if', 'my', 'drawing', 'frightened', 'them', '.', 'They', 'answered', 'me', ':', '“', 'Why', 'would', 'anyone', 'be', 'frightened', 'by', 'a', 'hat', '?', '”', 'My', 'drawing', 'was', 'not', 'of', 'a', 'hat', '.', 'It', 'showed', 'a', 'b', '##oa', 'con', '##st', '##ric', '##tor', 'dig', '##est', '##ing', 'an', 'elephant', '.', 'I', 'then', 'drew', 'the', 'inside', 'of', 'the', 'b']\n",
      "499\n",
      "0\n",
      "Once\n",
      "”\n",
      "499\n",
      "\n",
      "\n",
      "['I', 'was', 'discouraged', 'by', 'the', 'failure', 'of', 'my', 'Drawing', 'Number', 'one', 'and', 'of', 'my', 'Drawing', 'Number', 'two', '.', 'G', '##row', '##nu', '##ps', 'never', 'understand', 'anything', 'by', 'themselves', ',', 'and', 'it', '’', 's', 'tires', '##ome', 'for', 'children', 'to', 'always', 'explain', 'things', 'for', 'them', 'again', 'and', 'again', '.', 'So', 'I', 'had', 'to', 'choose', 'another', 'profession', ',', 'and', 'I', 'learned', 'to', 'fly', 'airplane', '##s', '.', 'I', 'flew', 'a', 'little', 'in', 'many', 'places', 'around', 'the', 'world', '.', 'And', 'geography', ',', 'it', \"'\", 's', 'true', ',', 'has', 'served', 'me', 'well', '.', 'I', 'could', 'recognize', ',', 'at', 'first', 'glance', ',', 'China', 'from', 'Arizona', '.', 'It', '’', 's', 'very', 'useful', 'if', 'you', 'get', 'lost', 'at', 'night', '.', 'I', 'have', 'had', ',', 'during', 'my', 'life', ',', 'a', 'lot', 'of', 'contact', 'with', 'many', 'persons', 'of', 'consequence', '.', 'I', 'have', 'lived', 'a', 'lot', 'amongst', 'the', 'grown', '##ups', '.', 'I', 'have', 'seen', 'them', 'from', 'close', 'up', '.', 'It', 'hasn', '##t', 'much', 'improved', 'my', 'opinion', 'of', 'them', '.', 'Whenever', 'I', 'met', 'one', 'of', 'them', 'that', 'seemed', 'a', 'bit', 'more', 'clear', '-', 'sighted', ',', 'I', 'tried', 'the', 'experiment', 'of', 'showing', 'them', 'my', 'Drawing', 'Number', 'one', ',', 'that', 'I', \"'\", 've', 'always', 'kept', '.', 'I', 'wanted', 'to', 'know', 'if', 'they', 'were', 'really', 'a', 'person', 'of', 'true', 'understanding', '.', 'But', 'they', 'always', 'responded', ':', '“', 'It', \"'\", 's', 'a', 'hat', '.', '”', 'So', 'I', 'would', 'never', 'speak', 'to', 'them', 'of', 'b', '##oa', 'con', '##st', '##ric', '##tors', ',', 'nor', 'of', 'prime', '##val', 'forests', ',', 'nor', 'of', 'the', 'stars', '.', 'I', 'put', 'myself', 'at', 'their', 'level', '.', 'I', 'talked', 'to', 'them', 'about', 'bridge', ',', 'golf', ',', 'politics', 'and', 'neck', '##ties', '.', 'And', 'the', 'grown', '##up', 'was', 'glad', 'to', 'know', 'such', 'a', 'sensible', 'man', '.', 'So', 'I', 'lived', 'alone', ',', 'without', 'anyone', 'I', 'could', 'really', 'talk', 'to', ',', 'until', 'a', 'breakdown', 'in', 'the', 'Sahara', 'desert', ',', 'six', 'years', 'ago', '.', 'Something', 'had', 'broken', 'in', 'my', 'engine', '.', 'And', 'as', 'I', 'had', 'with', 'me', 'neither', 'a', 'mechanic', 'nor', 'any', 'passengers', ',', 'I', 'read', '##ied', 'myself', 'to', 'try', 'and', 'carry', 'out', ',', 'all', 'alone', ',', 'the', 'difficult', 'repairs', '.', 'For', 'me', 'it', 'was', 'a', 'matter', 'of', 'life', 'or', 'death', '.', 'I', 'had', 'hardly', 'enough', 'water', 'to', 'drink', 'for', 'a', 'week', '.', 'The', 'first', 'night', 'I', 'went', 'to', 'sleep', 'on', 'the', 'sand', ',', 'a', 'thousand', 'miles', 'from', 'any', 'human', 'habitat', '##ion', '.', 'I', 'was', 'more', 'isolated', 'than', 'a', 'ship', '##w', '##reck', '##ed', 'sailor', 'on', 'a', 'r', '##aft', 'in', 'the', 'middle', 'of', 'the', 'ocean', '.', 'So', 'you', 'can', 'imagine', 'my', 'surprise', 'when', 'at', 'day', '##break', ',', 'a', 'funny', 'little', 'voice', 'woke', 'me', 'up', '.', 'It', 'said', ':', '“', 'Please', '.', '.', '.', 'draw', 'me', 'a', 'sheep', '!', '”', '“', 'What', '?', '”', '“', 'Draw', 'me', 'a', 'sheep', '!', '”', 'I', 'jumped', 'to', 'my', 'feet', 'as', 'if', 'I', '’', 'd', 'been', 'struck', 'by', 'lightning', '.', 'I', 'rubbed', 'my', 'eyes', '.', 'I', 'took', 'a', 'good', 'look', 'around', 'me', '.', 'And', 'I', 'saw', 'a', 'quite', 'extraordinary', 'little', 'man', ',', 'who', 'was', 'examining', 'me', 'seriously', '.', 'Here', 'is', 'the', 'best', 'portrait', 'that', ',', 'later', ',', 'I', 'managed', 'to', 'do', 'of', 'him', '.']\n",
      "\n",
      "506\n",
      "['I', 'was', 'discouraged', 'by', 'the', 'failure', 'of', 'my', 'Drawing', 'Number', 'one', 'and', 'of', 'my', 'Drawing', 'Number', 'two', '.', 'G', '##row', '##nu', '##ps', 'never', 'understand', 'anything', 'by', 'themselves', ',', 'and', 'it', '’', 's', 'tires', '##ome', 'for', 'children', 'to', 'always', 'explain', 'things', 'for', 'them', 'again', 'and', 'again', '.', 'So', 'I', 'had', 'to', 'choose', 'another', 'profession', ',', 'and', 'I', 'learned', 'to', 'fly', 'airplane', '##s', '.', 'I', 'flew', 'a', 'little', 'in', 'many', 'places', 'around', 'the', 'world', '.', 'And', 'geography', ',', 'it', \"'\", 's', 'true', ',', 'has', 'served', 'me', 'well', '.', 'I', 'could', 'recognize', ',', 'at', 'first', 'glance', ',', 'China', 'from', 'Arizona', '.', 'It', '’', 's', 'very', 'useful', 'if', 'you', 'get', 'lost', 'at', 'night', '.', 'I', 'have', 'had', ',', 'during', 'my', 'life', ',', 'a', 'lot', 'of', 'contact', 'with', 'many', 'persons', 'of', 'consequence', '.', 'I', 'have', 'lived', 'a', 'lot', 'amongst', 'the', 'grown', '##ups', '.', 'I', 'have', 'seen', 'them', 'from', 'close', 'up', '.', 'It', 'hasn', '##t', 'much', 'improved', 'my', 'opinion', 'of', 'them', '.', 'Whenever', 'I', 'met', 'one', 'of', 'them', 'that', 'seemed', 'a', 'bit', 'more', 'clear', '-', 'sighted', ',', 'I', 'tried', 'the', 'experiment', 'of', 'showing', 'them', 'my', 'Drawing', 'Number', 'one', ',', 'that', 'I', \"'\", 've', 'always', 'kept', '.', 'I', 'wanted', 'to', 'know', 'if', 'they', 'were', 'really', 'a', 'person']\n",
      "504\n",
      "217\n",
      "So\n",
      "of\n",
      "506\n",
      "\n",
      "\n",
      "['Something', 'had', 'broken', 'in', 'my', 'engine', '.', 'And', 'as', 'I', 'had', 'with', 'me', 'neither', 'a', 'mechanic', 'nor', 'any', 'passengers', ',', 'I', 'read', '##ied', 'myself', 'to', 'try', 'and', 'carry', 'out', ',', 'all', 'alone', ',', 'the', 'difficult', 'repairs', '.', 'For', 'me', 'it', 'was', 'a', 'matter', 'of', 'life', 'or', 'death', '.', 'I', 'had', 'hardly', 'enough', 'water', 'to', 'drink', 'for', 'a', 'week', '.', 'The', 'first', 'night', 'I', 'went', 'to', 'sleep', 'on', 'the', 'sand', ',', 'a', 'thousand', 'miles', 'from', 'any', 'human', 'habitat', '##ion', '.', 'I', 'was', 'more', 'isolated', 'than', 'a', 'ship', '##w', '##reck', '##ed', 'sailor', 'on', 'a', 'r', '##aft', 'in', 'the', 'middle', 'of', 'the', 'ocean', '.', 'So', 'you', 'can', 'imagine', 'my', 'surprise', 'when', 'at', 'day', '##break', ',', 'a', 'funny', 'little', 'voice', 'woke', 'me', 'up', '.', 'It', 'said', ':', '“', 'Please', '.', '.', '.', 'draw', 'me', 'a', 'sheep', '!', '”', '“', 'What', '?', '”', '“', 'Draw', 'me', 'a', 'sheep', '!', '”', 'I', 'jumped', 'to', 'my', 'feet', 'as', 'if', 'I', '’', 'd', 'been', 'struck', 'by', 'lightning', '.', 'I', 'rubbed', 'my', 'eyes', '.', 'I', 'took', 'a', 'good', 'look', 'around', 'me', '.', 'And', 'I', 'saw', 'a', 'quite', 'extraordinary', 'little', 'man', ',', 'who', 'was', 'examining', 'me', 'seriously', '.', 'Here', 'is', 'the', 'best', 'portrait', 'that', ',', 'later', ',', 'I', 'managed', 'to', 'do', 'of', 'him', '.', 'But', 'my', 'drawing', ',', 'of', 'course', ',', 'is', 'much', 'less', 'charming', 'than', 'its', 'model', '.', 'It', \"'\", 's', 'not', 'my', 'fault', '.', 'I', 'was', 'discouraged', 'in', 'my', 'career', 'as', 'a', 'painter', 'by', 'the', 'grown', '##ups', ',', 'at', 'the', 'age', 'of', 'six', ',', 'and', 'I', 'hadn', \"'\", 't', 'learned', 'to', 'draw', 'anything', 'except', 'b', '##oa', 'con', '##st', '##ric', '##tors', ',', 'closed', 'and', 'open', '.', 'I', 'stared', 'at', 'this', 'sudden', 'app', '##ari', '##tion', 'wide', 'eyed', 'with', 'astonishment', '.', 'Remember', 'that', 'I', 'was', 'a', 'thousand', 'miles', 'from', 'any', 'inhabited', 'region', '.', 'And', 'yet', 'this', 'little', 'fellow', 'seemed', 'neither', 'lost', ',', 'nor', 'half', '-', 'dead', 'with', 'fatigue', ',', 'nor', 'star', '##ved', 'or', 'dying', 'of', 'thirst', 'or', 'fear', '.', 'He', 'looked', 'nothing', 'like', 'a', 'child', 'lost', 'in', 'the', 'middle', 'of', 'the', 'desert', ',', 'a', 'thousand', 'miles', 'from', 'any', 'inhabited', 'region', '.', 'When', 'I', 'finally', 'managed', 'to', 'speak', ',', 'I', 'said', ':', '“', 'But', '—', 'what', 'are', 'you', 'doing', 'here', '?', '”', 'And', 'he', 'repeated', ',', 'very', 'slowly', ',', 'as', 'if', 'it', 'was', 'something', 'very', 'serious', ':', '“', 'Please', '.', '.', '.', 'draw', 'me', 'a', 'sheep', '.', '.', '.', '”', 'When', 'a', 'mystery', 'is', 'too', 'over', '##powering', ',', 'one', 'dare', 'not', 'di', '##so', '##bey', '.', 'A', '##bs', '##ur', '##d', 'as', 'it', 'seemed', 'to', 'me', 'a', 'thousand', 'miles', 'from', 'any', 'human', 'habitat', '##ion', 'and', 'in', 'danger', 'of', 'death', ',', 'I', 'took', 'out', 'of', 'my', 'pocket', 'a', 'sheet', 'of', 'paper', 'and', 'a', 'pen', '.', 'But', 'then', 'I', 'remembered', 'that', 'I', 'had', 'mainly', 'studied', 'geography', ',', 'history', ',', 'arithmetic', 'and', 'grammar', ',', 'and', 'I', 'told', 'the', 'little', 'fellow', '(', 'a', 'little', 'cross', '##ly', ')', 'that', 'I', 'didn', '’', 't', 'know', 'how', 'to', 'draw', '.', 'He', 'replied', ':', '“', 'It', 'doesn', \"'\", 't', 'matter', '.', 'Draw', 'me', 'a', 'sheep', '.', '”']\n",
      "\n",
      "495\n",
      "['Something', 'had', 'broken', 'in', 'my', 'engine', '.', 'And', 'as', 'I', 'had', 'with', 'me', 'neither', 'a', 'mechanic', 'nor', 'any', 'passengers', ',', 'I', 'read', '##ied', 'myself', 'to', 'try', 'and', 'carry', 'out', ',', 'all', 'alone', ',', 'the', 'difficult', 'repairs', '.', 'For', 'me', 'it', 'was', 'a', 'matter', 'of', 'life', 'or', 'death', '.', 'I', 'had', 'hardly', 'enough', 'water', 'to', 'drink', 'for', 'a', 'week', '.', 'The', 'first', 'night', 'I', 'went', 'to', 'sleep', 'on', 'the', 'sand', ',', 'a', 'thousand', 'miles', 'from', 'any', 'human', 'habitat', '##ion', '.', 'I', 'was', 'more', 'isolated', 'than', 'a', 'ship', '##w', '##reck', '##ed', 'sailor', 'on', 'a', 'r', '##aft', 'in', 'the', 'middle', 'of', 'the', 'ocean', '.', 'So', 'you', 'can', 'imagine', 'my', 'surprise', 'when', 'at', 'day', '##break', ',', 'a', 'funny', 'little', 'voice', 'woke', 'me', 'up', '.', 'It', 'said', ':', '“', 'Please', '.', '.', '.', 'draw', 'me', 'a', 'sheep', '!', '”', '“', 'What', '?', '”', '“', 'Draw', 'me', 'a', 'sheep', '!', '”', 'I', 'jumped', 'to', 'my', 'feet', 'as', 'if', 'I', '’', 'd', 'been', 'struck', 'by', 'lightning', '.', 'I', 'rubbed', 'my', 'eyes', '.', 'I', 'took', 'a', 'good', 'look', 'around', 'me', '.', 'And', 'I', 'saw', 'a', 'quite', 'extraordinary', 'little', 'man', ',', 'who', 'was', 'examining', 'me', 'seriously', '.', 'Here', 'is', 'the', 'best', 'portrait', 'that', ',', 'later', ',', 'I', 'managed', 'to']\n",
      "489\n",
      "202\n",
      "him\n",
      ".\n",
      "495\n",
      "\n",
      "\n",
      "['Remember', 'that', 'I', 'was', 'a', 'thousand', 'miles', 'from', 'any', 'inhabited', 'region', '.', 'And', 'yet', 'this', 'little', 'fellow', 'seemed', 'neither', 'lost', ',', 'nor', 'half', '-', 'dead', 'with', 'fatigue', ',', 'nor', 'star', '##ved', 'or', 'dying', 'of', 'thirst', 'or', 'fear', '.', 'He', 'looked', 'nothing', 'like', 'a', 'child', 'lost', 'in', 'the', 'middle', 'of', 'the', 'desert', ',', 'a', 'thousand', 'miles', 'from', 'any', 'inhabited', 'region', '.', 'When', 'I', 'finally', 'managed', 'to', 'speak', ',', 'I', 'said', ':', '“', 'But', '—', 'what', 'are', 'you', 'doing', 'here', '?', '”', 'And', 'he', 'repeated', ',', 'very', 'slowly', ',', 'as', 'if', 'it', 'was', 'something', 'very', 'serious', ':', '“', 'Please', '.', '.', '.', 'draw', 'me', 'a', 'sheep', '.', '.', '.', '”', 'When', 'a', 'mystery', 'is', 'too', 'over', '##powering', ',', 'one', 'dare', 'not', 'di', '##so', '##bey', '.', 'A', '##bs', '##ur', '##d', 'as', 'it', 'seemed', 'to', 'me', 'a', 'thousand', 'miles', 'from', 'any', 'human', 'habitat', '##ion', 'and', 'in', 'danger', 'of', 'death', ',', 'I', 'took', 'out', 'of', 'my', 'pocket', 'a', 'sheet', 'of', 'paper', 'and', 'a', 'pen', '.', 'But', 'then', 'I', 'remembered', 'that', 'I', 'had', 'mainly', 'studied', 'geography', ',', 'history', ',', 'arithmetic', 'and', 'grammar', ',', 'and', 'I', 'told', 'the', 'little', 'fellow', '(', 'a', 'little', 'cross', '##ly', ')', 'that', 'I', 'didn', '’', 't', 'know', 'how', 'to', 'draw', '.', 'He', 'replied', ':', '“', 'It', 'doesn', \"'\", 't', 'matter', '.', 'Draw', 'me', 'a', 'sheep', '.', '”', 'As', 'I', '’', 'd', 'never', 'drawn', 'a', 'sheep', ',', 'I', 'red', '##rew', 'for', 'him', 'one', 'of', 'the', 'only', 'two', 'drawings', 'that', 'I', 'was', 'capable', 'of', '.', 'The', 'one', 'of', 'the', 'closed', 'b', '##oa', 'con', '##st', '##ric', '##tor', '.', 'And', 'I', 'was', 'as', '##to', '##und', '##ed', 'to', 'hear', 'the', 'little', 'fellow', 'respond', ':', '“', 'No', '!', 'No', '!', 'I', 'don', '’', 't', 'want', 'an', 'elephant', 'inside', 'a', 'b', '##oa', 'con', '##st', '##ric', '##tor', '.', 'A', 'b', '##oa', 'con', '##st', '##ric', '##tor', 'is', 'very', 'dangerous', ',', 'and', 'an', 'elephant', 'is', 'very', 'cum', '##bers', '##ome', '.', 'Where', 'I', 'live', 'everything', 'is', 'very', 'small', '.', 'I', 'need', 'a', 'sheep', '.', 'Draw', 'me', 'a', 'sheep', '.', '”', 'So', 'I', 'drew', '.', 'He', 'looked', 'carefully', ',', 'then', 'said', ':', '“', 'No', '!', 'This', 'one', '’', 's', 'already', 'very', 'sick', '.', 'Make', 'another', 'one', '.', '”', 'I', 'drew', 'again', ':', 'My', 'friend', 'smiled', 'gently', 'and', 'in', '##du', '##lge', '##ntly', ':', '“', 'You', 'can', 'see', 'yourself', '.', '.', '.', 'this', 'isn', '’', 't', 'a', 'sheep', ',', 'it', \"'\", 's', 'a', 'ram', '.', 'It', 'has', 'horns', '.', '.', '.', '“', 'So', 'once', 'again', 'I', 'red', '##id', 'my', 'drawing', ':', 'But', 'it', 'was', 'rejected', ',', 'like', 'the', 'previous', 'ones', ':', '“', 'This', 'one', '’', 's', 'too', 'old', '.', 'I', 'want', 'a', 'sheep', 'that', 'will', 'live', 'a', 'long', 'time', '.', '”', 'So', ',', 'getting', 'impatient', ',', 'as', 'I', 'was', 'eager', 'to', 'start', 'di', '##sman', '##tling', 'my', 'engine', ',', 'I', 'hastily', 'sketch', '##ed', 'this', 'drawing', ':', 'And', 'I', 'snapped', ':', '“', 'This', 'here', 'is', 'the', 'box', '.', 'The', 'sheep', 'you', 'want', 'is', 'inside', '.', '”', 'But', 'I', 'was', 'very', 'surprised', 'to', 'see', 'the', 'face', 'of', 'my', 'young', 'judge', 'light', 'up', ':', '“', 'It', \"'\", 's', 'exactly', 'the', 'way', 'I', 'wanted', '!', 'Do', 'you', 'think', 'this', 'sheep', 'needs', 'a', 'lot', 'of', 'grass', '?', '”']\n",
      "\n",
      "516\n",
      "['Remember', 'that', 'I', 'was', 'a', 'thousand', 'miles', 'from', 'any', 'inhabited', 'region', '.', 'And', 'yet', 'this', 'little', 'fellow', 'seemed', 'neither', 'lost', ',', 'nor', 'half', '-', 'dead', 'with', 'fatigue', ',', 'nor', 'star', '##ved', 'or', 'dying', 'of', 'thirst', 'or', 'fear', '.', 'He', 'looked', 'nothing', 'like', 'a', 'child', 'lost', 'in', 'the', 'middle', 'of', 'the', 'desert', ',', 'a', 'thousand', 'miles', 'from', 'any', 'inhabited', 'region', '.', 'When', 'I', 'finally', 'managed', 'to', 'speak', ',', 'I', 'said', ':', '“', 'But', '—', 'what', 'are', 'you', 'doing', 'here', '?', '”', 'And', 'he', 'repeated', ',', 'very', 'slowly', ',', 'as', 'if', 'it', 'was', 'something', 'very', 'serious', ':', '“', 'Please', '.', '.', '.', 'draw', 'me', 'a', 'sheep', '.', '.', '.', '”', 'When', 'a', 'mystery', 'is', 'too', 'over', '##powering', ',', 'one', 'dare', 'not', 'di', '##so', '##bey', '.', 'A', '##bs', '##ur', '##d', 'as', 'it', 'seemed', 'to', 'me', 'a', 'thousand', 'miles', 'from', 'any', 'human', 'habitat', '##ion', 'and', 'in', 'danger', 'of', 'death', ',', 'I', 'took', 'out', 'of', 'my', 'pocket', 'a', 'sheet', 'of', 'paper', 'and', 'a', 'pen', '.', 'But', 'then', 'I', 'remembered', 'that', 'I', 'had', 'mainly', 'studied', 'geography', ',', 'history', ',', 'arithmetic', 'and', 'grammar', ',', 'and', 'I', 'told', 'the', 'little', 'fellow', '(', 'a', 'little', 'cross', '##ly', ')', 'that', 'I', 'didn', '’', 't', 'know', 'how', 'to', 'draw', '.', 'He']\n",
      "508\n",
      "211\n",
      "a\n",
      "this\n",
      "516\n",
      "\n",
      "\n",
      "['Where', 'I', 'live', 'everything', 'is', 'very', 'small', '.', 'I', 'need', 'a', 'sheep', '.', 'Draw', 'me', 'a', 'sheep', '.', '”', 'So', 'I', 'drew', '.', 'He', 'looked', 'carefully', ',', 'then', 'said', ':', '“', 'No', '!', 'This', 'one', '’', 's', 'already', 'very', 'sick', '.', 'Make', 'another', 'one', '.', '”', 'I', 'drew', 'again', ':', 'My', 'friend', 'smiled', 'gently', 'and', 'in', '##du', '##lge', '##ntly', ':', '“', 'You', 'can', 'see', 'yourself', '.', '.', '.', 'this', 'isn', '’', 't', 'a', 'sheep', ',', 'it', \"'\", 's', 'a', 'ram', '.', 'It', 'has', 'horns', '.', '.', '.', '“', 'So', 'once', 'again', 'I', 'red', '##id', 'my', 'drawing', ':', 'But', 'it', 'was', 'rejected', ',', 'like', 'the', 'previous', 'ones', ':', '“', 'This', 'one', '’', 's', 'too', 'old', '.', 'I', 'want', 'a', 'sheep', 'that', 'will', 'live', 'a', 'long', 'time', '.', '”', 'So', ',', 'getting', 'impatient', ',', 'as', 'I', 'was', 'eager', 'to', 'start', 'di', '##sman', '##tling', 'my', 'engine', ',', 'I', 'hastily', 'sketch', '##ed', 'this', 'drawing', ':', 'And', 'I', 'snapped', ':', '“', 'This', 'here', 'is', 'the', 'box', '.', 'The', 'sheep', 'you', 'want', 'is', 'inside', '.', '”', 'But', 'I', 'was', 'very', 'surprised', 'to', 'see', 'the', 'face', 'of', 'my', 'young', 'judge', 'light', 'up', ':', '“', 'It', \"'\", 's', 'exactly', 'the', 'way', 'I', 'wanted', '!', 'Do', 'you', 'think', 'this', 'sheep', 'needs', 'a', 'lot', 'of', 'grass', '?', '”', '“', 'Why', '?', '”', '“', 'Because', 'where', 'I', \"'\", 'm', 'from', 'everything', 'is', 'very', 'small', '.', '.', '.', '”', '“', 'There', 'will', 'certainly', 'be', 'enough', '.', 'I', 'gave', 'you', 'a', 'very', 'small', 'sheep', '.', '”', 'He', 'leaned', 'his', 'head', 'towards', 'the', 'drawing', ':', '“', 'Not', 'that', 'small', '.', '.', '.', 'Look', '!', 'He', \"'\", 's', 'fallen', 'asleep', '.', '.', '.', '”', 'And', 'that', \"'\", 's', 'how', 'I', 'met', 'the', 'little', 'prince', '.', 'It', 'took', 'me', 'a', 'long', 'time', 'to', 'find', 'out', 'where', 'he', 'came', 'from', '.', 'The', 'little', 'prince', ',', 'who', 'asked', 'me', 'many', 'questions', ',', 'never', 'seemed', 'to', 'hear', 'my', 'own', '.', 'It', 'was', 'the', 'words', 'spoken', 'by', 'chance', 'that', ',', 'little', 'by', 'little', ',', 'revealed', 'everything', 'to', 'me', '.', 'So', ',', 'when', 'he', 'saw', 'my', 'airplane', 'for', 'the', 'first', 'time', '(', 'I', 'won', '’', 't', 'draw', 'my', 'airplane', ',', 'it', 'would', 'be', 'a', 'drawing', 'far', 'too', 'complicated', 'for', 'me', ')', ',', 'he', 'asked', 'me', ':', '“', 'What', \"'\", 's', 'that', 'thing', 'there', '?', '”', '“', 'It', \"'\", 's', 'not', 'a', 'thing', '.', 'It', 'flies', '.', 'It', \"'\", 's', 'an', 'airplane', '.', 'It', '’', 's', 'my', 'airplane', '.', '”', 'And', 'I', 'was', 'proud', 'to', 'have', 'him', 'know', 'that', 'I', 'could', 'fly', '.', 'Then', 'he', 'cried', ':', '“', 'What', '?', 'You', 'fell', 'from', 'the', 'sky', '!', '”', '“', 'Yes', ',', '”', 'I', 'said', 'modest', '##ly', '.', '“', 'Oh', '!', 'That', \"'\", 's', 'funny', '!', '.', '.', '.', '”', 'And', 'the', 'little', 'prince', 'broke', 'into', 'a', 'lovely', 'p', '##eal', 'of', 'laughter', ',', 'which', 'irritated', 'me', 'very', 'much', '.', 'I', 'prefer', 'people', 'to', 'take', 'my', 'mi', '##s', '##fort', '##une', '##s', 'seriously', '.', 'Then', 'he', 'added', ':', '“', 'So', ',', 'you', 'also', 'come', 'from', 'the', 'sky', '!', 'What', 'planet', 'are', 'you', 'from', '?', '”']\n",
      "\n",
      "499\n",
      "['Where', 'I', 'live', 'everything', 'is', 'very', 'small', '.', 'I', 'need', 'a', 'sheep', '.', 'Draw', 'me', 'a', 'sheep', '.', '”', 'So', 'I', 'drew', '.', 'He', 'looked', 'carefully', ',', 'then', 'said', ':', '“', 'No', '!', 'This', 'one', '’', 's', 'already', 'very', 'sick', '.', 'Make', 'another', 'one', '.', '”', 'I', 'drew', 'again', ':', 'My', 'friend', 'smiled', 'gently', 'and', 'in', '##du', '##lge', '##ntly', ':', '“', 'You', 'can', 'see', 'yourself', '.', '.', '.', 'this', 'isn', '’', 't', 'a', 'sheep', ',', 'it', \"'\", 's', 'a', 'ram', '.', 'It', 'has', 'horns', '.', '.', '.', '“', 'So', 'once', 'again', 'I', 'red', '##id', 'my', 'drawing', ':', 'But', 'it', 'was', 'rejected', ',', 'like', 'the', 'previous', 'ones', ':', '“', 'This', 'one', '’', 's', 'too', 'old', '.', 'I', 'want', 'a', 'sheep', 'that', 'will', 'live', 'a', 'long', 'time', '.', '”', 'So', ',', 'getting', 'impatient', ',', 'as', 'I', 'was', 'eager', 'to', 'start', 'di', '##sman', '##tling', 'my', 'engine', ',', 'I', 'hastily', 'sketch', '##ed', 'this', 'drawing', ':', 'And', 'I', 'snapped', ':', '“', 'This', 'here', 'is', 'the', 'box', '.', 'The', 'sheep', 'you', 'want', 'is', 'inside', '.', '”', 'But', 'I', 'was', 'very', 'surprised', 'to', 'see', 'the', 'face', 'of', 'my', 'young', 'judge', 'light', 'up', ':', '“', 'It', \"'\", 's', 'exactly', 'the', 'way', 'I', 'wanted', '!', 'Do', 'you', 'think', 'this']\n",
      "487\n",
      "204\n",
      "of\n",
      "also\n",
      "499\n",
      "\n",
      "\n",
      "['The', 'little', 'prince', ',', 'who', 'asked', 'me', 'many', 'questions', ',', 'never', 'seemed', 'to', 'hear', 'my', 'own', '.', 'It', 'was', 'the', 'words', 'spoken', 'by', 'chance', 'that', ',', 'little', 'by', 'little', ',', 'revealed', 'everything', 'to', 'me', '.', 'So', ',', 'when', 'he', 'saw', 'my', 'airplane', 'for', 'the', 'first', 'time', '(', 'I', 'won', '’', 't', 'draw', 'my', 'airplane', ',', 'it', 'would', 'be', 'a', 'drawing', 'far', 'too', 'complicated', 'for', 'me', ')', ',', 'he', 'asked', 'me', ':', '“', 'What', \"'\", 's', 'that', 'thing', 'there', '?', '”', '“', 'It', \"'\", 's', 'not', 'a', 'thing', '.', 'It', 'flies', '.', 'It', \"'\", 's', 'an', 'airplane', '.', 'It', '’', 's', 'my', 'airplane', '.', '”', 'And', 'I', 'was', 'proud', 'to', 'have', 'him', 'know', 'that', 'I', 'could', 'fly', '.', 'Then', 'he', 'cried', ':', '“', 'What', '?', 'You', 'fell', 'from', 'the', 'sky', '!', '”', '“', 'Yes', ',', '”', 'I', 'said', 'modest', '##ly', '.', '“', 'Oh', '!', 'That', \"'\", 's', 'funny', '!', '.', '.', '.', '”', 'And', 'the', 'little', 'prince', 'broke', 'into', 'a', 'lovely', 'p', '##eal', 'of', 'laughter', ',', 'which', 'irritated', 'me', 'very', 'much', '.', 'I', 'prefer', 'people', 'to', 'take', 'my', 'mi', '##s', '##fort', '##une', '##s', 'seriously', '.', 'Then', 'he', 'added', ':', '“', 'So', ',', 'you', 'also', 'come', 'from', 'the', 'sky', '!', 'What', 'planet', 'are', 'you', 'from', '?', '”', 'I', 'caught', 'a', 'glimpse', 'into', 'the', 'mystery', 'of', 'his', 'presence', ',', 'and', 'I', 'asked', 'abruptly', ':', '“', 'So', 'you', 'come', 'from', 'another', 'planet', 'then', '?', '”', 'But', 'he', 'didn', '’', 't', 'answer', '.', 'He', 'shook', 'his', 'head', 'slowly', 'whilst', 'looking', 'at', 'my', 'airplane', ':', '“', 'It', \"'\", 's', 'true', 'that', 'you', 'can', \"'\", 't', 'have', 'come', 'from', 'far', 'away', 'in', 'that', 'thing', '.', '.', '.', '”', 'And', 'he', 'drifted', 'into', 'a', 'day', '##dre', '##am', 'which', 'lasted', 'a', 'long', 'while', '.', 'Then', ',', 'taking', 'my', 'sheep', 'out', 'of', 'his', 'pocket', ',', 'he', 'sank', 'himself', 'into', 'the', 'con', '##tem', '##p', '##lation', 'of', 'his', 'treasure', '.', 'You', 'can', 'imagine', 'how', 'my', 'curiosity', 'was', 'aroused', 'by', 'this', 'small', 'disclosure', 'about', '‘', 'the', 'other', 'planets', '.', '’', 'So', 'I', 'tried', 'to', 'find', 'out', 'more', ':', '“', 'Where', 'are', 'you', 'from', 'my', 'little', 'fellow', '?', 'Where', '’', 's', 'this', '‘', 'where', 'I', 'live', '’', 'of', 'yours', '?', 'Where', 'do', 'you', 'take', 'my', 'sheep', 'off', 'to', '?', '”', 'After', 'a', 'reflective', 'silence', 'he', 'answered', ':', '“', 'What', \"'\", 's', 'good', 'about', 'the', 'box', 'you', '’', 've', 'given', 'me', 'is', 'that', 'at', 'night', ',', 'he', 'can', 'use', 'it', 'as', 'a', 'house', '.', '”', '“', 'That', '’', 's', 'right', '.', 'And', 'if', 'you', '’', 're', 'good', ',', 'I', \"'\", 'll', 'give', 'you', 'a', 'rope', 'to', 'tie', 'him', 'up', 'with', 'during', 'the', 'day', '.', 'And', 'a', 'stake', '.', '”', 'The', 'offer', 'seemed', 'to', 'shock', 'the', 'little', 'prince', ':', '“', 'T', '##ie', 'him', 'up', '?', 'What', 'a', 'funny', 'idea', '!', '”', '“', 'But', 'if', 'you', 'don', \"'\", 't', 'tie', 'him', 'up', ',', 'he', '’', 'll', 'wander', 'off', ',', 'and', 'get', 'lost', '.', '”', 'My', 'friend', 'broke', 'into', 'another', 'p', '##eal', 'of', 'laughter', ':', '“', 'Where', 'do', 'you', 'think', 'he', '’', 'd', 'go', '!', '”', '“', 'Any', '##where', '.', 'Straight', 'ahead', '.', '.', '.', '”']\n",
      "\n",
      "508\n",
      "['The', 'little', 'prince', ',', 'who', 'asked', 'me', 'many', 'questions', ',', 'never', 'seemed', 'to', 'hear', 'my', 'own', '.', 'It', 'was', 'the', 'words', 'spoken', 'by', 'chance', 'that', ',', 'little', 'by', 'little', ',', 'revealed', 'everything', 'to', 'me', '.', 'So', ',', 'when', 'he', 'saw', 'my', 'airplane', 'for', 'the', 'first', 'time', '(', 'I', 'won', '’', 't', 'draw', 'my', 'airplane', ',', 'it', 'would', 'be', 'a', 'drawing', 'far', 'too', 'complicated', 'for', 'me', ')', ',', 'he', 'asked', 'me', ':', '“', 'What', \"'\", 's', 'that', 'thing', 'there', '?', '”', '“', 'It', \"'\", 's', 'not', 'a', 'thing', '.', 'It', 'flies', '.', 'It', \"'\", 's', 'an', 'airplane', '.', 'It', '’', 's', 'my', 'airplane', '.', '”', 'And', 'I', 'was', 'proud', 'to', 'have', 'him', 'know', 'that', 'I', 'could', 'fly', '.', 'Then', 'he', 'cried', ':', '“', 'What', '?', 'You', 'fell', 'from', 'the', 'sky', '!', '”', '“', 'Yes', ',', '”', 'I', 'said', 'modest', '##ly', '.', '“', 'Oh', '!', 'That', \"'\", 's', 'funny', '!', '.', '.', '.', '”', 'And', 'the', 'little', 'prince', 'broke', 'into', 'a', 'lovely', 'p', '##eal', 'of', 'laughter', ',', 'which', 'irritated', 'me', 'very', 'much', '.', 'I', 'prefer', 'people', 'to', 'take', 'my', 'mi', '##s', '##fort', '##une', '##s', 'seriously', '.', 'Then', 'he', 'added', ':', '“', 'So', ',', 'you', 'also', 'come', 'from', 'the', 'sky', '!', 'What', 'planet']\n",
      "502\n",
      "203\n",
      "?\n",
      ".\n",
      "508\n",
      "\n",
      "\n",
      "['Then', ',', 'taking', 'my', 'sheep', 'out', 'of', 'his', 'pocket', ',', 'he', 'sank', 'himself', 'into', 'the', 'con', '##tem', '##p', '##lation', 'of', 'his', 'treasure', '.', 'You', 'can', 'imagine', 'how', 'my', 'curiosity', 'was', 'aroused', 'by', 'this', 'small', 'disclosure', 'about', '‘', 'the', 'other', 'planets', '.', '’', 'So', 'I', 'tried', 'to', 'find', 'out', 'more', ':', '“', 'Where', 'are', 'you', 'from', 'my', 'little', 'fellow', '?', 'Where', '’', 's', 'this', '‘', 'where', 'I', 'live', '’', 'of', 'yours', '?', 'Where', 'do', 'you', 'take', 'my', 'sheep', 'off', 'to', '?', '”', 'After', 'a', 'reflective', 'silence', 'he', 'answered', ':', '“', 'What', \"'\", 's', 'good', 'about', 'the', 'box', 'you', '’', 've', 'given', 'me', 'is', 'that', 'at', 'night', ',', 'he', 'can', 'use', 'it', 'as', 'a', 'house', '.', '”', '“', 'That', '’', 's', 'right', '.', 'And', 'if', 'you', '’', 're', 'good', ',', 'I', \"'\", 'll', 'give', 'you', 'a', 'rope', 'to', 'tie', 'him', 'up', 'with', 'during', 'the', 'day', '.', 'And', 'a', 'stake', '.', '”', 'The', 'offer', 'seemed', 'to', 'shock', 'the', 'little', 'prince', ':', '“', 'T', '##ie', 'him', 'up', '?', 'What', 'a', 'funny', 'idea', '!', '”', '“', 'But', 'if', 'you', 'don', \"'\", 't', 'tie', 'him', 'up', ',', 'he', '’', 'll', 'wander', 'off', ',', 'and', 'get', 'lost', '.', '”', 'My', 'friend', 'broke', 'into', 'another', 'p', '##eal', 'of', 'laughter', ':', '“', 'Where', 'do', 'you', 'think', 'he', '’', 'd', 'go', '!', '”', '“', 'Any', '##where', '.', 'Straight', 'ahead', '.', '.', '.', '”', 'Then', 'the', 'little', 'prince', 'said', 'gravel', '##y', ':', '“', 'That', 'doesn', '’', 't', 'matter', ';', 'where', 'I', 'live', ',', 'everything', 'is', 'so', 'small', '!', '”', 'And', 'perhaps', 'with', 'a', 'hint', 'of', 'sadness', ',', 'he', 'added', ':', '“', 'Straight', 'ahead', 'you', 'can', \"'\", 't', 'go', 'far', '.', '.', '.', '”']\n",
      "\n",
      "272\n",
      "['Then', ',', 'taking', 'my', 'sheep', 'out', 'of', 'his', 'pocket', ',', 'he', 'sank', 'himself', 'into', 'the', 'con', '##tem', '##p', '##lation', 'of', 'his', 'treasure', '.', 'You', 'can', 'imagine', 'how', 'my', 'curiosity', 'was', 'aroused', 'by', 'this', 'small', 'disclosure', 'about', '‘', 'the', 'other', 'planets', '.', '’', 'So', 'I', 'tried', 'to', 'find', 'out', 'more', ':', '“', 'Where', 'are', 'you', 'from', 'my', 'little', 'fellow', '?', 'Where', '’', 's', 'this', '‘', 'where', 'I', 'live', '’', 'of', 'yours', '?', 'Where', 'do', 'you', 'take', 'my', 'sheep', 'off', 'to', '?', '”', 'After', 'a', 'reflective', 'silence', 'he', 'answered', ':', '“', 'What', \"'\", 's', 'good', 'about', 'the', 'box', 'you', '’', 've', 'given', 'me', 'is', 'that', 'at', 'night', ',', 'he', 'can', 'use', 'it', 'as', 'a', 'house', '.', '”', '“', 'That', '’', 's', 'right', '.', 'And', 'if', 'you', '’', 're', 'good', ',', 'I', \"'\", 'll', 'give', 'you', 'a', 'rope', 'to', 'tie', 'him', 'up', 'with', 'during', 'the', 'day', '.', 'And', 'a', 'stake', '.', '”', 'The', 'offer', 'seemed', 'to', 'shock', 'the', 'little', 'prince', ':', '“', 'T', '##ie', 'him', 'up', '?', 'What', 'a', 'funny', 'idea', '!', '”', '“', 'But', 'if', 'you', 'don', \"'\", 't', 'tie', 'him', 'up', ',', 'he', '’', 'll', 'wander', 'off', ',', 'and', 'get', 'lost', '.', '”', 'My', 'friend', 'broke', 'into', 'another', 'p', '##eal', 'of']\n",
      "268\n",
      "221\n",
      ".\n",
      "far\n",
      "272\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _, i in enumerate(batch):\n",
    "    tokens = t_bert.tokenize(i)\n",
    "    \n",
    "    \n",
    "    print(tokens)\n",
    "    print()\n",
    "    print(len(tokens))\n",
    "    print(tokens[:200])\n",
    "    print(indexes[_][1])\n",
    "    print(indexes[_][0])\n",
    "    print(tokens[indexes[_][0]])\n",
    "    print(tokens[indexes[_][1]-1])\n",
    "    print(len(tokens))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Straight ahead... ”'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_bert.decode(t_bert.convert_tokens_to_ids(t_bert.wordpiece_tokenizer.tokenize(' Straight ahead ... ”')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ĠStraight', 'Ġahead', 'Ġ...', 'ĠâĢ', 'Ŀ']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_base.tokenize(' Straight ahead ... ”')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []                                                                                                                                                                                        \n",
    "\n",
    "for line in iterator_list[0]:  \n",
    "    result.append(len([word for word in line.strip().split(' ')])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in result:\n",
    "    out_lstm.append(np.sum(lstm_result[index:index+i]))\n",
    "    index+=i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, line in enumerate(iterator_list[0]):  \n",
    "    out_gpt2_base = model_base(**t_base.encode_plus(line,add_special_tokens = False,max_length = 128, return_attention_mask = True,return_tensors = 'pt' )) \n",
    "    out_gpt2_medium = model_medium(**t_medium.encode_plus(line,add_special_tokens = False,max_length = 128, return_attention_mask = True,return_tensors = 'pt' ))  \n",
    "    out_bert = model_bert(**t_bert.encode_plus(line,add_special_tokens = False,max_length = 128, return_attention_mask = True,return_tensors = 'pt' ))  \n",
    "    results.append(eval_output(out_gpt2_base), eval_output(out_gpt2_medium), eval_output(out_bert), out_lstm[index]) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFram(results, columns=['GPT2-base', 'GPT2-medium', 'BERT-base-cased', 'LSTM-E600-H300-L1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
